<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.0">Jekyll</generator><link href="/feed.xml" rel="self" type="application/atom+xml" /><link href="/" rel="alternate" type="text/html" /><updated>2021-01-26T10:19:06-03:00</updated><id>/feed.xml</id><title type="html">CGomesu</title><subtitle>A blog and portfolio website built with Jekyll and hosted on Github Pages</subtitle><author><name>Carlos Gomes</name></author><entry><title type="html">TVHlink: Livestreams as IPTV channels with TVHeadend and Streamlink</title><link href="/blog/Tvhlink/" rel="alternate" type="text/html" title="TVHlink: Livestreams as IPTV channels with TVHeadend and Streamlink" /><published>2021-01-21T12:20:00-03:00</published><updated>2021-01-21T12:20:00-03:00</updated><id>/blog/Tvhlink</id><content type="html" xml:base="/blog/Tvhlink/"># Changelog
**Jan 21st, 2021**: Publication of the original article
{:.notice .notice--info}

[top](#){:.btn .btn--light-outline .btn--small}


# Introduction
In my previous post titled [Youtube live as IPTV channels for TVHeadend](/blog/Youtube-as-IPTV-with-TVH/), I mentioned a method for capturing a Youtube livestream and feeding it into a **[TVHeadend](https://github.com/tvheadend/tvheadend)** (TVH) server via a Python utility called **[Streamlink](https://github.com/streamlink/streamlink)**.  In this tutorial, I will present an easier and more reliable method of doing that for Youtube as well as [*any* other supported sources](https://streamlink.github.io/plugin_matrix.html).  I called this integration **TVHlink**.  

The simplified TVHlink integration is largely due to the release of a new version of the Streamlink utility (**[Streamlink v2.0.0](https://github.com/streamlink/streamlink/releases/tag/2.0.0)**) that includes many bug fixes and more flexible plugins for Youtube, Twitch, and other livestream sources.  For Youtube, for example, it's now possible to simply point to a channel URL and the parser will automatically try to grab its livestream, instead of using the old method of pointing to the exact livestream URL, which often changes from time to time.  This is basically what I was doing with my [youtube4tvh](https://github.com/cgomesu/youtube4tvh) utility but now that the improved content parser has been implemented into Streamlink, we don't need youtube4tvh anymore because the livestream URL is found upon each TVH client request, rather than previously stored into a `.m3u` playlist.

**DISCLAIMER**. All the software used here is **free and open-source** and **all livestream sources are publicly available** and are provided by the copyright owners themselves via either plataforms such as [Youtube](https://www.youtube.com/), [Twitch](https://www.twitch.tv/), [Dailymotion](https://www.dailymotion.com/), etc., or their official channels (e.g., [CBS News](https://www.cbsnews.com/),  [DW](https://www.dw.com/), [Reuters](https://www.reuters.com/)) for anyone to use. If you enjoy the content, **please consider supporting the developers, streamers, and providers** who make this possible.
{:.notice .notice--warning}

## Client demo
Here is a preview of how the TVHlink integration looks like for mulitple TVH clients.  This is a *non-exhaustive* list because there are [other TVH compatible clients](https://tvheadend.org/projects/tvheadend/wiki/Clients).  For more information about TVH client configuration, refer to the [TVH clients](#tvh-clients) section in this tutorial.

For reference, all client demos were tested with a modest connection of D:**10Mbps** / U:**150Kbps**, which shows that the TVHlink integration works fairly well even if you have limited connectivity.  However, if your connection is better than that, you can **expect much better performance than demonstrated** in the videos, and fine-tuning the source quality via stream profiles will greatly improve performance as well (the demos used 720p for all streams).  Performance is also very much client-dependent.  The **TVH client addon for Kodi** has been the one that provided me the best experience so far.  It uses the HTSP protocol, which was designed for streaming, and allows the use of predictive tuning, which pre-loads channels before you access them, making the transition between channels next to each other much smoother than via webUI or VLC, as you can see in the demos.

* **[Kodi](#tvh-kodi-pvr-addon)**

{% include video id=&quot;uZw3M3by2tI&quot; provider=&quot;youtube&quot; %}

* **[Web-browser (TVH webUI)](#tvh-clients)**

{% include video id=&quot;EjJCRwiHXwY&quot; provider=&quot;youtube&quot; %}

* **[VLC player](#vlc-and-other-m3u-players)**

{% include video id=&quot;RBvuZXWxDMU&quot; provider=&quot;youtube&quot; %}

## Overview
This tutorial is organized into six main sections.  The first two sections introduce a few reasons two implement the TVH link integration ([motivation](#motivation)) and a general picture of how it works ([client-server flow](#client-server-flow)).  The third section, called [hardware](#hardware), contains a brief discussion about the hardware requirements to run a TVH server and my personal recommendation for new and experienced home users looking for hardware to buy. 

The last three sections contain the actual how-to guide for the [software](#software) components, such as the installation of a TVH server and Streamlink on a GNU/Linux host or Docker container, as well as their basic configuration.  Afterwards, the [TVHlink](#tvhlink) integration was described in detail, showing how to build customized IPTV networks of livestream channels.  The [TVH clients](#tvh-clients) were discussed at the end of the tutorial, with a focus on my two favorite ones--namely, the Kodi PVR addon and VLC/`m3u` players.

If you have already read my previous post called [Youtube live as IPTV channels for TVHeadend](/blog/Youtube-as-IPTV-with-TVH/), you might want to skip straight to the [software](#software) discussion and [TVHlink integration](#tvhlink).  Note that the installation sections are much more detailed than before and the TVHlink integration was greatly simplified because now, we do not need to generate and update `m3u` playlists outside of the TVH server environment.  That said, the current TVHlink tutorial is self-contained and does not require anyone to have read my previous post in order to implement the TVHlink integration.

If you are new to all of this, don't panic!  Grab a towel, save some time, and read through. Then, give it a try on your own first and if you run into an &quot;unsolvable&quot; issue, feel free to [get in touch with me](/contact).  I am glad to help out.

[top](#){:.btn .btn--light-outline .btn--small}


# Motivation
There are multiple reasons to watch livestreams as if they were IPTV channels via a centralized server such as TVH.  To mention a few:

* It is **free and all programs are open-source**;
* There is at least one **24/7 livestream** that you enjoy. For example, the following Youtube channels: 
  * **News**: ABC News, Sky News, DW, France 24
  * **Space**: NASA TV, Space Videos
  * **Webcam - Nature**: Cornell Bird Cams, Monterey Bay Aquarium, Explore Nature
  * **Webcam - Other**: earthTV, I Love You Venice, Railway
  * **Radio**:  BGM channel, Cafe del Mar, Stay See
* More options to access content from multiple networks using a single client;
* Keep your streaming services as centralized as possible.  That is, instead of multiple applications, you can manage everything from a single server;
* Record livestreams with the push of a button on any client or via a schedule;
* Take advantage of fast and reliable content delivery networks (e.g., Akamai, Youtube CDN).

[top](#){:.btn .btn--light-outline .btn--small}


# Client-server flow
The client-server flow underlying the TVHlink integration is illustrated next.

[![Client-server-flow](/assets/posts/2021-01-17-Tvhlink/client-server-flow.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/client-server-flow.jpg)

That is, the TVH server stores one or more IPTV networks as `m3u` playlists that contain one or more (livestreaming) channels as a track.  When a TVH client (any IPTV/`m3u` player) connects to the TVH server, the server executes a Streamlink command, which will in turn try to find the livestream data.  If successful, streamlink will output the data into the TVH server, which will then send back to the client that requested the livestream.  Otherwise, the request will either return an error or timeout.

A TVH server is not capable of multicasting any livestream.  This requires a third software component to the client-server flow, such as [VLC](https://www.videolan.org/vlc/).  This topic is beyond the scope of the current tutorial but if interested, check the following guide: [VLC Multicasting for IPTV into TVHeadend](https://tvheadend.org/projects/tvheadend/wiki/VLC_Multicasting#VLC-Multicasting-for-IPTV-into-TVHeadend).

[top](#){:.btn .btn--light-outline .btn--small}


# Hardware
The hardware requirement to run a TVH server depends largely on its usage.  It runs on a huge variety of devices, from a tiny ARM-based single-board computer (SBC) to a powerful AMD/Intel x86-64 machine.  (Users have even managed to run TVH on a [travel router](https://tvheadend.org/boards/4/topics/16579) with 8MB of flash storage, 64MB of RAM, and a 600 MHz MIPS CPU.)  However, if you want to use TV tuners in addition to the TVHlink integration, I strongly suggest you to use a x86-64 machine with at least one PCIe interface instead of a SBC.  This will give you more options to choose from than relying exclusively on USB tuners.

Most of the resource requirements to run TVH come from transcoding and networking.  For example, while a [Raspbery Pi 3B](https://www.raspberrypi.org/products/raspberry-pi-3-model-b/) (RPi) will be more than enough to run a TVH server and use the TVHlink integration with default settings, CPU-wise, the RPi will strugle if you enable transcoding via different streaming profiles and feed it to multiple clients.  Fortunately, you can avoid transcoding altogether by configuring Streamlink to grab and feed lower resolution streams **directly from the source**, or even better, create **\_HD** and **\_SD** channels for the same livestream source and let the client choose what works best for them (e.g., in the pipe command to run `streamlink`, use the option `--default-stream 1080p,720p,best` for HD channels, and the option `--default-stream 480p,360p,worst` for SD).

Networking-wise, a 100Mbit ethernet port can get easily saturated if serving high-resolution streams to more than one client at once.  Wireless connections are okay for clients but your TVH server should not rely on them because too many things can interfere with wireless communication.  An alternative is to use the wireless interface for management (i.e., to access the webUI) and reserve one or more ethernet ports for streaming.  My suggestion is that at the very least, reserve a **1Gbit ethernet port** for TVH.

The RAM requirement is pretty low if not transcoding or recording to RAM.  In general, plan on dedicating **at least 1GB of RAM** to the TVH server.  Similarly, the TVH server **uses less than 100MB of storage space**.  However, TVH let's you record videos from any of your sources and depending on the recording profile, this can use a lot of space.

The hardware requirements for Streamlink are negligible.

## Device recomendations
If you are new to all of this and are looking for cheap and efficient hardware to get started, take a look at the [Raspberry Pi 4B](https://www.raspberrypi.org/products/raspberry-pi-4-model-b/) and the [Odroid C2](https://www.hardkernel.com/shop/odroid-c2/) or its latest iteration, the [Odroid C4](https://www.hardkernel.com/shop/odroid-c4/), for example.  They are solid, low-power devices that you can buy for less than US$ 50 and that meet the requirements to run a TVH server and more.  They can even be used as an **all-in-one** box--that is, TVH server and client at the same time.  All such boards are well-known and sold world-wide via AliExpress, Amazon, and the like.

[![RPi 4B](/assets/posts/2021-01-17-Tvhlink/rpi4b-board.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/rpi4b-board.jpg)

[![Odroid C2](/assets/posts/2021-01-17-Tvhlink/odroidc2-board.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/odroidc2-board.jpg)

[![Odroid C4](/assets/posts/2021-01-17-Tvhlink/odroidc4-board.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/odroidc4-board.jpg)

However, if you are an experienced user, consider using **virtualization** with your existing hardware.  This will save you money and provide an easy to manage plataform for TVH and other services.

[top](#){:.btn .btn--light-outline .btn--small}


# Software
As the name suggests, there are two main software components to the TVHlink integration, namely [TVH](https://github.com/tvheadend/tvheadend) and [Streamlink](https://github.com/streamlink/streamlink). The minor components are all their dependencies (e.g., `Python3`, `ffmpeg`) but their installation packages will take care of them in most cases.  As mentioned before, both projects are free and open-source, so anyone can download, install, use, and help developing and maintaining the projects.  (You don't need to be a programmer to help out.  Check if they need assistance with translations, for example, and check how to report bugs via the Github repositories whenever you find one.)  **Please consider supporting both projects** if you find them useful:

* **TVH Donations**: [https://tvheadend.org/projects/tvheadend/wiki/donate](https://tvheadend.org/projects/tvheadend/wiki/donate)

* **Streamlink Donations**: [https://streamlink.github.io/donate.html](https://streamlink.github.io/donate.html)

In this section of the tutorial, I will go over the installation process of the related software, their basic usage, concepts, and configuration.  Unless otherwise specified, I will assume the host is a **GNU/Linux OS** and more specifically, an `apt` based distribution, such as **Debian** or **Ubuntu**.  If this is not the case, simply adapt the commands to use your OS pkg manager instead.  In any case, a reference to the official documentation is always provided, which includes instructions for other distros as well.  However, make sure that by the end of the installation, you are running **the latest version** of both programs.  Otherwise, you will run into issues with the TVHlink integration.

## TVHeadned
&gt; Tvheadend is a TV streaming server for Linux supporting DVB-S, DVB-S2, DVB-C, DVB-T, ATSC, IPTV,SAT&gt;IP and other formats through the unix pipe as input sources.

The goal of this section is to cover the **installation** and **basic configuration** of a TVH server in order to use the TVHlink integration.  Therefore, tuners, drivers, and electronic program guide (EPG) data usage won't be covered here, even though they are all supported by a TVH server.  Fortunately, the configuration of such aspects and the TVHlink integration are **not** mutually exclusive--that is, you can configure your tuners and EPG data however you like after implementing the TVHlink integration. Similarly, if you use IPTV services, you can also run them in parallel to the TVHlink integration.

### Concepts
In addition to the [client-server flow](#client-server-flow) illustrated before, there are four key concepts related to how TVH organizes its content--namely, the notions of **networks**, **muxes**, **services**, and **channels**.  In brief, a network is composed of one or more muxes, which define services that are mapped onto channels.  

In the TVHlink and IPTV context, a *network* defines a meaningful `m3u` playlist (e.g., a livestreaming platform, like Youtube or Twitch) or the name of the IPTV service provider.  The `m3u` playlist contain *tracks*, which are translated into *muxes* in TVH lingo.  A mux carries and defines properties of each track, such as its name, icon, EPG source, provider, and so on.  Once a mux is verified to contain valid streaming data, it creates a corresponding *service*, and services are then mapped onto specific *channels* that will be accessible to a TVH client.  

The mapping of services onto channels is usually manual.  However, in this guide, we use *bouquets* to automatically map services to channels and generate their tags.  In the TVHlink/IPTV context, bouquets are just meaningful channel groupings with customized settings.

### Installation
Here is a list of various installation procedures.  Read the notes before following the official installation procedure.  Whatever method you choose, *after the installation*, check that your TVH server is either version `4.3` or higher.  Otherwise, review your installation or choose a different method because you are using an outdated version and compatibility is uncertain.

#### Host installation
* [Install on host Linux machine via APT](https://tvheadend.org/projects/tvheadend/wiki/AptRepositories): Suitable for Debian and Debian-based distros (e.g., Raspberry Pi OS, Ubuntu).  This is the recommended procedure for compatible devices because it allows you to keep your TVH updated via APT along with the other installed packages on your OS.

  In the **apt source** for tvheadend (`/etc/apt/sources.list.d/tvheadend.list`), use the **[Unstable](https://apt.tvheadend.org/unstable/)** repository instead of the Stable one. The latter is too outdated.
  {:.notice .notice--warning}

  **Before** running `sudo apt install tvheadend`, check the repo's package version with `sudo apt policy tvheadend`.  The package version must be `4.3*` or higher.  If it's not, double check your installation procedure or use a different installation method (see below).
  {:.notice .notice--warning}

  Specific package versions can be installed via `sudo apt install tvheadend=&lt;version&gt;`, in which `&lt;version&gt;` is an exact match to a repo's valid version (version table avaliable with `sudo apt policy tvheadend`). This is useful if the candidate version (i.e., what would be installed by defeault) is not the latest one.
  {:.notice .notice--info}

* [Install on host Linux machine via RPM](https://tvheadend.org/projects/tvheadend/wiki/RpmRepository): Suitable for Fedora and CentOS.
  
  In the `config-manager` command, add either the **[Fedora Unstable](https://dl.bintray.com/tvheadend/fedora/:bintray-tvheadend-fedora-unstable.repo)** (if FedoraOS) or the **[CentOS Unstable](https://dl.bintray.com/tvheadend/centos/bintray-tvheadend-centos-unstable.repo)** (if CentOS) repository instead of the other ones.  The other repos contain outdated releases.
  {:.notice .notice--warning}

* [Install on host Linux machine from the Github source](https://tvheadend.org/projects/tvheadend/wiki/Building): *Alternative* to using the APT/RPM repositories.  It takes some time to build from the source because dependencies and conflits have to be fixed manually and it's much harder to keep TVH updated this way.

  Always build from the `master` branch of the Github repo.
  {:.notice .notice--warning}

#### Docker installation
* [Install as a Docker Container with the LinuxServer image](https://docs.linuxserver.io/images/docker-tvheadend): *Alternative* to anyone who is not running a Linux host, for example, or already have other Dockerized services up and running.  The image is provided by an unofficial but well-known source--namely, [LinuxServer](https://www.linuxserver.io/).  The TVHlink integration is **non-trivial** because the container does not include Streamlink by default.  However, I've covered this in the section about [running Streamlink in a TVH Docker container](#docker-installation-1).  In short, it uses [custom script execution](https://blog.linuxserver.io/2019/09/14/customizing-our-containers/#custom-scripts) to install and update Streamlink in the container.

  Use the `latest` image tag for your architecture. This is the default, so you should not need to change anything to pull the right image.
  {:.notice .notice--warning}

### Basic configuration
1. Open a web-browser and navigate to the **TVH webUI**. If the web-browser is running on the same host as TVH, then the webUI will be at **[http://127.0.0.1:9981](http://127.0.0.1:9981)**; Otherwise, it will be at `http://HOST_IP:9981`, in which `HOST_IP` is the IP address of the machine hosting the TVH server.
  
    It goes without saying that the machine hosting the TVH server should have a **fixed IP address** at the local network because all the clients will be pointing to it.
    {:.notice .notice--info}

2. If you provided admin credentials during the installation, you will be prompted to enter the credentials now.

3. TVH will start **the wizard** the first time you access the webUI but go ahead and skip it altogether:
   ```
   # Press Cancel
   ```

4. Notice that there are several tabs in the webUI but many options will not show up if the **View level** is set to `Basic`. Change it to `Expert`, as follows: 
   ```
   # Configuration &gt; General &gt; Base &gt; Web Interface Settings &gt; Default view level
   ```
   ```
   # Press Save
   ```

   [![TVH config 01](/assets/posts/2021-01-17-Tvhlink/tvh-config01.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-config01.jpg)

5. *Optional.* In the same tab as before, change the **Authentication type** to `Both plain and digest` to make the TVH server compatible with more clients than before.  (VLC, for example, is unable to authenticate if type is set to `Digest`.)
   ```
   # Configuration &gt; General &gt; Base &gt; HTTP Server Settings &gt; Authentication type
   ```
   ```
   # Press Save
   ```

   [![TVH config 02](/assets/posts/2021-01-17-Tvhlink/tvh-config02.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-config02.jpg)

   **Note on exposing TVH to WAN**. This configuration allows clients to send all their credentials *in plain text*.  This is *not a problem* if your TVH server is only used locally.  However, *this is a problem* if your TVH server is reachable outside your private network because the credentials will be accessible to anyone able to intercept the packets between client and server--you should always assume that this is the case when sending packets over the WAN.  If you want to use your TVH server remotely, my suggestion is to either use (a) vpn or (b) wireguard or (c) ssh tunnel (key-based auth) or (d) a reverse proxy with SSL termination (TLS) and independent and hardened credentials.
   {:.notice .notice--danger}

6. Clients can access TVH using the same credentials as you (admin access). However, as a general rule of thumb, that is not a good practice. Also, if you have multiple clients, it is nice to know what each one is trying to access on your TVH server.  To create a single **user** called `client` with password `client` and permission to only access streaming, do the following:
   ```
   # Configuration &gt; Users &gt; Access Entries &gt; Add
   ```
   Then in the **Add Access Entry** window:
   ```
   # Enabled: Checked
   # Username: client
   # Streaming: Basic,Advanced,HTSP
   # Comment: default streaming client user
   ```
   ```
   # Press Create
   ```

   [![TVH config 03](/assets/posts/2021-01-17-Tvhlink/tvh-config03.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-config03.jpg)

   Now create a **password** for the `client` user:
   ```
   # Configuration &gt; Users &gt; Passwords &gt; Add
   ```
   Then in the **Add Password** window:
   ```
   # Enabled: Checked
   # Username: client
   # Password: client
   # Comment: default streaming client password
   ```
   ```
   # Press Create
   ```

   [![TVH config 04](/assets/posts/2021-01-17-Tvhlink/tvh-config04.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-config04.jpg)

   If you want to **add more users**, just repeat this step as many times as necessary.

7. *Optional.* By default, TVH will attempt to grab EPG data from any channel added to it at start-up.  In the TVHlink context, however, EPG data either don't make sense or there is no simple way of grabbing them. 
   
   Because some of the 24/7 news channels actually follow the same EPG as their Cable/Satellite broadcast, it is possible to use EPG tools like [WebGrab+Plus](http://webgrabplus.com/) to configure TVH to use them.  However, this is way beyond the scope of this tutorial.
   {:.notice .notice--info}

   Therefore, you can safely **disable automatic EPG grabbing at start-up**, as follows:
   ```
   # Configuration &gt; Channel / EPG &gt; EPG Grabber
   # Uncheck all 'grab at start-up' options
   ```
   ```
   # Press Save
   ```

   [![TVH config 05](/assets/posts/2021-01-17-Tvhlink/tvh-config05.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-config05.jpg)

   In addition, because you won't be using any tuner for the TVHlink integration, you can also **disable all EPG Grabber Modules**, as follows:
   ```
   # Configuration &gt; Channel / EPG &gt; EPG Grabber Modules
   # For each enabled module (green icon), make sure enabled is unchecked (red icon)
   ```
   ```
   # Press Save
   ```

   [![TVH config 06](/assets/posts/2021-01-17-Tvhlink/tvh-config06.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-config06.jpg)

8. That is it. There are [many other things you can do configuration-wise](https://tvheadend.org/projects/tvheadend/wiki/Documentation) but the ones covered are sufficient for the TVHlink integration.  Other things you might want to take a look at are the **[recording](https://docs.tvheadend.org/webui/config_dvr/)** settings and **[stream profiles](https://docs.tvheadend.org/webui/config_streamprofile/)**. 

## Streamlink
&gt; Streamlink is a command-line utility which pipes video streams from various services into a video player, such as VLC. The main purpose of Streamlink is to avoid resource-heavy and unoptimized websites, while still allowing the user to enjoy various streamed content.

This is an awesome Python utility and if you have never used it before, make sure to check their **[documentation](https://streamlink.github.io/)**.  In the TVHlink context, it is used to pipe data from a livestream channel to a TVH server, as [illustrated in the client-server flow](#client-server-flow).  

Streamlink has plugins for most of the major streaming platforms (Youtube, Twitch, Dailymotion, etc.) as well as a few specific websites (CBS News, NBC News, Reuters, etc.).  For an exhaustive list of the available plugins, check their [plugin matrix](https://streamlink.github.io/plugin_matrix.html#plugins).

### Installation
The official docs contain detailed instructions about [how to install Streamlink on a variety of platforms](https://streamlink.github.io/install.html).  However, a few of the package repositories contain **outdated versions** of the Streamlink utility.  If you choose to install via `apt`, `pacman`, `dnf`, and other common Linux distro package manager, make sure to install Streamlink version `2.0` or higher.  In my experience, keeping Streamlink up-to-date is more important than the TVH server because the former is more prone to changes than the latter, owning to required fixes/updates to content parsers.

Once installed, you can find the version by running 
```
streamlink --version
```
which should be at least `2.0` or higher, as mentioned before.  You can find the latest version number and a summary of the changes on their **[Releases page](https://github.com/streamlink/streamlink/releases)**.

#### Host installation
* [Install on host Linux or BSD machine via the system's package manager](https://streamlink.github.io/install.html#linux-and-bsd): At the time this tutorial was originally published, this was compatible with Arch, Debian, Fedora, Gentoo, NetBSD, NixOS, OpenBSD, Solus, Ubuntu, and Void.  This is the recommended procedure for compatible devices because it allows you to keep your Streamlink updated along with other packages installed on your OS.

* [Install via Python's package manager, `pip`](https://streamlink.github.io/install.html#pypi-package-and-source-code): *Alternative* to other installation methods when Streamlink is not available in the system's package manager or the version is outdated. This offers the highest cross-plataform compatibility--that is, as long as you can install Python, you can install Streamlink this way.

  Starting Streamlink version `2.*`, the utility is only compatible with **Python 3** (and I strongly recommend to use Python `3.7` or higher).  Therefore, first, install `python3` and its package manager, `python3-pip`.  Then, install Streamlink via `pip3` to make sure it is installed as a Python 3 package instead of Python 2.
  {:.notice .notice--warning}

  On Linux distributions, Python's package manager will install user-related packages on the user's `$HOME/.local/bin` directory, which by default, is not part of the user's `$PATH`.  This means that if you try to run `streamlink` after a `pip3 install --user streamlink` install, for example, your shell might not find the executable.  To fix this, you need to add `$HOME/.local/bin` to your user's `$PATH` as follows:
  ```
  echo &quot;export &quot;PATH=$HOME/.local/bin:$PATH&quot;&quot; | tee -a &quot;$HOME/.profile&quot; &gt; /dev/null
  ```
  Then logoff and back on to apply the changes.

#### Docker installation
* [Install on the LinuxServer TVH docker container](https://github.com/cgomesu/tvhlink/blob/master/tools/docker/streamlink_for_tvh_container.sh): **Required for containerized TVH server installations** because by deafult, the LinuxServer TVH container does not include Streamlink.  I created a repo called **[tvhlink](https://github.com/cgomesu/tvhlink)** where I wrote a script to handle the automatic installation and update of the Streamlink utility via LinuxServer's [custom script execution feature](https://blog.linuxserver.io/2019/09/14/customizing-our-containers/#custom-scripts).  To use it, do the following:

  1. **Install git** on the docker *host machine* (*not* the container):
    ```
    sudo apt update &amp;&amp; sudo apt install git
    ```
  
  2. **Clone the tvhlink repo** to `/opt`:
    ```
    cd /opt &amp;&amp; sudo git clone https://github.com/cgomesu/tvhlink.git
    ```
  
  3. Go to your TVH container's `/config` directory (edit `&lt;TVH_CONTAINER&gt;` below before running the command; this is the dir where the TVH's `/config` subdir is) and **create a new dir** called `custom-cont-init.d`. Any scripts in this dir are automatically executed at the container's start-up:
    ```
    cd &lt;TVH_CONTAINER&gt;/config &amp;&amp; sudo mkdir custom-cont-init.d
    ```
  
  4. **Copy** the `streamlink_for_tvh_container.sh` script from the `tvhlink` repo to the new `custom-cont-init.d` dir:
    ```
    sudo cp /opt/tvhlink/tools/docker/streamlink_for_tvh_container.sh custom-cont-init.d/
    ```
  
  5. **Fix the dir and script ownership** to match the `PUID` (e.g., `1010`) and `PGID` (e.g., `100`) of your TVH container (edit the values before running the command below; if uncertain, then type `id &lt;TVH_USER&gt;`, in which `&lt;TVH_USER&gt;` is the user running the TVH container):
    ```
    sudo chown -R 1010:100 custom-cont-init.d/
    ```
  
  6. **Restart your TVH container** and the script should automatically install and update Streamlink at every startup.  Check the logs for any `[TVHlink]` messages.  If you don't see any, just **recreate the container** and wait until it's done installing--it can take a few minutes.

     Because the script is in the `/config` dir, it should persist after a TVH container update and will automatically be triggered at start-up to reinstall the required packages and Streamlink.  If you notice it's broken, check the [tvhlink repo](https://github.com/cgomesu/tvhlink) for an update or open an issue to let me know about it.  The script also updates Streamlink after it has been installed, so it makes sure your container is always runnig the latest version of it.  However, the script only triggers at start-up, so it will only try to update Streamlink then.  Therefore, if there's a [new Streamlink release](https://github.com/streamlink/streamlink/releases/) and you want to update it in the TVH container, simply restart the container and the script should take care of it.  (The script uses Python's package manager, `pip`, so it will only install the latest version available there.)
     {:.notice .notice--warning}
  
  For other TVH docker images, either go to my [tvhlink repo](https://github.com/cgomesu/tvhlink) and open an issue to request support or you will need to install Streamlink manually and then disable automatic container updates.
  {:.notice .notice--info}

### Standalone usage
After installing Streamlink, you should be able to run it by itself with
```
streamlink [OPTIONS] &lt;URL&gt; [STREAM]
```
in which `&lt;URL&gt;` is a livestreaming channel (e.g., *Explore Live Nature Cams* Youtube channel: [https://www.youtube.com/channel/UC-2KSeUU5SMCX6XLRD-AEvw](https://www.youtube.com/channel/UC-2KSeUU5SMCX6XLRD-AEvw)) or [a parsable website](https://streamlink.github.io/plugin_matrix.html) URL; and `[STREAM]` is a streaming quality profile (e.g., `worst`, `best`, `720p`, `360p`)--if you omit the latter, `streamlink` will show a list of all available profiles for the given `&lt;URL&gt;`.  You can find a complete list of additional options (`[OPTIONS]`) with the `--help` usage argument, as follows:
```
streamlink --help
```
Streamlink is compatible with multiple popular video players, such as [VLC](https://videolan.org/) and [MPV](https://mpv.io/).  For a non-exhaustive compatibility list and their transport modes, check the [official player compatibility table](https://streamlink.github.io/players.html#player-compatibility).

[top](#){:.btn .btn--light-outline .btn--small}


# TVHlink
Now that you have installed both TVH and Streamlink, the TVHlink integration is rather trivial.  In fact, the only difference between its implementation and the implementation of any IPTV is that in the configuration of each *mux* in the TVH server, we will be using a `pipe://` command with our `streamlink` utility, instead of pointing it to an external `MPEG-TS` or similar file.

## Single livestream channel
To add a single livestream channel to your TVH server, first, you need to manually create an IPTV network and then add muxes to it.  We will configure the network to automatically create services for the muxes, instead of scanning them one by one, and then enable a bouquet to automatically map services to channels.
1. Open your TVH webUI and go to the **Networks** tab of your TV inputs settings:
   ```
   # Configuration &gt; DVB Inputs &gt; Networks
   ```
2. Create a **new network** called `Youtube`:
   ```
   # Press Add
   ```
   In the **Add Network** window, select the following:
   ```
   # Type: IPTV Network
   ```
   
   [![TVHlink config 01](/assets/posts/2021-01-17-Tvhlink/tvhlink-config01.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvhlink-config01.jpg)

   Now, in the **Add IPTV Network** window, change the following:
   ```
   # Enabled: Checked
   # Network name: Youtube
   # Create bouquet: Checked
   # Provider name: Youtube
   # Ignore provider's channel numbers: Checked
   # Character set: UTF-8
   # Scan after creation: Unchecked
   # Skip startup scan: Checked
   # Service ID: 1
   ```
   ```
   # Press Create
   ```
   
   [![TVHlink config 02](/assets/posts/2021-01-17-Tvhlink/tvhlink-config02.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvhlink-config02.jpg)

3. Create a **new mux** called `France 24 English`:
   ```
   # Configuration &gt; DVB Inputs &gt; Muxes
   ```
   ```
   # Press Add
   ```
   and in **Add Mux** window, select the following:
   ```
   # Network: Youtube
   ```
   
   [![TVHlink config 03](/assets/posts/2021-01-17-Tvhlink/tvhlink-config03.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvhlink-config03.jpg)

   Then, change the following settings:
   ```
   # Enabled: Enable
   # EPG scan: Disabled
   # URL: pipe:///usr/bin/env streamlink --stdout --default-stream best --url https://www.youtube.com/user/france24english
   # Mux name: Youtube - France 24 English
   # Channel number: 1
   # Service name: France 24 English
   # Icon URL: https://yt3.ggpht.com/ytc/AAUvwnjQokqv8-b-XLH34XJulaY0W27AzlCmyeEY7TayMw=s176-c-k-c0x00ffffff-no-rj
   # Channel tags: News
   # Accept zero value for TSID: Checked
   ```
   ```
   # Press Create
   ```
   
   [![TVHlink config 04](/assets/posts/2021-01-17-Tvhlink/tvhlink-config04.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvhlink-config04.jpg)

   Notice the `pipe://` command in *URL*. In brief, it tells your TVH server to call `streamlink` with the options:
   * `--stdout`: Output the stream data to `stdout`, which will be read by your TVH server
   * `--default-stream`: Stream quality, which is `best` but could be `720p`, `480p`, or whatever is acceptable by the source (Youtube)
   * `--url`: France 24 English Youtube channel URL. Sometimes, this will be the channelID instead of an alias.

   It is possible to include additional options but these are both necessary and sufficient to get the TVHlink integration working.  Also, I tend to use the *Icon URL* from the official Youtube channels because the address has proved to be quite reliable and the image format is perfect for what we are doing.  Lastly, *Channel tags* are optional but it will help your clients finding what they want more efficiently.

4. Open the **Tvheadend log** window in the webUI (at the bottom) and check that the TVH is correctly requesting and reading data from `streamlink`.  If it is, you should see something like this:

   [![TVH Kodi config 05](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config05.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config05.jpg)

   ```
   2021-01-21 10:31:51.171 bouquet: new bouquet 'Youtube'
   2021-01-21 10:55:26.380 mpegts: Youtube - France 24 English in Youtube - tuning on IPTV #1
   2021-01-21 10:55:26.381 subscription: 0001: &quot;scan&quot; subscribing to mux &quot;Youtube - France 24 English&quot;, weight: 5, adapter: &quot;IPTV #1&quot;, network: &quot;Youtube&quot;, service: &quot;Raw PID Subscription&quot;
   2021-01-21 10:55:26.381 spawn: Executing &quot;/usr/bin/env&quot;
   2021-01-21 10:55:27.575 spawn: [cli][info] Found matching plugin youtube for URL https://www.youtube.com/user/france24english
   2021-01-21 10:55:30.524 spawn: [cli][info] Available streams: 144p (worst), 240p, 360p, 480p, 720p, 1080p (best)
   2021-01-21 10:55:30.524 spawn: [cli][info] Opening stream: 1080p (hls)
   2021-01-21 10:55:41.380 mpegts: Youtube - France 24 English in Youtube scan complete
   2021-01-21 10:55:41.380 subscription: 0001: &quot;scan&quot; unsubscribing
   ```
   And in the *Scan result* of the mux, you should now see a `OK` status, which means we can configure the bouquet to automap the service to a channel that any TVH client will be able to watch.

5. Enable the `Youtube` **bouquet**, as follows:
   ```
   # Configuration &gt; Channel / EPG &gt; Bouquets
   ```
   Scroll down until you find `Youtube` and enable it:
   ```
   # Enabled: Checked
   ```
   ```
   # Press Save
   ```
   
   [![TVHlink config 05](/assets/posts/2021-01-17-Tvhlink/tvhlink-config05.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvhlink-config05.jpg)
   
   And in the **Tvheadend log**, you should see a message confirming that the service was mapped:
   ```
   2021-01-21 11:02:41.575 bouquet: Youtube/Youtube - France 24 English/{PMT:0}: mapped service from Youtube
   ```
   which will then show up in the **Channels** tab:

   [![TVHlink config 06](/assets/posts/2021-01-17-Tvhlink/tvhlink-config06.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvhlink-config06.jpg)

6. To test your new channel using the webUI itself, do the following:
   ```
   # Electronic Program Guide &gt; Watch TV
   ```
   ```
   # Select channel: 1 France 24 English
   ```
   The webUI playback is not very reliable because lots of things depend on the web-browser you are using and how it handles the video playback.  (In other words, even if you're unable to see the video or hear the sound using the webUI, chances are the stream is working just fine when using a *proper video player*.)  If you really want to test the connection at this point, then skip to the [TVH clients](#tvh-clients) section and use one of the methods described there.

## Automatic network of livestream channels
If you were paying attention to the IPTV network creation step described before, you might have noticed that there is an **IPTV Automatic Network** option in the network *Type*.  In this type of network, we **import** an external `m3u` file to the TVH server and it reads its *tracks* as *muxes*, which means that we don't need to create muxes one by one.  The drawback is that you need to know the `m3u` syntax in order to build one yourself or find someone who has already done that for you and made the file available.  In this section, I will describe both alternatives.

### Building m3u playlists
Anyone can create and edit `m3u` playlists using any simple text editor, such as Pluma, `nano`, `vi`, Vim, and so on.  For example, open a text editor of your choice and copy and paste the following:
```
#EXTM3U
#EXTINF:-1 tvg-name=&quot;France 24 English&quot; tvg-language=&quot;English&quot; tvg-country=&quot;FR&quot; tvg-logo=&quot;https://yt3.ggpht.com/ytc/AAUvwnjQokqv8-b-XLH34XJulaY0W27AzlCmyeEY7TayMw=s176-c-k-c0x00ffffff-no-rj-mo&quot; group-title=&quot;News&quot;,France 24 English
pipe:///usr/bin/env streamlink --stdout --default-stream 720p,best --url https://www.youtube.com/user/france24english
#EXTINF:-1 tvg-name=&quot;France 24&quot; tvg-language=&quot;French&quot; tvg-country=&quot;FR&quot; tvg-logo=&quot;https://yt3.ggpht.com/ytc/AAUvwngwSBIFO5UNdycjzkUjIRFEq0n5YWKTOgsfbgKdoQ=s176-c-k-c0x00ffffff-no-rj-mo&quot; group-title=&quot;News&quot;,France 24
pipe:///usr/bin/env streamlink --stdout --default-stream 720p,best --url https://www.youtube.com/user/france24
#EXTINF:-1 tvg-name=&quot;DW English&quot; tvg-language=&quot;English&quot; tvg-country=&quot;DE&quot; tvg-logo=&quot;https://yt3.ggpht.com/ytc/AAUvwngnDcvUkm6jCn6TEENsvO8bdy60g-T4lCgUWOyemCs=s176-c-k-c0x00ffffff-no-rj-mo&quot; group-title=&quot;News&quot;,DW English
pipe:///usr/bin/env streamlink --stdout --default-stream 720p,best --url https://www.youtube.com/user/deutschewelleenglish
#EXTINF:-1 tvg-name=&quot;DW Deutsch&quot; tvg-language=&quot;German&quot; tvg-country=&quot;DE&quot; tvg-logo=&quot;https://yt3.ggpht.com/ytc/AAUvwnhXY-iIvV4naxL4WWuS_JQKOqfjqwSgzMswGp4aJUc=s176-c-k-c0x00ffffff-no-rj-mo&quot; group-title=&quot;News&quot;,DW Deutsch
pipe:///usr/bin/env streamlink --stdout --default-stream 720p,best --url https://www.youtube.com/user/deutschewelle
#EXTINF:-1 tvg-name=&quot;Euronews English&quot; tvg-language=&quot;English&quot; tvg-country=&quot;FR&quot; tvg-logo=&quot;https://yt3.ggpht.com/ytc/AAUvwnja_dPZdy_el5IhBkj9BJUAd29fZzSs4-vaws_uPLw=s176-c-k-c0x00ffffff-no-rj-mo&quot; group-title=&quot;News&quot;,Euronews English
pipe:///usr/bin/env streamlink --stdout --default-stream 720p,best --url https://www.youtube.com/user/Euronews
#EXTINF:-1 tvg-name=&quot;Euronews Spanish&quot; tvg-language=&quot;Spanish&quot; tvg-country=&quot;FR&quot; tvg-logo=&quot;https://yt3.ggpht.com/ytc/AAUvwnh8LYxyL6VKfHAGYV0qCJ4hqaWDO5GympC7lRIViw=s176-c-k-c0x00ffffff-no-rj-mo&quot; group-title=&quot;News&quot;,Euronews Spanish
pipe:///usr/bin/env streamlink --stdout --default-stream 720p,best --url https://www.youtube.com/user/euronewses
#EXTINF:-1 tvg-name=&quot;Euronews Portuguese&quot; tvg-language=&quot;Portuguese&quot; tvg-country=&quot;FR&quot; tvg-logo=&quot;https://yt3.ggpht.com/ytc/AAUvwngxE0l-vGHBafT-fP7WfCq_Xo7QfDLATRspf0agKA=s176-c-k-c0x00ffffff-no-rj-mo&quot; group-title=&quot;News&quot;,Euronews Portuguese
pipe:///usr/bin/env streamlink --stdout --default-stream 720p,best --url https://www.youtube.com/user/euronewspt
```
Then, observe that

1. The first row always contains `#EXTM3U` to identify this file as being an `m3u` playlist;

2. The remaining rows contain two distinct rows, namely (a) one starting with `#EXTINF:` that defines properties of a mux, and (b) another immediately below it that contains the `pipe://` command to request the stream data.

Regarding the `#EXTINF:` row, the `-1` next to it simply indicates that this *track* has infinite length; the meaning of the other variables is quite intuitive. Of note, however, I've ommitted the `tvg-id` variable that is often found in such files because it has no useful meaning outside the context of EPG data.  If you choose to play around with EPG, then you might want to add one that matches the channel's `id` in a given EPG data provider, for example.

As long as you follow the structure in the example, you can add as many livestreaming channels as you want.  When you are done, you can import your `m3u` playlist to the TVH server as follows:

1. **Save your `m3u` playlist** with the name `youtube.m3u` on a dir **accessible to your TVH server**. In Dockerized installations, I suggest to create a subdir on the container's appdata (next to its `/config` dir, for example) and in the container's settings, add a new volume bind pointing to the new dir you created. Make sure to fix permissions, so that the new dir and `m3u` files match the `PUID` and `PGID` of the TVH server;

2. Open your TVH webUI and naviagate to the **Networks** tab:
   ```
   # Configuration &gt; DVB Inputs &gt; Networks
   ```

3. Create a **new network** called `Youtube Auto`:
   ```
   # Press Add
   ```
   In the **Add Network** window, select the following:
   ```
   # Type: IPTV Automatic Network
   ```

   Now, in the **Add IPTV Network** window, change the following:
   ```
   # Enabled: Checked
   # Network name: Youtube Auto
   # Create bouquet: Checked
   # URL: file:///full/path/to/youtube.m3u
   # Channel numbers from: 101
   # Accept zero value for TSID: Checked
   # Provider name: Youtube
   # Ignore provider's channel numbers: Checked
   # Character set: UTF-8
   # Scan after creation: Unchecked
   # Content character set: UTF-8
   # Skip startup scan: Checked
   # Service ID: 1
   ```
   ```
   # Press Create
   ```

  [![TVHlink config 07](/assets/posts/2021-01-17-Tvhlink/tvhlink-config07.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvhlink-config07.jpg)

4. Enable the `Youtube Auto` **bouquet**, as follows:
   ```
   # Configuration &gt; Channel / EPG &gt; Bouquets
   ```
   Scroll down until you find `Youtube Auto` and enable it:
   ```
   # Enabled: Checked
   ```
   ```
   # Press Save
   ```
   which should map all services to channels in the **Channels** tab:

6. To test your new channels using the webUI itself, do the following:
   ```
   # Electronic Program Guide &gt; Watch TV
   ```

7. That is it!  You have learned how to build and import a customized `m3u` playlist of livestreams to your TVH server.  If you think this is a lot of work, check the following section then.

### Curated m3u playlists
I create a Github repository called **[tvhlink](https://github.com/cgomesu/tvhlink)** that contains [tools](https://github.com/cgomesu/tvhlink/tree/master/tools) and [`m3u` playlists](https://github.com/cgomesu/tvhlink/tree/master/m3u) I personally use for my TVHlink integration.  You are all welcome to use my `m3u` playlists and contribute to keep them up-to-date ([fork, make changes, push commits, and submit a PR with a description of what and why](https://akrabat.com/the-beginners-guide-to-contributing-to-a-github-project/)).

To add one of my curated `m3u` playlists to your TVH server, follow the same steps as in the previous section, with the following exceptions:

* You **do not need to save any playlist locally**, unless you want to edit them before importing to the TVH server.  Instead, you can tell your TVH server to automatically **fetch from the tvhlink repo**, as follows:
  * In the **Add IPTV Automatic Network** copy and paste the following on the *URL* option to fetch my `youtube.m3u` playlist:

     ```
     https://raw.githubusercontent.com/cgomesu/tvhlink/master/m3u/youtube.m3u
     ```
     
     or alternatively, my `direct.m3u` playlist:

     ```
     https://raw.githubusercontent.com/cgomesu/tvhlink/master/m3u/direct.m3u
     ```

That is it! Your TVH server will automatically check the **tvhlink** repo every hour for changes and if detected, it will update all your channels accordingly.

[top](#){:.btn .btn--light-outline .btn--small}


# TVH clients
Now that there is a TVH server up and running with the TVHlink integration enabled, you should configure at least one TVH *client* for testing purpose.  There are [multiple ways to watch the channels on your TVH server](https://tvheadend.org/projects/tvheadend/wiki/Clients), including directly from the **TVH webUI** itself:
```
# Electronic Program Guide &gt; Watch TV
```

[![TVH webUI config 01](/assets/posts/2021-01-17-Tvhlink/tvh-webui-config01.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-webui-config01.jpg)

The webUI player uses a very specific streaming profile though, and because it requires access to the webUI, it's not possible to test the `client` user this way (because it doesn't have permission to access the webUI).

There are clients (apps) for **iOS** and **Android**, for example.  They can be clients developed *for* a TVH server--such as Robert's [TVHClient](https://play.google.com/store/apps/details?id=org.tvheadend.tvhclient) for Android or Luis' [TvhClient](https://apps.apple.com/us/app/tvhclient/id638900112) for iOS--or general use *IPTV players*.  The latter works because the TVH server can provide a parsable `m3u` file to such players--see the section about the [VLC player](#vlc-player) for an example of how to obtain such file.

Here, however, I will show how to configure my two preferred clients.  Specifically, the **[Kodi PVR addon](#tvh-kodi-pvr-addon)** and **[VLC and other `m3u` players](#vlc-and-other-m3u-players)**. 

## TVH Kodi PVR addon
The [TVH HTSP client addon](https://kodi.wiki/view/addon:Tvheadend_HTSP_Client) for the [**Kodi Media Center**](https://kodi.tv/download) is *by far* my favorite client.  It uses the proper protocol for streaming (HTSP) and has **predictive tuning**, which makes the channel transitions very smooth because it loads neighboring channels in advance, threfore reducing the initial livestream request time (but this also greatly incrases bandwidth usage).

You can install Kodi on pretty much any OS.  The [official Kodi website](https://kodi.tv/) provides a variety of installation packages to [download](https://kodi.tv/download) and you will find a *HOW-TO* button for each one of them. Choose one of them and follow the installation instructions.  When you are done, come back to see **how to install the [TVH PVR addon](https://kodi.wiki/view/addon:Tvheadend_HTSP_Client)**.

1. To install the PVR addon, open Kodi and try to install via the **official repo**:
   ```
   # Addons &gt; Install from repo &gt; PVR clients
   ```

   [![TVH Kodi config 01](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config01.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config01.jpg)

2. **If you find** the `PVR clients` option, then select it, then select `Tvheadend HTSP Client` and install it.  However, if you **do not find** the `PVR clients` option, this means the PVR clients binary was not packaged with your Kodi version, which happens with a few `apt`-based distributions.  The solution is to manually install the missing addon.  Close Kodi and open a terminal, then with a `sudo` user, type the following:
   ```
   sudo apt update &amp;&amp; sudo apt install kodi-pvr-hts
   ```
   Restart Kodi and the `PVR clients` option should be available and will contain the `Tvheadend HTSP Client` installed.

   [![TVH Kodi config 02](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config02.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config02.jpg)

   Another option to install a missing addon is to download a `.zip` of it from a public website and in the Kodi addons tab, choose `install from zip`.  However, do not go around installing addons from random websites.  **Do your research first**.  Unofficial addons can contain all sorts of bad stuff.
   {:.notice .notice--info}

3. Now, to configure the PVR addon, do the following:
   ```
   # Addons &gt; My addons &gt; PVR clients &gt; Tvheadend HTSP Client &gt; Configure
   ```
   and in the **Connection settings** tab, change the following:
   ```
   # IP address: &lt;IP of the machine hosting the TVH server&gt;
   # HTTP port: 9981
   # HTSP port: 9982
   # Username: client
   # Password: client
   ```

   [![TVH Kodi config 03](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config03.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config03.jpg)

   and in the **Streaming settings**, change the following:
   ```
   # Profile to use: htsp
   # Use predictive tuning: Enabled
   # Number of subscriptions: 3
   # Unused subscription delay: 50
   ```
   ```
   # Press OK
   ```

   [![TVH Kodi config 04](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config04.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config04.jpg)

4. Every time you change the client configuration, you will be required to **restart Kodi** to see the changes.  So, restart your Kodi now. Once it comes back, all the channels will show up in
   ```
   # TV &gt; Channels
   ```

5. Go ahead and test a few of them.  If you want to debug the connection, open a web-browser and navigate to your TVH webUI.  At the bottom of the webUI, there's a button to open the TVH log.  Press the buttom and see the log updates live.

   [![TVH Kodi config 05](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config05.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config05.jpg)

   [![TVH Kodi config 06](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config06.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-kodi-config06.jpg)

6. Lastly, **additional Kodi PVR settings** can be changed in
   ```
   # Settings &gt; PVR &amp; Live TV settings
   ```

7. That is it!  Enjoy your TVHlink integration.

## VLC and other m3u players
&gt; VLC media player (previously the VideoLAN Client and commonly known as simply VLC) is a free and open-source, portable, cross-platform media player software, and streaming media server developed by the VideoLAN project. VLC is available for desktop operating systems, and mobile platforms, such as Android, iOS, iPadOS, Tizen, Windows 10 Mobile, and Windows Phone. VLC is also available on digital distribution platforms such as Apple's App Store, Google Play, and Microsoft Store. 

The VLC player is available to a variety of platforms and can be [downloaded from the official website](https://www.videolan.org/vlc/#download).

There is an [unofficial TVH HTSP plugin for VLC](https://github.com/BtbN/vlc-htsp-plugin) but the repository has been archived and according to the author:
&gt; I am no longer working on this (..). Also, if you export an m3u playlist of your channels from tvh, and open it in VLC, you have the same set of features this plugin offers, just without all the weird bugs.

Fortunately, it is very easy to export your TVH channels `m3u` playlist and use it with the VLC player or any other `m3u` capable player:

1. Open a web-browser and navigate to your TVH webUI;

2. Append `/playlist` to the TVH webUI address, as follows:
   ```
   http://TVH_HOST_IP:9981/playlist
   ```

   [![TVH VLC config 01](/assets/posts/2021-01-17-Tvhlink/tvh-vlc-config01.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-vlc-config01.jpg)

3. This will request an `m3u` playlist from your TVH server called `channels`.  It contains all currently configured channels from your server.  **Save it** on a directory accessible to your VLC player or other `m3u` player.

   If you open the `m3u` playlist with a text editor, you will see that below each `#EXTINF`, there is a network address (`http://...`).  If the address does not contain the IP address of your TVH server host, go ahead and replace them.  Please do not do this manually; use the editor's *find a replace* tool instead.  For example, if your client is not running on the same host as the TVH server, then instead of `http://localhost` or `http://127.0.0.1`, you would want to use `http://TVH_IP`, in which `TVH_IP` is the IP address of the TVH server host in your local network.  When you're done making the changes, just save the `m3u` file.
   {:.notice .notice--warning}

4. Open your VLC player and open the `channels` `m3u` playlist as follows:
   ```
   # Media &gt; Open files
   ```
   Then, in the **Select on or more files to open** window, select *All Files* type, navigate to where you stored the `channels` playlist and open it.

   [![TVH VLC config 02](/assets/posts/2021-01-17-Tvhlink/tvh-vlc-config02.jpg){:.PostImage .PostImage--large}](/assets/posts/2021-01-17-Tvhlink/tvh-vlc-config02.jpg)

5. You should be prompted to authenticate yourself now.  Use your `client` credentials.

6. That is it! Enjoy your TVHlink integration.

[top](#){:.btn .btn--light-outline .btn--small}


# Conclusion
You have reached the end of this tutorial.  If you have not started configuring your TVH server, this is the perfect time to do so.  I have been using this integration for multiple months now and it has been absolutely great.  I strongly recommend it for any cord-cutters out there and in my opinion, it is a *must have* if you already have a TVH server up and running.  

Streamlink v2.0 made the implementation of Youtube channels so much simpler than before and in my experience, Youtube provides the most reliable 24/7 livestream channels (mostly news, webcams, and music).  I am not a big fan of gaming streams in general, so I don't ever watch Twitch streams, for example.  But as pointed out previously, Streamlink has plugins able to parse content from many sources other than Youtube and you are welcome to try them out.

That is it for now.  If you enjoyed or have a few suggestions, [let me know](/contact).  Every once in a while, come back and check the [changelog](#changelog) for updates.

[top](#){:.btn .btn--light-outline .btn--small}</content><author><name>Carlos Gomes</name></author><category term="blog" /><category term="tvhlink" /><category term="streamlink" /><category term="tvheadend" /><category term="github" /><category term="iptv" /><category term="kodi" /><category term="youtube" /><category term="streaming" /><category term="livestream" /></entry><entry><title type="html">Tasmota webcam server for the ESP32-cam</title><link href="/blog/Esp32cam-tasmota-webcam-server/" rel="alternate" type="text/html" title="Tasmota webcam server for the ESP32-cam" /><published>2021-01-15T09:00:00-03:00</published><updated>2021-01-15T09:00:00-03:00</updated><id>/blog/Esp32cam-tasmota-webcam-server</id><content type="html" xml:base="/blog/Esp32cam-tasmota-webcam-server/">&lt;h1 id=&quot;changelog&quot;&gt;Changelog&lt;/h1&gt;
&lt;p class=&quot;notice notice--info&quot;&gt;&lt;strong&gt;Jan 26th, 2021&lt;/strong&gt;: Added an alternative source for the Tasmota32 binaries to the &lt;a href=&quot;#flashing-tasmota32-webcam-server&quot;&gt;Flashing Tasmota32 webcam server&lt;/a&gt; section.  I few individuals reported issues flashing the latest (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;firmware&lt;/code&gt; branch) binaries, so I added a reference to the more stable (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;release-firmware&lt;/code&gt; branch) binaries instead.  A list of currently active branches can be found in the official Github repos &lt;a href=&quot;https://github.com/arendst/Tasmota/branches/active&quot;&gt;active branches&lt;/a&gt; website.&lt;/p&gt;

&lt;p class=&quot;notice notice--info&quot;&gt;&lt;strong&gt;Jan 16th, 2021&lt;/strong&gt;: Publication of the original article&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--light-outline btn--small&quot;&gt;top&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;The ESP32 is a cheap and low-power microcontroller developed by &lt;a href=&quot;https://www.espressif.com&quot;&gt;Espressif&lt;/a&gt;.  In addition to its low-cost, the ESP32 is known for its tiny and robust design, the versatility of its applications, and for having onboard Wi-Fi and Bluetooth.  It is sold world-wide (e.g., &lt;a href=&quot;https://www.amazon.com/s?k=esp32&quot;&gt;Amazon&lt;/a&gt;, &lt;a href=&quot;https://aliexpress.com/wholesale?SearchText=esp32&quot;&gt;Aliexpress&lt;/a&gt;, &lt;a href=&quot;https://lista.mercadolivre.com.br/esp32&quot;&gt;Mercado Livre&lt;/a&gt;) in a variety of boards (e.g., NodeMCU, TTGO, Lolin32).&lt;/p&gt;

&lt;p&gt;In this tutorial, I will talk about one type of ESP32 board that has an &lt;strong&gt;integrated camera module&lt;/strong&gt;, called the &lt;strong&gt;ESP32-cam&lt;/strong&gt;, which can be found for &lt;a href=&quot;https://www.amazon.com/s?k=esp32+cam&amp;amp;s=price-asc-rank&amp;amp;ref=sr_st_price-asc-rank&quot;&gt;less than US$10&lt;/a&gt;.  The goal is to build a cheap alternative to commercial wireless cameras using an open-source firmware that can be easily controlled via HTTP or MQTT and integrated to an existing camera surveillance server (e.g., &lt;a href=&quot;https://github.com/ccrisan/motioneye/&quot;&gt;MotionEye&lt;/a&gt;, &lt;a href=&quot;https://shinobi.video/&quot;&gt;Shinobi&lt;/a&gt;, &lt;a href=&quot;https://www.zoneminder.com/&quot;&gt;ZoneMinder&lt;/a&gt;, &lt;a href=&quot;https://www.ispyconnect.com/&quot;&gt;iSpy&lt;/a&gt;) or multi-purpose automation server (e.g., &lt;a href=&quot;https://www.home-assistant.io/&quot;&gt;HomeAssistant&lt;/a&gt;, &lt;a href=&quot;https://www.openhab.org/&quot;&gt;OpenHAB&lt;/a&gt;, &lt;a href=&quot;https://nodered.org/&quot;&gt;NodeRed&lt;/a&gt;) by capturing its live stream from a simple MJPEG URL.  All that can be accomplished with &lt;strong&gt;&lt;a href=&quot;https://tasmota.github.io/&quot;&gt;Tasmota&lt;/a&gt;&lt;/strong&gt; and its (beta) &lt;strong&gt;&lt;a href=&quot;https://github.com/arendst/Tasmota/tree/firmware/firmware/tasmota32&quot;&gt;webcam server firmware for the ESP32-cam&lt;/a&gt;&lt;/strong&gt;.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;If youre new to &lt;strong&gt;ESP32&lt;/strong&gt; boards, check Bills (&lt;a href=&quot;https://www.youtube.com/channel/UCzml9bXoEM0itbcE96CB03w&quot;&gt;DroneBot Workshop&lt;/a&gt;) review video:&lt;/p&gt;

&lt;!-- Courtesy of embedresponsively.com //--&gt;
&lt;div class=&quot;responsive-video-container&quot;&gt;

  &lt;iframe src=&quot;https://www.youtube-nocookie.com/embed/xPlN_Tk3VLQ&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;For a comparison of a few different &lt;strong&gt;ESP32-cam&lt;/strong&gt; boards, check &lt;a href=&quot;https://www.youtube.com/channel/UCu7_D0o48KbfhpEohoP7YSQ&quot;&gt;Andreas Spiess&lt;/a&gt; video:&lt;/p&gt;

&lt;!-- Courtesy of embedresponsively.com //--&gt;
&lt;div class=&quot;responsive-video-container&quot;&gt;

  &lt;iframe src=&quot;https://www.youtube-nocookie.com/embed/5IhhyJjjCxo&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--light-outline btn--small&quot;&gt;top&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;overview&quot;&gt;Overview&lt;/h1&gt;
&lt;p&gt;This tutorial was organized as follows.  First, I presented the motivation behind the use of Tasmota32 webcam server over one of the most common firmwares for the ESP32-cam, the Espressif CameraWebServer Arduino sketch.  This is followed by a list of the main hardware components involved into flashing a firmware onto the ESP32-cam.  Most of the tutorial focused on the installation and configuration of the Tasmota32 webcam server using a GNU/Linux OS.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--light-outline btn--small&quot;&gt;top&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;why-tasmota&quot;&gt;Why Tasmota?&lt;/h1&gt;
&lt;p&gt;Tasmota was created and it is still maintanted by &lt;a href=&quot;https://github.com/arendst&quot;&gt;Theo Arends&lt;/a&gt;. It started as hacky alternative to the &lt;a href=&quot;https://sonoff.tech/&quot;&gt;Sonoff&lt;/a&gt; commercial firmware and moved onto an independent, &lt;a href=&quot;https://github.com/arendst/Tasmota&quot;&gt;free and open-source project&lt;/a&gt; that provides multiple firmwares for ESP8266-based devices.  The firmwares come with a simple webUI that lets you control and configure the board main modules as well as integration with a MQTT server and more. Even though Tasmota &lt;a href=&quot;https://tasmota.github.io/docs/ESP32/&quot;&gt;support for the ESP32 is still in beta development&lt;/a&gt;, my experience with it has been very positive.&lt;/p&gt;

&lt;p&gt;One of the main webcam firmwares for the &lt;strong&gt;ESP32-cam&lt;/strong&gt; is the one provided by Espressif themselves, the &lt;a href=&quot;https://github.com/espressif/arduino-esp32/tree/master/libraries/ESP32/examples/Camera/CameraWebServer&quot;&gt;CameraWebServer&lt;/a&gt; Arduino sketch.  This one has features that the Tasmota32 webcam firmware does not offer, such as face recognition and motion detection.  However, my experience with the &lt;strong&gt;video streaming&lt;/strong&gt; has been negative.  Specifically, the streaming runs smoothly when the video resolution is low (640x480) but it strugles quite a bit when running at medium to high resolutionsthat is, the number of frames per second decreases noticeably.  Ive also noticed that the board runs very hot when running the CameraWebServer Arduino sketch, even when the most CPU intensive tasks (motion detection and face reconition) are disabled.&lt;/p&gt;

&lt;p&gt;On the other hand, the &lt;strong&gt;&lt;a href=&quot;https://github.com/arendst/Tasmota/tree/firmware/firmware/tasmota32&quot;&gt;Tasmota32 webcam server&lt;/a&gt;&lt;/strong&gt; seems to perform much better in the areas the CameraWebServer Arduino sketch strugles with.  More specifically, the streaming is smoother and the board does not seem to get as hot.  Ive not had a chance to investigate why this happens and to measure the actual difference in frames per second and temperature, so dont take my opinion too seriously.  Also, I cannot tell if this happens for all ESP32-cam boards because Ive only tested with the &lt;strong&gt;AI-Thinker&lt;/strong&gt; module.  Overall, however, my experience with the Tasmota32 firmware has been better than with the Espressif firmware in the area that I think is the most relevant one for a camera module, namely video streaming performance.  On top of that, the Tasmota firmware offers a multitude of methods to interact with the ESP32-cam remotely, while the Espressif sketch is very limited in that regard.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;If youve never heard of Tasmota before, check Robberts (&lt;a href=&quot;https://www.youtube.com/channel/UC2gyzKcHbYfqoXA5xbyGXtQ&quot;&gt;The Hook Up&lt;/a&gt;) introduction video:&lt;/p&gt;

&lt;!-- Courtesy of embedresponsively.com //--&gt;
&lt;div class=&quot;responsive-video-container&quot;&gt;

  &lt;iframe src=&quot;https://www.youtube-nocookie.com/embed/08_GBROKQH0&quot; frameborder=&quot;0&quot; allowfullscreen=&quot;&quot;&gt;&lt;/iframe&gt;

&lt;/div&gt;

&lt;hr /&gt;

&lt;p&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--light-outline btn--small&quot;&gt;top&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;hardware&quot;&gt;Hardware&lt;/h1&gt;
&lt;p&gt;To make a single wireless camera based on the ESP32-cam board, youll need at least the following items:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Board:
    &lt;ul&gt;
      &lt;li&gt;01x &lt;a href=&quot;https://www.amazon.com/s?k=esp32cam+ai-thinker&quot;&gt;ESP32-CAM, AI-Thinker board&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;a href=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/esp32cam.jpg&quot;&gt;&lt;img src=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/esp32cam.jpg&quot; alt=&quot;ESP32cam&quot; class=&quot;PostImage&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;USB to TTL adapter:
    &lt;ul&gt;
      &lt;li&gt;01x &lt;a href=&quot;https://www.amazon.com/s?k=ftdi+ft232RL+usb+to+ttl&quot;&gt;FTDI FT232RL USB to TTL/serial module with 5v/3v3 voltage jumper&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;a href=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/ftdi-usb-ttl.jpg&quot;&gt;&lt;img src=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/ftdi-usb-ttl.jpg&quot; alt=&quot;FTDI FT232RL&quot; class=&quot;PostImage&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Cables:
    &lt;ul&gt;
      &lt;li&gt;05x &lt;a href=&quot;https://www.amazon.com/s?k=female+dupont+wires&quot;&gt;Female-Female dupont/jumper wires&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;a href=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/female-dupont.jpg&quot;&gt;&lt;img src=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/female-dupont.jpg&quot; alt=&quot;Female dupont wires&quot; class=&quot;PostImage&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

    &lt;ul&gt;
      &lt;li&gt;01x USB cable compatible with your USB to TTL adapter: Check the USB type and use a short cable to decrease resistance as much as possible because initially, we will be powering the ESP32-cam via your computers USB port.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;a href=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/usb-cable.jpg&quot;&gt;&lt;img src=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/usb-cable.jpg&quot; alt=&quot;USB cable&quot; class=&quot;PostImage&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Optional.&lt;/em&gt; If you wish to add a case to your ESP32-cam project, there are many &lt;a href=&quot;https://duckduckgo.com/?q=esp32-cam+case&quot;&gt;3D printed options to choose from&lt;/a&gt;.  (Notice that the use of an external antenna requires (de)soldering very small components.  If you plan on installing the camera on an area with good wireless coverage, dont bother with an external antenna.  Otherwise, plan accordingly.)  In addition, you might want to add a &lt;a href=&quot;https://www.amazon.com/s?k=USB+to+DIP&quot;&gt;USB to DIP adapter&lt;/a&gt; to your shopping list in order to power your ESP32-cam without the USB to TTL adapter.  The USB to DIP adapter is highly dependent on the casing choice and most 3D printed enclosure projects for the ESP32-cam include assembly instructions.  &lt;strong&gt;Casing and assembly are not covered in this tutorial&lt;/strong&gt;, owing to the plethora of alternatives.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--light-outline btn--small&quot;&gt;top&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;installation&quot;&gt;Installation&lt;/h1&gt;
&lt;p&gt;This guide assumes youre running a &lt;strong&gt;Linux&lt;/strong&gt; distribution, and more specifically, an &lt;strong&gt;apt-based distro&lt;/strong&gt;, such as Debian or Ubuntu.  If youre running a different distro, simply change the apt code to reflect your systems package manager.  For non-Linux users, check &lt;a href=&quot;https://tasmota.github.io/docs/Getting-Started/&quot;&gt;Tasmotas Getting Started&lt;/a&gt; but use the binaries mentioned here and come back for the post-flashing configuration of the webcam server.&lt;/p&gt;

&lt;h2 id=&quot;required-packages-and-user-permissions&quot;&gt;Required packages and user permissions&lt;/h2&gt;
&lt;p&gt;Before we can flash the Tasmota32 webcam server onto the ESP32-cam, we will need to install a few packages and configure the permissions of our Linux user.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Open a terminal and install the required packages:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo apt update &amp;amp;&amp;amp; sudo apt install wget python3 python3-pip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Install &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;esptool.py&lt;/code&gt; via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;pip3&lt;/code&gt;:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pip3 install esptool
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Find out if &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;esptool.py&lt;/code&gt; can be found in your users &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$PATH&lt;/code&gt;. (Alternatively, when required to run &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;esptool.py&lt;/code&gt;, instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;esptool.py OPTIONS&lt;/code&gt;, run as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;python3 -m esptool OPTIONS&lt;/code&gt;. If you choose to do this, skip this and the next step.)
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;whereis esptool.py
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;If &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;esptool.py&lt;/code&gt; was not found, it means your users &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.local/bin&lt;/code&gt; is not in your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$PATH&lt;/code&gt;.  Add it as follows:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;echo &quot;export PATH=&quot;$HOME/.local/bin:$PATH&quot;&quot; | tee -a &quot;$HOME/.bashrc&quot; &amp;gt; /dev/null
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Connect your ESP32-cam to the USB to TTL/serial adapter in flash mode:&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/esp32cam-wiring-flash-mode.jpg&quot;&gt;&lt;img src=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/esp32cam-wiring-flash-mode.jpg&quot; alt=&quot;ESP32cam flash mode&quot; class=&quot;PostImage PostImage--large&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

    &lt;p class=&quot;notice notice--warning&quot;&gt;&lt;strong&gt;Attention.&lt;/strong&gt; Make sure your USB to TTL adapter has &lt;strong&gt;VCC in 5V mode&lt;/strong&gt; and in the ESP32, the VCC cable is connected to the 5V pin.  Double check the wiring before moving on.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Connect the adapter to a USB port on your computer and check the new device in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/dev/&lt;/code&gt;:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ls -l /dev/ttyUSB*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Add your &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;$USER&lt;/code&gt; to the same group as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/dev/ttyUSB*&lt;/code&gt; (its usually &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dialout&lt;/code&gt; but if different, change in the command below) and &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tty&lt;/code&gt;:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo usermod -a -G dialout ${USER} &amp;amp;&amp;amp; sudo usermod -a -G tty ${USER}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Log off and back on.  (If you continue to run into permission issues, try rebooting instead.  You can check your users permissions with &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;id ${USER}&lt;/code&gt;.)&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;flashing-tasmota32-webcam-server&quot;&gt;Flashing Tasmota32 webcam server&lt;/h2&gt;
&lt;p&gt;We are now ready to flash the Tasmota firmware.  For reference, the official information is available at &lt;a href=&quot;https://tasmota.github.io/docs/ESP32&quot;&gt;https://tasmota.github.io/docs/ESP32&lt;/a&gt;.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Create a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Tasmota32&lt;/code&gt; dir in &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/opt&lt;/code&gt;:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /opt &amp;amp;&amp;amp; sudo mkdir Tasmota32
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Download the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tasmota32-webcam.bin&lt;/code&gt; binary and the needed ESP32 Tasmota binaries from the official Github repo via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wget&lt;/code&gt;.  The most stable binaries are available in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;release-firmware&lt;/code&gt; branch and can be downloaded via the following command:&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo wget -P Tasmota32/ https://github.com/arendst/Tasmota/raw/release-firmware/firmware/tasmota32/tasmota32-webcam.bin https://github.com/arendst/Tasmota/raw/release-firmware/firmware/tasmota32/ESP32_needed_files/boot_app0.bin https://github.com/arendst/Tasmota/raw/release-firmware/firmware/tasmota32/ESP32_needed_files/bootloader_dout_40m.bin https://github.com/arendst/Tasmota/raw/release-firmware/firmware/tasmota32/ESP32_needed_files/partitions.bin 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;However, if you want to try the latest (development) binaries, then download the binaries from the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;firmware&lt;/code&gt; branch via the following command:&lt;/p&gt;

    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo wget -P Tasmota32/ https://github.com/arendst/Tasmota/raw/firmware/firmware/tasmota32/tasmota32-webcam.bin https://github.com/arendst/Tasmota/raw/firmware/firmware/tasmota32/ESP32_needed_files/boot_app0.bin https://github.com/arendst/Tasmota/raw/firmware/firmware/tasmota32/ESP32_needed_files/bootloader_dout_40m.bin https://github.com/arendst/Tasmota/raw/firmware/firmware/tasmota32/ESP32_needed_files/partitions.bin 
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;

    &lt;p&gt;My recommendation is to try the latest (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;firmware&lt;/code&gt;) first. Then, if you run into issues, go back to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;release-firmware&lt;/code&gt;.  You can find a list of active branches at &lt;a href=&quot;https://github.com/arendst/Tasmota/branches/active&quot;&gt;https://github.com/arendst/Tasmota/branches/active&lt;/a&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Change ownership to your user instead of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;root&lt;/code&gt;:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;sudo chown -R ${USER} Tasmota32/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Make sure your ESP32-cam is still connected to your computer in &lt;strong&gt;flash mode&lt;/strong&gt; (GPIO0-GND jumper).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Erase the current firmware (or whatever data) from your ESP32-cam. Change &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--port /dev/ttyUSB&lt;/code&gt; to the port your device is connected to, which you can find via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ls -l /dev/ttyUSB*&lt;/code&gt;. For example, if your device is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/dev/ttyUSB0&lt;/code&gt;, then use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--port /dev/ttyUSB0&lt;/code&gt; in the options of the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;esptool.py&lt;/code&gt; utility.
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;esptool.py --port /dev/ttyUSB erase_flash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Wait until &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;esptool.py&lt;/code&gt; is done&lt;/strong&gt;. Then, press the &lt;strong&gt;reset button on the ESP32-cam&lt;/strong&gt;.  Now, check that &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;/dev/ttyUSB&lt;/code&gt; is available again.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Flash the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;tasmota32-webcam.bin&lt;/code&gt; webcam server binary and the required Tasmota binaries to the ESP32-cam. (As before, change &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;--port&lt;/code&gt; before running the command.)
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;esptool.py --chip esp32 --port /dev/ttyUSB --baud 921600 --before default_reset --after hard_reset write_flash -z --flash_mode dout --flash_freq 40m --flash_size detect 0x1000 /opt/Tasmota32/bootloader_dout_40m.bin 0x8000 /opt/Tasmota32/partitions.bin 0xe000 /opt/Tasmota32/boot_app0.bin 0x10000 /opt/Tasmota32/tasmota32-webcam.bin
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Wait until &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;esptool.py&lt;/code&gt; is done&lt;/strong&gt;. Then, &lt;strong&gt;remove the flash mode (GPIO0-GND) jumper&lt;/strong&gt; from the ESP32-cam.&lt;/p&gt;

    &lt;p&gt;&lt;a href=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/esp32cam-wiring-nonflash-mode.jpg&quot;&gt;&lt;img src=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/esp32cam-wiring-nonflash-mode.jpg&quot; alt=&quot;ESP32cam nonflash mode&quot; class=&quot;PostImage PostImage--large&quot; /&gt;&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Now &lt;strong&gt;press the reset button&lt;/strong&gt; on your ESP32-cam.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--light-outline btn--small&quot;&gt;top&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;configuration&quot;&gt;Configuration&lt;/h1&gt;
&lt;p&gt;By default, the Tasmota firmware will create a wireless access point for your ESP32-cam.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;Use a wifi-capable device (e.g., laptop) and connect to it. The ESP32-cam will give your device an IP address, which you can check via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;ip a&lt;/code&gt;. Usually, the devices IP address is in the &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;192.168.4.0/24&lt;/code&gt; pool, which means the ESP32-cam webUI is at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;192.168.4.1:80&lt;/code&gt;; Otherwise, the webUI will be at the first addr in whichever pool your device connected to after joining the wireless access point created by the Tasmota firmware.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Open a web-browser of your choice and navigate to the ESP32-cam webUI. You should be prompted to change the wifi settings to allow your ESP32-cam to connect to your local wifi network.  Change the settings, save it, and wait for the ESP32-cam to reboot.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Navigate to the &lt;strong&gt;DHCP server&lt;/strong&gt; of your local network and find the IP address assigned to your ESP32-cam.  At this point, its a good idea to assign a static address to it as well.  (If you set a static address, then reboot the ESP32-cam before moving on.)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Navigate to the ESP32-cam webUI on your local network.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;updating-the-template&quot;&gt;Updating the template&lt;/h2&gt;
&lt;p&gt;Tasmota templates are device-specific definitions of how their GPIO pins are assigned. As mentioned before, there are multiple ESP32-cam boards out there with different definitions.  In my case, Im using the &lt;strong&gt;AI-Thinker cam&lt;/strong&gt; module and therefore, I should configure the Tasmota32 webcam server to use the &lt;a href=&quot;https://tasmota.github.io/docs/ESP32/#aithinker-cam&quot;&gt;AITHINKER CAM template&lt;/a&gt; instead of the default one.  (If your ESP32-cam is different, then check &lt;a href=&quot;https://tasmota.github.io/docs/ESP32/&quot;&gt;https://tasmota.github.io/docs/ESP32/&lt;/a&gt; for the appropriate template and use that one instead of the AITHINKER CAM.)&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Copy the &lt;strong&gt;AITHINKER CAM template&lt;/strong&gt;:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{&quot;NAME&quot;:&quot;AITHINKER CAM&quot;,&quot;GPIO&quot;:[4992,1,1,1,1,5088,1,1,1,1,1,1,1,1,5089,5090,0,5091,5184,5152,0,5120,5024,5056,0,0,0,0,4928,1,5094,5095,5092,0,0,5093],&quot;FLAG&quot;:0,&quot;BASE&quot;:1}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;From the ESP32-cam webUI, go to &lt;strong&gt;Configuration &amp;gt; Configure &amp;gt; Configure other&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Paste the template under &lt;strong&gt;Other parameters &amp;gt; Template&lt;/strong&gt;; &lt;strong&gt;Check Activate&lt;/strong&gt;; Save it and wait for the reboot.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The device should now be named AITHINKER CAM (or whaterver NAME was in the template).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;The MJPEG stream should be accessible at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://DEVICE_IP:81/stream&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://DEVICE_IP:81/cam.mjpeg&lt;/code&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;A single snapshot can be obtained at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://DEVICE_IP:80/snapshot.jpg&lt;/code&gt;.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;auto-enabling-the-webcam-server-at-boot&quot;&gt;Auto-enabling the webcam server at boot&lt;/h2&gt;
&lt;p&gt;If your board is like mine, the stream does not initialize on its own at bootit requires a request to get webUI to initialize the stream.  This will happen whenever you try to visit the devices webUI.  However, if you want to automatically initialize the webserver and video stream at boot, we can do so using Tasmotas &lt;strong&gt;&lt;a href=&quot;https://tasmota.github.io/docs/Rules/&quot;&gt;rules&lt;/a&gt;&lt;/strong&gt;.  More specifically, we will add &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Rule1&lt;/code&gt; that tells the ESP32-cam to start the stream once Tasmota is fully initialized (i.e., after wifi and MQTT are connected, if configured).&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Copy the following rule:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Rule1 ON System#Boot DO WcInit ENDON
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Go to the ESP32-cam webUI and then &lt;strong&gt;Console&lt;/strong&gt;.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Paste the rule in the &lt;strong&gt;enter command&lt;/strong&gt; box and press enter.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;To enable &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;Rule1&lt;/code&gt;, enter the following command:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Rule1 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Restart the ESP32-cam with the following command:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Restart 1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;Once it comes back on, check the console if &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;RULE 1&lt;/code&gt; was executed.  It should show something similar to the following if the rule is working as expected:
    &lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;... RUL: SYSTEM#BOOT performs &quot;WcInit&quot;
... SRC: Rule
... CMD: Group 0, Index 1, Command &quot;WCINIT&quot;, Data &quot;&quot;
... CAM: Stream init
... CAM: User template
... CAM: PSRAM found
... CAM: Initialized
... RSL: stat/tasmota_***/RESULT = {&quot;WCInit&quot;:&quot;Done&quot;}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;The MJPEG stream should now be accessible at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://DEVICE_IP:81/stream&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://DEVICE_IP:81/cam.mjpeg&lt;/code&gt; without ever accessing the webUIs main page.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;By the way, &lt;strong&gt;rules&lt;/strong&gt; are a great way to program your Tasmota device indepedently of any automation server. Make sure to read about &lt;a href=&quot;https://tasmota.github.io/docs/Rules/&quot;&gt;how to add or modify rules&lt;/a&gt; and &lt;a href=&quot;https://tasmota.github.io/docs/Commands/#rules&quot;&gt;the list of available rule commands&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;webcam-server-additional-configurations&quot;&gt;Webcam server additional configurations&lt;/h2&gt;
&lt;p&gt;A full list of commands for ESP32 devices can be found at &lt;a href=&quot;https://tasmota.github.io/docs/Commands/#esp32&quot;&gt;the official docs page&lt;/a&gt;.  However, by the time I finished writing this, many of the commands that are specific to the Tasmota32 webcam server binary were gone Im not sure what happened there.  For this reason, Ive decided to post here all the additional commands (&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;wc&lt;/code&gt;) that Im aware of (in alphabetical order):&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Command&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Definition&lt;/th&gt;
      &lt;th style=&quot;text-align: center&quot;&gt;Values&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WcBrightness&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Image brightness&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-2&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WcContrast&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Image contrast&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-2&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WCFlip&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Flips the image vertically&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WcInit&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Initializes the webcam server&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WCMirror&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Flips the image horizontally&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WcResolution&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Image resolution&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FRAMESIZE 96x96&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FRAMESIZE 160x120&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FRAMESIZE 176x144&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;3&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FRAMESIZE 240x176&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;4&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FRAMESIZE 240x240&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;5&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FRAMESIZE 320x240&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;6&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FRAMESIZE 400x256&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;7&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FRAMESIZE 480x320&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;8&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FRAMESIZE 640x480&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;9&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FRAMESIZE 800x600&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;10&lt;/code&gt;: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;FRAMESIZE 1024x768&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WcSaturation&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Image saturation&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-2&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt;, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;2&lt;/code&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;WcStream&lt;/code&gt;&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;Controls the video streaming&lt;/td&gt;
      &lt;td style=&quot;text-align: center&quot;&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;0&lt;/code&gt;: stop, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;1&lt;/code&gt;: start&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;For example, to set the stream resolution to 800x600, go to the &lt;strong&gt;Console&lt;/strong&gt; and enter the following command :&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WcResolution 9
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Alternatively, its possible to send commands via HTTP.  The previous example via web-browser: &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://DEVICE_IP/cm?cmnd=WcResolution%209&lt;/code&gt;.  If using a terminal, you can send via &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;curl&lt;/code&gt;, as follows:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl http://DEVICE_IP/cm?cmnd=WcResolution%209
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;which should reply with a &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;json&lt;/code&gt; parsable by utilities such as &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;jq&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Finally, the &lt;strong&gt;flash LED&lt;/strong&gt; is controlled by &lt;strong&gt;GPIO4&lt;/strong&gt; and the &lt;strong&gt;red LED&lt;/strong&gt; is controlled by &lt;strong&gt;GPIO33&lt;/strong&gt;. Their state can be changed programatically as well.&lt;/p&gt;

&lt;h2 id=&quot;fixing-the-timezone&quot;&gt;Fixing the timezone&lt;/h2&gt;
&lt;p&gt;If you installed a pre-compilled firmware, theres a chance your device is using the incorrect timezone.  To check the current timezone, go to &lt;strong&gt;Console&lt;/strong&gt; and type&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;timezone
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;and to change it, enter the command with a value equal to your regions &lt;a href=&quot;https://upload.wikimedia.org/wikipedia/commons/8/88/World_Time_Zones_Map.png&quot;&gt;standardized time zone&lt;/a&gt;.  For America/Sao_Paulo, for example, that would be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;-3&lt;/code&gt;, which can be set in your Tasmota device as follows&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;timezone -3
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--light-outline btn--small&quot;&gt;top&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;basic-usage&quot;&gt;Basic usage&lt;/h1&gt;
&lt;p&gt;You can now capture the live stream of your ESP32-cam at either &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://DEVICE_IP:81/stream&lt;/code&gt; or &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://DEVICE_IP:81/cam.mjpeg&lt;/code&gt;, and a single snapshot at &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;http://DEVICE_IP:80/snapshot.jpg&lt;/code&gt;.  Such URLs can be easily fed into most camera surveillance servers, such as &lt;a href=&quot;https://github.com/ccrisan/motioneye/&quot;&gt;MotionEye&lt;/a&gt;, &lt;a href=&quot;https://shinobi.video/&quot;&gt;Shinobi&lt;/a&gt;, &lt;a href=&quot;https://www.zoneminder.com/&quot;&gt;ZoneMinder&lt;/a&gt;, or &lt;a href=&quot;https://www.ispyconnect.com/&quot;&gt;iSpy&lt;/a&gt;.  As mentioned before, the Tasmota32 webcam server can be configure to connect to a &lt;strong&gt;&lt;a href=&quot;https://mqtt.org/&quot;&gt;MQTT server&lt;/a&gt;&lt;/strong&gt; (see &lt;strong&gt;Configuration&lt;/strong&gt; &amp;gt; &lt;strong&gt;Configure MQTT&lt;/strong&gt;) and then integrated with most home automation servers, such as &lt;a href=&quot;https://www.home-assistant.io/&quot;&gt;HomeAssistant&lt;/a&gt;, &lt;a href=&quot;https://www.openhab.org/&quot;&gt;OpenHAB&lt;/a&gt;, or one based on &lt;a href=&quot;https://nodered.org/&quot;&gt;NodeRed&lt;/a&gt;s flow programming.&lt;/p&gt;

&lt;h2 id=&quot;standalone-wiring&quot;&gt;Standalone wiring&lt;/h2&gt;
&lt;p&gt;If you bought a USB to DIP adapter, you can now power your ESP32-cam independent of your USB to TTL/serial adapter using a cheap &lt;strong&gt;5V (at least 400mA) USB power supply&lt;/strong&gt;, such as an old cellphone charger, as follows:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/esp32cam-wiring-standalone-mode.jpg&quot;&gt;&lt;img src=&quot;/assets/posts/2021-01-15-Esp32cam-tasmota-webcam-server/esp32cam-wiring-standalone-mode.jpg&quot; alt=&quot;ESP32cam standalone mode&quot; class=&quot;PostImage PostImage--large&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--light-outline btn--small&quot;&gt;top&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;This concludes the tutorial on how to install and configure the Tasmota32 webcam server onto the ESP32-cam.  As usual, if you spot an error or want to share an idea, feel free to &lt;a href=&quot;/contact&quot;&gt;get in touch with me&lt;/a&gt;.  I try to keep my articles updated as much as possible to reflect my current understanding about the topic.  All such updates are noted in the &lt;a href=&quot;#changelog&quot;&gt;changelog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;#&quot; class=&quot;btn btn--light-outline btn--small&quot;&gt;top&lt;/a&gt;&lt;/p&gt;</content><author><name>Carlos Gomes</name></author><category term="blog" /><category term="iot" /><category term="esp32" /><category term="tasmota" /><category term="mqtt" /><category term="cam" /><category term="webcam" /><category term="surveillance" /><category term="wifi" /><category term="wireless" /><category term="network" /></entry><entry><title type="html">Repurposing external HDD enclosures into button boxes for the Raspberry Pi</title><link href="/blog/Rpi-button-box-ehdd-enclosure/" rel="alternate" type="text/html" title="Repurposing external HDD enclosures into button boxes for the Raspberry Pi" /><published>2020-12-18T12:08:00-03:00</published><updated>2020-12-18T12:08:00-03:00</updated><id>/blog/Rpi-button-box-ehdd-enclosure</id><content type="html" xml:base="/blog/Rpi-button-box-ehdd-enclosure/"># Changelog
**Dec 18th, 2020**: Publication of the original guide
{: .notice .notice--info }

[top](#){: .btn .btn--light-outline .btn--small}

# Introduction
Hard disk drives (HDDs) are often sold in an external enclosure with easy-to-use interfaces as a detachable, semi-mobile data storage solution. Every so often, however, their price goes below the market price for an equivalent internal HDD and when that happens, many of us will buy them only to remove the HDD from its external enclosure and use it as a regular HDD in our PCs and servers--a practice called **shucking**.

[![Amazon ad Seagate expansion 4tb](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/amazon-seagate-4tb-ehdd.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/amazon-seagate-4tb-ehdd.jpg) 

But what do you do with the external enclosure afterwards? Do you throw it away?  Well, you could do that but here I'll show that such enclosures can be repurposed into nice looking **button boxes** for most single board computers (SBCs).  More specifically, I'll transform an old, shucked [**Seagate Expansion 4TB USB3.0 HDD** (STBV4000100)](https://www.newegg.com/seagate-expansion-4tb/p/N82E16822178354) into a button box for the [**Raspberry Pi** (RPi)](https://www.raspberrypi.org/products/raspberry-pi-3-model-b/). Here's a preview of how it looks like:

[![RPi and buttons](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/preview-rpi-and-buttons.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/preview-rpi-and-buttons.jpg) 

[![RPi and buttons - Closed 01](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/preview-rpi-and-buttons-closed.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/preview-rpi-and-buttons-closed.jpg) 

[![RPi and buttons - Closed 02](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/preview-rpi-and-buttons-closed-2.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/preview-rpi-and-buttons-closed-2.jpg) 

In the first section of this tutorial, I described a few general points to consider when [planning your button box](#assessment), such as whether the SBC fits, if it already has holes, and so on.  Then, I go into the specifics of my own case, such as the [hardware components](#hardware) of it (e.g., buttons, switches), the [software](#software) used (Pi OS and a Python button box controller), and finally, the [assembly](#assembly) of hardware and software into a functional button box.  If that sounds good, let's get started.

**ATTENTION**. I do not recommend to use an external HDD enclosure as a button box to control **mains power**.  None of those enclosures was designed to have 110-220V AC running inside of it and things might melt and catch fire, and of course, you don't want someone to get electrocuted because of a loose mains cable.  Even though some of the buttons and switches might be rated 110-220V AC at 10A, for instance, to be safe, stick to **low voltage DC** inside the button box.
{: .notice .notice--danger}

[top](#){: .btn .btn--light-outline .btn--small}

# Assessment
* Does the enclosure have a **flat surface** to attach the buttons?

* Will the SBC **fit** inside of the enclosure?
  
  Height-wise, make sure there's a little bit of room for the jumper cables that will be connected to the GPIO pins--*at least* 5cm (roughly 2 inches) of space above the GPIO pins.

* Will the buttons fit inside the enclosure? 
  
  Some buttons have fairly long terminals that could hit the bottom of the enclosure once the lid is closed.  You also need to take into consideration that jumper cables will be soldered to the button's terminal and might need additional room.

* If the SBC will go inside of the enclosure, does it have holes to **remove hot air from inside**?
  
  Depending on the SBC and usage, you might need to plan a small fan to remove the hot air generated by the board. However, this is likely not necessary for external HDD enclosures because heat will also harm HDDs and manufacturers will design their external cases with that in mind.

* Can you repurpose some of the **existing holes**?

  It's much easier to use existing holes than making new ones and they usually look better because the case was designed with them in mind, as opposed to the new ones.

* Is it **safe to drill** holes in the enclosure?

  Some materials can crack/break easily and a few can be harmful to you if you do not take the necessary precautions.

[top](#){: .btn .btn--light-outline .btn--small}

# Hardware

* SBC:
  * [Raspberry Pi 3B](https://www.raspberrypi.org/products/raspberry-pi-3-model-b/)
    
    [![RPi model 3B](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/rpi-model-3b.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/rpi-model-3b.jpg)

* External HDD enclosure:
  * [Seagate Expansion 4TB USB3.0 HDD (STBV4000100)](https://www.newegg.com/seagate-expansion-4tb/p/N82E16822178354)
    
    [![Seagate HDD enclosure](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/seagate-external-enclosure.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/seagate-external-enclosure.jpg)

* [Push buttons](https://www.amazon.com/s?k=push+button):
  * 02x Red push button
  * 02x Black push button
  * 02x Green push button
    
    [![Push Button](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/push-button.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/push-button.jpg)

* [Toggle switches](https://www.amazon.com/s?k=toggle+switch):
  * 03x OFF/on toggle switch
  * 02x Red safety cover for the toggle switch
  * 01x &quot;ON/OFF&quot; label for the toggle switch
    
    [![Toggle Switch](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/toggle-switch.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/toggle-switch.jpg)

* [Buzzer]((https://www.amazon.com/s?k=active+buzzer))
  * 01x Active buzzer

  [![Buzzer](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/buzzer.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/buzzer.jpg)

* Cover:
  * [Textured vynil/PVC film](https://www.amazon.com/s?k=carbon+fiber+vinyl+wrap)
    
    The size depends on the surface area you want to cover with it.  My suggestion is to use a **thin** film instead of a thick layer because it is flexible and therefore, easy to attach to the enclosure.  By the way, these things are actually super useful to have around if you are into DIY projets.
    
    [![Vynil Film](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/textured-vynil-film.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/textured-vynil-film.jpg)

* Cables and related materials:
  * 18x [Female-X Dupont/jumper wires](https://www.amazon.com/s?k=dupont+wires)

    The female side connects to GPIO pins and the other side can be whatever because is soldered to terminals or otherwise attached to them.
    
    [![Jumper Cables](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/jumper-cables.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/jumper-cables.jpg)

  * 06x [Heat shrink tube](https://www.amazon.com/s?k=heat+shrink+tube)

    Cut them in half to protect both terminals of each push button
    
    [![Heat Shrink Tube](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/heat-shrink-tube.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/heat-shrink-tube.jpg)

  * 01x [Electrical tape](https://www.amazon.com/s?k=electrical+tape)

    [![Electrical Tape](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/electrical-tape.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/electrical-tape.jpg)

* Other tools
  * [Basic soldering kit](https://www.amazon.com/s?k=soldering+kit)

    [![Soldering Kit](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/soldering-kit.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/soldering-kit.jpg)

  * Any low power drill or even a manual [hand drill](https://www.amazon.com/s?k=hand+drill): An electric drill will save you a lot of time.  For better results, use a step drill bit after making the center hole.

    [![Step Drill Bit](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/step-drill-bit.jpg){:.PostImage}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/step-drill-bit.jpg)  


[top](#){: .btn .btn--light-outline .btn--small}

# Software

* Operating System (OS):
  * [Raspberry Pi OS Lite](https://www.raspberrypi.org/software/operating-systems/): `Raspbian GNU/Linux 10 (buster)`, `lite edition`
    * Kernel: `5.4`
    * Release date: `December 2nd 2020`

* Button box controller:
  * [`rpi-button-box`](https://github.com/cgomesu/rpi-button-box): `1.0` 
    * A custom-made controller written in Python

* Controller requirements:
  * [Python](https://www.python.org): `3.7.3`
    * [`gpiozero`](https://gpiozero.readthedocs.io/en/stable/): An interface to GPIO devices
    * [`argparse`](https://docs.python.org/3/library/argparse.html), [`logging`](https://docs.python.org/3/library/logging.html), [`signal`](https://docs.python.org/3/library/signal.html), [`subprocess`](https://docs.python.org/3/library/subprocess.html): Standard, built-in libraries

* Optional:
  * [Logrotate](https://linux.die.net/man/8/logrotate): `3.14.0`
    * Manage the `button-box.log` log files generated by the controller

[top](#){: .btn .btn--light-outline .btn--small}

## `rpi-button-box` controller
&gt; Core program for a Raspberry Pi button box controller that uses the `gpiozero` Python library.

I wrote this program with the current project in mind--that is, a 40-pins Raspberry Pi with six push buttons and three switches, one of them being a power on/off for the box--but hopefully, my comments and documentation will be enough to allow adapting the program to multiple types of button boxes.  In this section, I'll explain the program's main logic and its functionalities.  The installation procedure and usage examples are described in [assembly](#assembly).

The `gpiozero` library is at the core of the button box controller.  The library makes it very easy to enable GPIO devices with just a few lines of code because it leaves much of the device configuration and cleanup procedures to the background.  All that we need to do is create objects for the GPIO devices of the appropriate class, which in our case is the [`Button`](https://gpiozero.readthedocs.io/en/stable/api_input.html#button) class and [`Buzzer`](https://gpiozero.readthedocs.io/en/stable/api_output.html#buzzer) class.

The `rpi-button-box` controller's main logic is explained next.
```python
def main():
  try:
    logging.basicConfig(filename='/opt/rpi-button-box/button-box.log', level=logging.INFO,
      format='%(asctime)s.%(msecs)03d %(levelname)s %(module)s : %(message)s',
      datefmt='%Y-%m-%d %H:%M:%S')
    logging.info('Started the button box controller')
    buttons = config_buttons()
```
* The program starts by configuring and initializing the logging of controller-related events, such as whether button `G1` was pressed, which `GPIO` pins are being used, and so on. Then, it asks `config_buttons` for a list of `buttons` to be used by the controller, as follows:

```python
def config_buttons():
  logging.info('Loading buttons...')
  Button.label, Button.type, Button.cmdheld, Button.cmdpressed, Button.cmdreleased = False, False, False, False, False
  g1, g1.label, g1.type, g1.cmdpressed, g1.cmdreleased = Button(26), 'green #1', 'push', args['g1_pressed'], args['g1_released']
  b1, b1.label, b1.type, b1.cmdpressed, b1.cmdreleased = Button(19), 'black #1', 'push', args['b1_pressed'], args['b1_released']
  r1, r1.label, r1.type, r1.cmdpressed, r1.cmdreleased = Button(13), 'red #1', 'push', args['r1_pressed'], args['r1_released']
  g2, g2.label, g2.type, g2.cmdpressed, g2.cmdreleased = Button(6), 'green #2', 'push', args['g2_pressed'], args['g2_released']
  b2, b2.label, b2.type, b2.cmdpressed, b2.cmdreleased = Button(5), 'black #2', 'push', args['b2_pressed'], args['b2_released']
  r2, r2.label, r2.type, r2.cmdpressed, r2.cmdreleased = Button(12), 'red #2', 'push', args['r2_pressed'], args['r2_released']
  s1, s1.label, s1.type, s1.cmdheld, s1.cmdreleased = Button(16, hold_time=2), 'power', 'switch', args['s1_held'], args['s1_released']
  s2, s2.label, s2.type, s2.cmdheld, s2.cmdreleased = Button(20, hold_time=2), 'middle S2', 'switch', args['s2_held'], args['s2_released']
  s3, s3.label, s3.type, s3.cmdheld, s3.cmdreleased = Button(21, hold_time=2), 'right S3', 'switch', args['s3_held'], args['s3_released']
  logging.info('Buttons loaded')
  return [g1, b1, r1, g2, b2, r2, s1, s2, s3]

```

* Notice that it starts by creating *new* attributes for the `Button` class, which are called `label`, `type`, and `cmd*`. I found this to be useful when working with multiple buttons because it allows me to define events on a *per button basis*.  For example, one might want to set different triggers for **switches** and **push buttons**, and the `type` attribute will help differentiate those.  Similarly, one might want to execute a different command for a button labeled `power` than a button labeled `reboot`.  It goes without saying that if your box does not follow the same layout as mine, you have to edit this part of the code.

* Going back to `main`:

```python
    logging.info('Trying to find a power switch...')
    for button in buttons:
      if button.label == 'power':
        logging.info('Power switch found at {}'.format(button.pin))
        if not button.is_active:
          print('Waiting for the power button ({}) to be turned ON...'.format(button.pin))
          button.wait_for_active()
          logging.info('Power switch was turned ON by user'.format(button.pin))
          sleep(button.hold_time)  # wait for the power button to enter is_held state
        break
```

* In my original design for the button box, I had a toggle, on/off `switch` labeled `power` that I wanted to use to **enable** and **disable** the button box controller.  The code above handles the activation of the button box depending on the state of a button labeled `power`.

```python
    push_buttons, switches = [], []
    for button in buttons:
      if button.type == 'switch':
        switches.append(button)
        button.when_held, button.when_released = event_held, event_released
        logging.info('Configured the switch button ({0}) at {1}'.format(button.label, button.pin))
      else:
        push_buttons.append(button)
        button.when_pressed, button.when_released = event_pressed, event_released
        logging.info('Configured the push button ({0}) at {1}'.format(button.label, button.pin))
```

* Here, the program learns what triggers each button.  As mentioend before, the `type` attr is used to set different triggers for `switch` and `push` buttons.

* Of note, `when_*` properties will pass the device that activated it to a function that takes a single parameter (`btn`), and because there are multiple new attributes for each button object, it is possible to use a single function to control all buttons by reading the `btn` attributes.  For example, take a look at the `event_held`, in which we have code for invoking an external command/script using the `btn.cmdheld` attribute:

```python
def event_held(btn):
  logging.info('The button labeled \'{0}\' at {1} was held'.format(btn.label, btn.pin))
  if args['debug']:
    print('Detected a HELD event by {0} : {1} button : {2}'.format(btn.pin, btn.type, btn.label))
  if btn.cmdheld:
    logging.info('Started running the following command: \'{}\''.format(btn.cmdheld))
    Popen(btn.cmdheld) if args['cmd'] == 'Popen' else run(btn.cmdheld)
    if args['debug']:
      print('Finished invoking the script at \'{}\''.format(btn.cmdheld))
    logging.info('Finished waiting for the following command: \'{}\''.format(btn.cmdheld))

```

* Going back to `main`:

```python
    if args['buzzer']:
      buzzer, buzzer.source = Buzzer(args['buzzer']), any_values(*push_buttons)
      logging.info('Configured a buzzer at {}'.format(buzzer.pin))
```

* This configures the `Buzzer` object to be activated whenever a `push` button is pressed.

```python
    print('The button box is now turned ON. To close it, release the power button or press Ctrl+C.')
    logging.info('The button box is ON and waiting for user input')
    pause()
  except KeyboardInterrupt:
    end(msg='Received a signal to stop.', status=1)
  except GPIOZeroError as err:
    end(msg='GPIOZero error: {}'.format(err), status=1)
```

* And finally, at the end of our main logic, the program is `pause`d to wait for a user input to trigger an event (`when_pressed`, `when_held`, `when_released`). This is a better alternative to using an infinite loop (`while True`).

There's a little bit more to the code than that but this covers the most important aspects of it. [Check the repo for updates](https://github.com/cgomesu/rpi-button-box), [start a discussion](https://github.com/cgomesu/rpi-button-box/discussions) if you had an idea, or [open an issue](https://github.com/cgomesu/rpi-button-box/issues) if you're having trouble with the program.  

# Assembly

## Installing the software

### Raspberry Pi OS
Follow [the official instructions to install the Raspberry Pi OS](https://projects.raspberrypi.org/en/projects/raspberry-pi-setting-up). If you don't feel like it, here's a brief summary:

1. Download the image file from the official repository.
2. Verify checksum.  On Linux distros, run the following, changing `img.zip` for the filename of the downloaded OS zipped image:
```
sha256sum img.zip
```
3. Flash onto a microSD card with [balenaEtcher](https://www.balena.io/etcher/) or similar application.
4. For headless access, add an empty `ssh` file to the root of the `boot` drive.
5. Insert the microSD card into the RPi and boot it up.
6. Find the RPi IP and `ssh` into it (`ssh pi@IP` and the default passwd is `raspberry`).
7. Config the RPi with `sudo raspi-config` (locale, time, wireless, etc.) then **reboot it**.
8. Reconnect to the RPi and update the package list &amp;&amp; upgrade all eligible pkgs, as follows:
```
sudo apt update &amp;&amp; sudo apt upgrade -y
```
9. Reboot the device once again and you're done!

### Python3, `rpi-button-box`, and installing the requirements
The button box controller was developed for the Lite version of the [Raspberry Pi OS](https://www.raspberrypi.org/software/) but it should work with other similar systems for single board computers (e.g., [Armbian](https://www.armbian.com/)).

The following instructions assume you're logged in with the `pi` user with `sudo` permission. (This is not a requirement but if different, make sure to change file permissions accordingly.  This applies to `systemd` service file and `logrotate/button-box` config as well.)

1. Use `apt` to install required programs
```
sudo apt update
sudo apt install git python3 python3-pip
```
2. Clone the `rpi-button-box` repo in `/opt`
```
cd /opt
sudo git clone https://github.com/cgomesu/rpi-button-box.git
sudo chown -R pi rpi-button-box
```
3. Install Python libraries from `requirements.txt`
```
pip3 install -r /opt/rpi-button-box/requirements.txt
```
* If you get a warning that `.local/bin` is not in your user's `$PATH`, then add it to your existing `$PATH` as follows:
  ```
  export PATH=/home/pi/.local/bin:$PATH
  ```
  and then append it to your user's `.bashrc`:
  ```
  echo &quot;export PATH=/home/pi/.local/bin:$PATH&quot; | tee -a /home/pi/.bashrc &gt; /dev/null
  ```
4. Test `button-box.py` and read its usage
```
cd /opt/rpi-button-box
./button-box.py -h
```
If you wish to skip to a more detailed description of the button box controller, go to [Using the button box controller](#using-the-button-box-controller) section in this tutorial.

### Configure logrotate
(Optional.) The `rpi-button-box` controller generates a `button-box.log` file upon execution where it stores a couple of controller-related messages, such as initialization configs and button presses, releases, and so on.  Over time, this file will grow forever unless you manually rotate it.  Obviously, you don't need to do that.  The easiest way to rotate log files in a GNU/Linux system is to configure [logrotate](#) to manage your log files.  I've already written such a config file for the button box controller (see `logrotate.d/button-box`).  To enable it, just copy the config to your `/etc/logrotate.d/` directory, as follows
```
sudo cp /opt/rpi-button-box/logrotate.d/button-box /etc/logrotate.d/
```
If you want, you can edit the rotation settings in `button-box`.  The default should be good enough though.

## Building the button box
**ATTENTION.**  If you have never used a drill before, take a few minutes to learn about best practices first.  When drilling holes into the case, make sure to secure the case very well before you begin.  When soldering cables to terminals, use a fan to move the fumes away from you and anyone else.  Wash your hands very well afterwards.
{: .notice .notice--danger}

**REMINDER.**  Inside the button box, stick to **low voltage DC**.  External HDD enclosures were not made to house mains power and unless you have taken the time to learn how to handle it, do not tinker with it.
{: .notice .notice--warning}

After the [assessment](#assessment), it's DIY time.

* Start by drawing the location of each button on the box.  Use a ruler and pencil.

[![Drawing](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-drawing.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-drawing.jpg)

* Then, drill the holes and check that the buttons fit them.

* Cut the vynil film and attach it to the surface of your button box.  

* Find the holes by gently pressing the surface of the vynil film.  Then, get a scissors or other cutting tool and either cut a circle where the hole is or cut an X where the hole is and fold the vynil film inwards.

* Attach the buttons to the enclosure.  It should look like this now:

[![Buttons](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-buttons.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-buttons.jpg)

* Flip the case and it's time to solder the jumper cables to each button terminal.

* Tricks for working with dupont cables: 
  {% include video id=&quot;eI3fxTH6f6I&quot; provider=&quot;youtube&quot; %}

* Because the buttons use a common ground, you *could* solder them together (terminal to terminal or splicing). However, if you want to reuse the buttons for another project in the future, or simply replace one of them, this will make it much harder to do that.  I wanted to make each button detachable without any desoldering, so I used the following idea for a custom-made header:
  {% include video id=&quot;OC3aAuhU3og&quot; provider=&quot;youtube&quot; %}

* If your heat shrinking tubes are pretty long, cut them.  Also, remember to insert the tubes into the cable before soldering.  (For a hobbyist like me, it's very easy to forget that. Ugh!)
  
* If at all possible, use different colors for ground (black, grey) and live/vcc (any thing else).

* After it's all done, it should look like this:

[![Soldered Cables](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-soldering.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-soldering.jpg)

[![Soldered Cables 2](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-soldering-2.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-soldering-2.jpg)

* If you have a [multimeter](https://www.amazon.com/s?k=multimeter), **test all your connections**.

* Connect the dupont cables to the RPi GPIO pins according to the following wiring schema:

[![Wiring](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/button-box-wiring.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/button-box-wiring.jpg)

This uses the **internal pull-up resistor** to simplify the wiring ([enabled by default in the `Button` class of the `gpiozero` Python library](https://gpiozero.readthedocs.io/en/stable/_modules/gpiozero/input_devices.html)). Otherwise, check the wiring on my [`rpi-buttons`](https://github.com/cgomesu/rpi-buttons) repo for an example of how to wire **current-limiting** (1k ohms) resistors and **pull-down** (10k ohms) resistors.  However, if you choose the latter alternative, you'll have to change the `gpiozero` deafult settings for the `Button` class. 
{: .notice .notice--info}

* Secure the cables as much as possible:

[![Securing the Cables](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-secure.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-secure.jpg)

* **Before closing the box**, [test your button box controller](#using-the-button-box-controller).  Remember that once closed, these cases are not meant to be (easily) opened.  If there's anything that needs to be connected to the Raspberry Pi, this is the time to do so.  For example, I wanted to make extra GPIO pins available to an LCD and added power and ethernet cable extensions:

[![Extra Cables](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-extra-cables.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/diy-extra-cables.jpg)

* **Once you got everything working as intended**, close the box.  Try to leave the area where the cpu heatsink is as clear as possible.  Be gentle when closing the box and guide the cables where they should be while closing the box (use a pen or something).

[![RPi and buttons - Closed 01](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/preview-rpi-and-buttons-closed.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-12-08-Rpi-button-box-ehdd-enclosure/preview-rpi-and-buttons-closed.jpg) 

* Go play with it!

## Using the button box controller

### Usage
```
./button-box.py -h
```
```
usage: button-box.py [-h] [--buzzer BUZZER] [--cmd {Popen,run}]
                     [--g1_pressed G1_PRESSED] [--g1_released G1_RELEASED]
                     [--s1_held S1_HELD] [--s1_released S1_RELEASED] [-i] [-d]

RPi button box controller. Repo: https://github.com/cgomesu/rpi-button-box

optional arguments:
  -h, --help            show this help message and exit
  --buzzer BUZZER       If installed, the buzzer's GPIO number.
  --cmd {Popen,run}     Popen: run external scripts in a NON-BLOCKING fashion.
                        run: run external scripts in a BLOCKING fashion.
                        Default=run
  --g1_pressed G1_PRESSED
                        /path/to/script to run when G1 is pressed. The
                        --btn_pressed arg is available to other PUSH buttons
                        as well.
  --g1_released G1_RELEASED
                        /path/to/script to run when G1 is released. The
                        --btn_released arg is available to other PUSH buttons
                        as well.
  --s1_held S1_HELD     /path/to/script to run when S1 is held. The
                        --btn_held arg is available to other SWITCHES as well.
  --s1_released S1_RELEASED
                        /path/to/script to run when S1 is released. The
                        --btn_released arg is available to other SWITCHES as
                        well.
  -i, --info            Show the board information.
  -d, --debug           Print additional messages to the terminal.
```

As mentioned, there are **hidden arguments** for passing external scripts to be executed upon a button event, such as pressing `G2`, or releasing `S3`.  More specifically, in addition to `--g1_*` and `--s1_*` args shown in the help output, the program accepts args for any of the other seven buttons, as follows:

* script for `pressed` and `released` events: the **push buttons** `--g1_*`, `--b1_*`, `--r1_*`, `--g2_*`, `--b2_*`, and `--r2_*`,
* script for `held` and `released` events: the **switches** `--s1_*`, `--s2_*`, and `--s3_*`.

The script generates a `button-box.log` log file to keep track of controller-related events.

### Examples
* Output info about the board
```
./button-box.py -i
```

* Run the controller in debug mode (prints more messages to the terminal) and enable the buzzer (`GPIO4`)
```
./button-box.py -d --buzzer 4
```

* Run the controller with a buzzer and execute `/opt/rpi-button-box/scripts/template.sh` whenever the push button `R2` is **pressed**:
```
./button-box.py --buzzer 4 \
--r2_pressed '/opt/rpi-button-box/scripts/template.sh'
```

* Same as before, but don't wait for the external script to finish running (**non-blocking** command execution):
```
./button-box.py --buzzer 4 --cmd Popen \
--r2_pressed '/opt/rpi-button-box/scripts/template.sh'
```

### Run the controller as a service
If you're using options different than the default values, first edit the `systemd/button-box.service` file to include those options into the `ExecStart=` command execution.  (Reminder: If you've installed Python3 libraries with a user different than `pi` and the `rpi-button-box` dir is owned by another user, you'll have to edit the `systemd/button-box.service` file to reflect such changes. Otherwise, you will run into errors related to permission.) Then, run `button-box.py` as a service, as follows:

1. Copy the `systemd/button-box.service` file to your systemd directory
```
sudo cp /opt/rpi-button-box/systemd/button-box.service /lib/systemd/system/
```
2. Enable the service and start it
```
sudo systemctl enable button-box.service
sudo systemctl start button-box.service
```
3. Check the service status to make sure it's running without issues
```
systemctl status button-box.service
```

### Bash script template
I've included a template for bash scripts on `scripts/template.sh` that anyone can use to create their customized set of commands to run upon a button event.  Just copy the template, rename it, edit it according to your needs, and when running the `button-box.py` controller, add the full path to the new script to one (or more) of the `--btn_*` arguments.  For example:
```
./button-box.py --buzzer 4 \
--g1_pressed '/opt/rpi-button-box/scripts/notification.sh' \
--b1_pressed '/opt/rpi-button-box/scripts/switch_cameras.sh' \
--r1_pressed '/opt/rpi-button-box/scripts/lights_toggle.sh' \
--g2_pressed '/opt/rpi-button-box/scripts/test_connectivity.sh' \
--b2_pressed '/opt/rpi-button-box/scripts/shutdown.sh' \
--r2_pressed '/opt/rpi-button-box/scripts/reboot.sh' \
--s2_held '/opt/rpi-button-box/scripts/alarm_on.sh' \
--s2_released '/opt/rpi-button-box/scripts/alarm_off.sh' \
--s3_held '/opt/rpi-button-box/scripts/emergency.sh'
```

## Alternatives to Python
There are many other languages you can use to make your own button box controller. [**Node-RED**](https://nodered.org/), for example, is a nice alternative to users unfamiliarized with programming languages.  It uses flow-based programming and has built-in input nodes for the RPi GPIO pins, which makes programming a button box a matter of connecting a line between two nodes.  Also, it makes very easy to create a web dashboard for your button-box that you can access from anywhere.  Check it out.

[top](#){: .btn .btn--light-outline .btn--small}

# Conclusion
This conlcudes the tutorial on how to repurpose an old external HDD enclosure into a button box for the Raspberry Pi (or any other SBC).  Check the [changelog](#changelog) for updates.  If you have any questions, feel free to [get in touch with me](/contact/).  For anything related to the controller, please visit the [rpi-button-box repo](https://github.com/cgomesu/rpi-button-box).

[top](#){: .btn .btn--light-outline .btn--small}</content><author><name>Carlos Gomes</name></author><category term="blog" /><category term="DIY" /><category term="raspberrypi" /><category term="rpi" /><category term="hdd" /><category term="enclosure" /><category term="button" /><category term="box" /></entry><entry><title type="html">Mesh networking: A guide to using free and open-source software with common hardware</title><link href="/blog/Mesh-networking-openwrt-batman/" rel="alternate" type="text/html" title="Mesh networking: A guide to using free and open-source software with common hardware" /><published>2020-12-07T12:10:00-03:00</published><updated>2020-12-07T12:10:00-03:00</updated><id>/blog/Mesh-networking-openwrt-batman</id><content type="html" xml:base="/blog/Mesh-networking-openwrt-batman/"># Changelog
**Jan 9th, 2021**, Update #2: Added instructions on how to automatically upgrade all installed packages with a single command.  This information is in [Updating and installing packages](#updating-and-installing-packages).
{: .notice .notice--info }
**Jan 9th, 2021**, Update #1: Added a new section about [hardware-specific configurations](#hardware-specific-configurations) that are sometimes required for enabling the `mesh point` mode of operation.
{: .notice .notice--info }
**Dec 7th, 2020**: Publication of the original guide
{: .notice .notice--info }

[top](#){: .btn .btn--light-outline .btn--small}

# Introduction
In this tutorial, we will learn how to create [**mesh networks**](https://en.wikipedia.org/wiki/Wireless_mesh_network) ([**IEEE 802.11s**](https://en.wikipedia.org/wiki/IEEE_802.11s)) using [**OpenWrt**](https://openwrt.org/) and the [layer-2](https://en.wikipedia.org/wiki/Data_link_layer) implementation of the *Better Approach to Mobile Adhoc Networking*, called [**batman-adv**](https://www.kernel.org/doc/html/v4.15/networking/batman-adv.html).  All the software mentioned here is **free** and **open-source**, as opposed to commercial alternatives ([UniFi Mesh](https://unifi-mesh.ui.com) or [Google's Nest Wifi](https://store.google.com/us/product/nest_wifi)).

This is not meant to be an exhaustive presentation of any of the covered topics. If you have suggestions on how to improve this guide, feel free to [get in touch with me](/contact/). I'm always eager to learn new things and share them. Also, I plan on updating this article every once in a while to best reflect my knowledge about the topics covered here and to add information provided by the readers. Check the [changelog](#changelog) for updates.

[top](#){: .btn .btn--light-outline .btn--small}

# Why am I writing this guide?
Even though the concept of mesh networking has been around for quite some time now, the documentation of its implementation is still scarce/nichey, proprietary, or outdated.  I don't feel qualified to speculate on why this is so but I find it odd because many of the radio devices found in popular wireless routers actually support mesh networking--but the original firmware rarely supports it.

My intention with this tutorial is to help closing the gap between concept and implementation of mesh networking using up-to-date software that anyone can download and install on cheap, commonly available hardware--primarily consumer wireless routers (from old to new, single- or multi-band) but the principles should be extendable to any cellphones, laptops, PCs or servers running **Linux**.  The content is partially based on my own experience and builds upon the work of other, much more talented individuals who shared their knowledge on the Web.  More specifically, the content is notably influenced by the following:

* Brian Innes workshop about using Raspberry Pis to create a mesh network for sharing sensor data wirelessly ([Github repo](https://github.com/binnes/WiFiMeshRaspberryPi))
* Andreas Spiess [LoRa mesh project](https://www.youtube.com/watch?v=TY6m6fS8bxU)
* Maintaners of the [OpenWRT documentation](https://openwrt.org/docs/start) and the [B.A.T.M.A.N. wiki](https://www.open-mesh.org/projects/batman-adv/wiki)
* Multiple users from the OpenWrt forum who shared their opinions over the years. To name a few,  the users [jeff](https://forum.openwrt.org/u/jeff), [mcarni](https://forum.openwrt.org/u/mcarni), [oavaldezi](https://forum.openwrt.org/u/oavaldezi), [slh](https://forum.openwrt.org/u/slh), and many others. Thanks for keeping the posts public.

[top](#){: .btn .btn--light-outline .btn--small}

# Objectives
1. Get familiar with `/etc/config/` files in OpenWrt devices (namely, `wireless`, `network`, `dhcp`, `firewall`) to quickly and permanently configure mesh nodes. 
2. Edit files directly from the terminal using the default text editor `vi`.
3. Configure OpenWrt devices to play one of three possible roles in the network: (a) mesh node, (b) mesh + bridge node, or (c) mesh + gateway node.
4. Install and configure the Kernel module `batman-adv` on an OpenWrt device using the `opkg` package manager.
5. Use `batctl` to test, debug, and monitor connectivity within the mesh.
6. Add encryption to the mesh network with the package `wpad-mesh-openssl`.
7. Use VLANs to create `default`, `iot`, and `guest` networks within the mesh using `batman-adv`.

[top](#){: .btn .btn--light-outline .btn--small}

# Outline
From this point forward, the article is divided into four main parts: 
1. [Concepts and documentation](#concepts-and-documentation): *Optional for advanced users.* Brief introduction to just enough network concepts to allow the implementation of simple mesh networks. When appropriate, a link to the relevant OpenWrt documentation was also provided.  
2. [Hardware](#hardware): *Optional for everyone*. A few notes about the hardware used in the examples and recommendations for those who are planning on buying new/used devices for their mesh project.
3. [Software](#software): *Optional for everyone*. A few notes about the software used in the examples.
4. [Implementation](#implementation): *Required*. Step-by-step procedure to configure mesh nodes, bridges, and gateways.  It goes from flashing OpenWrt to configuring VLANs with `batman-adv`. You probably came here for this part.

[top](#){: .btn .btn--light-outline .btn--small}

# Concepts and documentation

## Main network definitions
* Mesh [node](https://en.wikipedia.org/wiki/Node_(networking)): Any network device that is connected to the mesh network and that helps routing data to (and from) mesh clients.  Here, however, if a mesh node acts as a bridge or gateway, it will always be referred by the latter role, even though by definition, mesh bridges and mesh gateways are also mesh nodes.  
  In addition, even though it's possible to route mesh traffic via cable, in this tutorial, *all mesh nodes are also wireless devices*, meaning that they have access to a radio with [**mesh point** (802.11s)](https://en.wikipedia.org/wiki/IEEE_802.11s) capabilities.
  * [Learn about the OpenWrt wireless config **/etc/config/wireless**](https://openwrt.org/docs/guide-user/network/wifi/basic)

* [Bridge](https://en.wikipedia.org/wiki/Bridging_(networking)): A network device that joins any two or more network interfaces (e.g., LAN ethernet and wireless) into a single network.  Here, when a device is referred to as a bridge, it means that in addition to being a mesh node, the only other thing it does is bridge interfaces.  But of course, a gateway *device*, such as a router with a built-in modem, or a firewall appliance, may also work as a bridge for multiple interfaces. The distinction in the examples is just used to highlight its main role in the network.  Therefore, a mesh bridge in this tutorial is a mesh node that simply bridges the mesh network with a WiFi access point  for non-mesh clients, for example, or its LAN ports.

* [Gateway](https://en.wikipedia.org/wiki/Gateway_(telecommunications)): A network device that translates traffic from one network (LAN) to another (WAN) and here, acts as both a **firewall** and **DHCP server**.  (If there's more than one DHCP server in the same network, they assign IPs to different ranges, such as `.1-100`, `.101-200`, and so on.)
  * [Learn about the OpenWrt network config **/etc/config/network**](https://openwrt.org/docs/guide-user/base-system/basic-networking)

* [DNS](https://en.wikipedia.org/wiki/Domain_Name_System): In brief, a system for translating domain names (e.g., `cgomesu.com`) into IP addresses (`185.199.108.153`, `185.199.109.153`, `185.199.110.153`, `185.199.111.153`). DNS filtering systems, such as [PiHole](https://pi-hole.net/), work by catching such requests--usually sent through port `53`--and checking if the domain is blacklisted or not.  In this tutorial, we will always use an external DNS server, such as `1.1.1.1` (Cloudflare) or `8.8.8.8` (Google), but if you have your own DNS resolver, feel free to use it instead when configuring your mesh network but then make sure the mesh network/VLAN has access to its address.

* [DHCP](https://en.wikipedia.org/wiki/Dynamic_Host_Configuration_Protocol): An IP management system that dynamically assigns layer-3 addresses for devices connected to a network. For instance, it might dynamically assign IPs between `192.168.1.0` and `192.168.1.255` (i.e., `192.168.1.0/24`) to any devices connected to LAN. Of note, because this is a network layer protocol, it uses IP addresses, whereas `batman-adv` uses MAC addresses because it works at the data link layer (and therefore, `batman-adv` actually doesn't need DHCP and IPs to discover and manage mesh clients but we're going to use them to make it more intuitive and easier to integrate mesh with non-mesh clients).
  *  [Learn about the OpenWrt DNS and DHCP config **/etc/config/dhcp**](https://openwrt.org/docs/guide-user/base-system/dhcp)

* [Firewall](https://en.wikipedia.org/wiki/Firewall_(computing)): A network system that monitors and controls network traffic, such as specifying rules for incoming WAN traffic (e.g., `deny all`), outgoing LAN traffic (`accept all`), geoblocking and IP filtering systems, intrusion prevention/detection systems ([Suricata](https://suricata-ids.org/)), and so on.  [OpenSense](https://opnsense.org/) and [pfSense](https://www.pfsense.org/) are examples of dedicated firewall software. If a mesh node is acting as a mesh gateway, it's imperative to configure the firewall or your mesh network will likely end up without access to external networks (e.g., WAN) and their services (e.g., DNS servers).
  * [Learn about the OpenWrt firewall config **/etc/config/firewall**](https://openwrt.org/docs/guide-user/firewall/firewall_configuration)

* [VLAN](https://en.wikipedia.org/wiki/Virtual_LAN): A *virtual* LAN that is partitioned and isolated in a network at the layer-2 level.  They are often followed by an integer to differentiate each other (e.g., VLAN 1, VLAN 50) and used to better manage network clients that belong to different groups (e.g., administrators, IoT devices, security cameras, guests).

## Network topologies

{% include video id=&quot;zbqrNg4C98U&quot; provider=&quot;youtube&quot; %}
{:. text-center}

## Mesh networks

### What are mesh networks?

{% include video id=&quot;tYLU755T6_I&quot; provider=&quot;youtube&quot; %}
{:. text-center}

### Where can I learn more about mesh networking?
* Wikipedia articles about [mesh networking](https://en.wikipedia.org/wiki/Mesh_networking) and [wireless mesh networks](https://en.wikipedia.org/wiki/Wireless_mesh_network)
* [Peer-reviewed papers or books](https://scholar.google.com/scholar?q=mesh+networking)

### Routing protocols
There are [dozens of algorithms](https://en.wikipedia.org/wiki/Wireless_mesh_network#Protocols) for routing packets in a mesh network.  A few notable ones are the Optimized Link State Routing (OLSR) and the Hybrid Wireless Mesh Protocol (HWMP). 

In this tutorial, however, we will cover only one of them, called [*Better Approach to Mobile Adhoc Networking*](https://en.wikipedia.org/wiki/B.A.T.M.A.N.) (**B.A.T.M.A.N.**), because [it has long been incorporated into the Linux Kernel](https://www.kernel.org/doc/html/latest/networking/batman-adv.html) and is thus easily enabled on Linux devices.  It is also a [fairly well-documented](https://www.open-mesh.org/projects/batman-adv/wiki) algorithm that [has been continuously improved](https://www.open-mesh.org/projects/open-mesh/activity) over the years.  Another noteworthy feature of `batman-adv` is its lack of reliance on layer-3 protocols for managing mesh clients because it works at the layer-2 and its ability to create VLANs.  Think of it as if it were a big, smart, virtual switch, in which its VLANs are port-based segmentations.  If you want an interface to use a particular mesh VLAN, just &quot;plug it&quot; into the approriate port of the `batX` switch (e.g., bridge `if-guest` and `bat0.2` to give the guest network access to the `bat0` VLAN 2).

#### batman-adv
As mentioned before, B.A.T.M.A.N. has gone through multiple changes over the years, which means that there are actually *multiple versions of the algorithm*. I've had a good experience with [**B.A.T.M.A.N. IV**](https://www.open-mesh.org/projects/batman-adv/wiki/BATMAN_IV) and therefore, the examples here make use of it.  However, you are free to try whatever version you want and even run them in parallel to each other, by assigning a different `batX` interface to each version of the algorithm (versions are chosen with `option routing_algo` in the `/etc/config/network` config file for each enabled `batX` interface).

Config-wise, there's very little to do because the default settings should work very well in most environments.  One exception is when you have multiple gateways in the network to provide high availability, for example, and you might want to let each mesh node know about them and their speeds to better route the mesh traffic.  This requires setting `option gw_mode` to `server` or `client`, for example.  Many other tweaks that are not covered here are [described in their wiki](https://www.open-mesh.org/projects/batman-adv/wiki/Doc-overview#Protocol-Documentation).

#### batctl
Another very cool feature of B.A.T.M.A.N. is the ability to test, debug, monitor, and set settings with the package [`batctl`](https://downloads.open-mesh.org/batman/manpages/batctl.8.html).  A few noteworthy options:

* Ping mesh node/client with its MAC address `f0:f0:00:00:00:00`
```
batctl p f0:f0:00:00:00:00
```
* [`tcpdump`](https://linux.die.net/man/8/tcpdump) for all mesh traffic in the `bat0` interface
```
batctl td bat0
```
* Prints useful stats for all mesh traffic, such as sent and received bytes
```
batctl s
```
* Shows the neighboring mesh nodes
```
batctl n
```
* Displays the gateway servers (`option gw_mode 'server'`) in the mesh network
```
batctl gwl
```

It goes without saying that if you want to dive deep into `batman-adv`, you should take a good look at `batctl`, too.

[top](#){: .btn .btn--light-outline .btn--small}

# Hardware
Unless otherwise specified, all mesh nodes used in the various implementations had the following hardware:

* **Device**: [TP-Link WR-1043ND](https://www.tp-link.com/us/home-networking/wifi-router/tl-wr1043nd/) v1.8
* **Architecture**: Atheros AR9132 rev 2

[![TP-Link 1043nd](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/tplink-wr1043nd.jpg){:.PostImage}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/tplink-wr1043nd.jpg)

This was mainly a matter of convenience--I had a few lying around and they are very, very cheap--and because the examples in the OpenWrt documentation often refer to them as well, so the community support is good.

However, the general ideas presented here should apply to **any wireless device** that meets the following criteria:

1. Compatible with the latest OpenWRT version. Refer to their [**Hardware List**](https://openwrt.org/toh/start);
2. Has access to a radio that supports the **mesh point** (**802.11s**) mode of operation. If you already have OpenWrt installed on a wireless device, you can type `iw list` and search for `mesh point` under **Supported interface modes**, or simply check if the following command outputs `* mesh point` below the name of a detected radio (e.g., `phy0`, `phy1`):

	```
iw list | grep -ix &quot;^wiphy.*\|^.*mesh point$&quot;
```

	If it does, then the associated radio can be configured as a mesh point.

Now, if you're looking for devices to buy and experiment on, my suggestion is to look for dual-band wireless routers to allow a better segmentation of the wireless networks.  If you can afford spending more for a mesh node, look for tri-band devices.  Netgear and Linksys have solid options that are compatible with OpenWrt. For example, the Linksys WRT1900AC (v1/v2) dual-band wireless router would make for a good mesh node:

[![Linksys WRT1900AC](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/linksys-wrt1900ac.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/linksys-wrt1900ac.jpg) 

For single-board computer (SBC) fans like me, you can run OpenWrt with most of them and then use a combination of on-board wireless and USB adapter to create a powerful mesh node. [ClearFog boards](https://shop.solid-run.com/product-category/embedded-computers/marvell-family/clearfog-base-pro/) with one or two mini PCIe wireless cards would make very good candidates for such a project, for example:

[![ClearFog Pro](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/clearfog-pro.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/clearfog-pro.jpg) 

Of course, you can install OpenWrt on bare metal x86-64 machines (e.g., standard PC or server running Intel/AMD), which will give you lots of options to put together an impressive mesh device. However, if you just want your work/home laptops/PCs to *be part of the mesh* (i.e., become a mesh node), there are better alternatives than installing OpenWrt as its OS.  For example, you can run OpenWrt with a [virtual machine](https://openwrt.org/docs/guide-user/virtualization/start) or as a [docker container](https://github.com/openwrt/docker).  Naturally, it's also possible to configure `batman-adv` on Linux distributions other than OpenWrt, such as Arch, Debian, and Ubuntu.  See [Getting started with `batman-adv` on any Linux device](#getting-started-with-batman-adv-on-any-linux-device).

As mentioned before, even if the existing/on-board radio of your SBC/laptop/PC/server does not support the mesh point mode of operation, you can always buy a compatible PCIe card or USB adapter to turn your device into a mesh node and then use the other radio for another purpose.  For example, many [Alfa Network](https://www.alfa.com.tw/) adapters can operate in mesh point mode, like the cheap AWUS036NH: 

[![Alfa AWUS036NH](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/AWUS036NH.jpg){:.PostImage}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/AWUS036NH.jpg) 

**All that said**, most home users will be **just fine with a cheapo, used, old, single-band router**.  For a brand reference, TP-Link has good and affordable devices that can be used in a mesh networking project without issues.  If you're new to this, start from here (small, simple) and think about efficiency over power.  You don't need to drive a Lamborghini to get a snack at the grocery store.

## Hardware-specific configurations
Every once in a while, I run into hardware that is capable of operating in `mesh point` mode but the default OpenWrt firmware uses a module for the wireless adapter that is loaded with incompatible parameters.  Here is a list of a few of the known ones and their solution.

### ath9k modules
If your device uses the `ath9k` module, there's a chance that you'll need to enable the `nohwcrypt` parameter of the module to use the mesh *with encryption*.  First, however, try without changing the default module parameters.  After rulling out possible typos in the network and wireless configuration files, try the following:
1. Edit the `/etc/modules.d/ath9k` file and add `nohwcrypt=1` to it.  If there's something in the file, use a whitespace to separate parameters.
2. Save the file, and **reboot** your device. 
3. Once the device comes back, check if `nohwcrypt` is now enabled by typing 
   ```
   cat /sys/module/ath9k/parameters/nohwcrypt
   ```
   If `nohwcrypt` is enabled, the output will be `1`; otherwise, it will be `0`.
4. Check your mesh configuration once again and add encryption to your wireless mesh stanza.

* Known affected devices:

  | brand | model | version |
  |:---:|:---:|:---:|
  | TP-Link | WR-1043-ND | 1.8 |

### ath10k modules
I've noticed that radio devices that use the `ath10k` module and more specifically, the ones using `ath10k-firmware-qca988x-ct`, are not able to operate in `mesh point` mode by default.  If you check the syslog, you'll notice that there will be a few messages stating that the `ath10k` module must be loaded with `rawmode=1` to allow mesh.  However, I've tried that before without much success.  Instead, my current recommendation to get `mesh point` working with the **QCA988x** is the following (**Internet connection required** to download packages via `opkg`):
1. Remove the **Candela Tech** (`*-ct`) modules as follows:
   ```
   opkg remove ath10k-firmware-qca988x-ct kmod-ath10k-ct
   ```
2. Install the non-ct modules:
   ```
   opkg update &amp;&amp; opkg install ath10k-firmware-qca988x kmod-ath10k
   ```
3. Reboot your device and then check the status of your mesh network.

* Known affected devices:

  | brand | model | version |
  |:---:|:---:|:---:|
  | TP-Link | Archer C7 | 2.0 |
  | TP-Link | Archer C7 (US) | 2.0 |


[top](#){: .btn .btn--light-outline .btn--small}

# Software
Unless otherwise specified, all mesh nodes were running the following software:

[![OpenWrt default SSH welcome](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/openwrt-ssh-welcome.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/openwrt-ssh-welcome.jpg) 

* **Operating System**:
	* **Firmware**: OpenWrt 19.07.4 r11208-ce6496d796
	* **Linux kernel**: 4.14.195

* **Packages mentioned in the tutorial**:
	* [`batctl-default`](https://openwrt.org/packages/pkgdata/batctl-default): 2019.2-7
	* [`kmod-batman-adv`](https://openwrt.org/packages/pkgdata/kmod-batman-adv): 4.14.195+2019.2-9
	* [`wpad-mesh-openssl`](https://openwrt.org/packages/pkgdata/wpad-mesh-openssl): 2019-08-08-ca8c2bd2-4

To find out the version of all installed packages, type 

```
opkg list-installed
```

or if you prefer to filter the output, use grep.  For example, the following will show the version of all installed packages containing `bat` (e.g., `batctl`, `kmod-batman-adv`):

```
opkg list-installed | grep bat
```

Huge differences in firmware, kernel, or package versions *might* make the implementation of a mesh network a little bit different than the way it was explained here.  Of note, devices running the `batman-adv` **version 2019.0-2 and older** are certainly incompatible with the instructions found in this tutorial, the reason being that the module was modified after then to better integrate with the [network interface daemon](https://openwrt.org/docs/techref/netifd).  Fortunately, the implementation using old modules is just a simple as with the latest one. [Check what the B.A.T.M.A.N. wiki has to say about it](https://www.open-mesh.org/projects/batman-adv/wiki/Batman-adv-openwrt-config#Batman-adv-20190-2-and-older).  However, it's worth mentioning that with old batman modules, changes to `/etc/config/network` will likely require a reboot instead of simply reloading `/etc/init.d/network`.

Also, I've noticed that when installing `kmod-batman-adv`, the package manager will install a minimal version of `batctl`, called `batctl-tiny`, that lacks some of the options mentioned here (e.g., `batctl n` and `batnctl o`).  However, if you install `batctl` first and then `kmod-batman-adv`, the package manager will preserve `batctl-default`, which is the package used in this tutorial and that has all the options referred to in the [batctl man page](https://downloads.open-mesh.org/batman/manpages/batctl.8.html).

Finally, the installation of `wpad-mesh-openssl` will conflict with the already installed `wpad-basic` package.  This means **you have to remove the latter before installing the former**.  To remove the `wpad-basic` package, simply type

```
opkg remove wpad-basic
```

## VI text editor
The default text editor in a standard OpenWrt image is [**vi**](https://en.wikipedia.org/wiki/Vi), which is an old, screen oriented editor that most modern users will find counterintuitive to use.  Fortunately, once you get the hang of it, `vi` becomes very easy to use and it becomes a very convenient way of editing config files.  Here's all that you need to know about using `vi` in a terminal:

You can open a file by adding the filename as an argument to `vi`, as follows

```
vi /etc/config/network
```

and if the file does not exist, `vi` will create one with that name.  

By default, `vi` will start in **command mode**.  Such a mode let's you navigate the file with the arrow keys and use the *delete button* to delete characters.  (Also, in command mode, you can type `dd` to delete entire lines, which is very useful if you need to delete lots of things quickly.)  

However, if you need to type characters and have more flexibility to edit the file, you need to tell `vi` to enter **insert mode**.  To enter insert mode, type (no need to hit return/enter afterwards)

```
i
```

and at the bottom of the screen, you will see that it now shows a `I` to indicate that `vi` is in insert mode.  You can now type freely and even paste multiple things at once in insert mode. 

When you're done, press the button **Esc** to go back into command mode.  Notice that at the bottom of the screen, now there's a `-` where the `I` was, which tells you you're in command mode once again.

In command mode, you can then **write changes to the file** by typing (followed by return/enter)

```
:w
```

Now you've saved the file. To quit, type

```
:q
```

Alternatively, you can *write and quit* by simply typing `:wq`.

`vi` has other commands as well but honestly, that's pretty much all that you need to know about `vi` in order to use in the examples covered here.  Give it a try!  

## Alternatives to VI
Now, if you still don't like to use `vi`, you can always transfer files from your laptop/PC to OpenWrt via sftp, for example, or utilities like [`scp`](https://en.wikipedia.org/wiki/Secure_copy_protocol).

[top](#){: .btn .btn--light-outline .btn--small}

# Implementation
In this section, we will see how to configure **four mesh nodes** in **three different network topologies**. More specifically: 

* **Gateway-Bridge**: A mesh network in which one node plays the role of a mesh gateway and another, of a bridge, while the remaining are just mesh nodes.  This is a very typical scenario for a home or small office, for example.

[![Topology - Gateway-Bridge](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-gateway-bridge.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-gateway-bridge.jpg)

* **Bridge-Bridge**: Two nodes play the role of a bridge, therefore making the mesh network transparent to the external (non-mesh) networks.

[![Topology - Bridge-Bridge](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-bridge-bridge.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-bridge-bridge.jpg)

* **Gateway-Gateway**: Two nodes play the role of a gateway to provide high-availability to mesh clients/nodes.

[![Topology - Gateway-Gateway](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-gateway-gateway.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-gateway-gateway.jpg)

First, however, we will start with the aspects that are common to all topologies, such as planning the mesh network, and the installation and basic configuration of OpenWrt mesh nodes.  Then, we will move to the specifics of each of the aforementioned mesh network topologies.  Finally, we end the section with a slightly more complex scenario to illustrate how to create **mesh VLANs** with `batman-adv` and a very brief introduction to using `batman-adv` on other Linux distros.

[![Topology - Mesh VLANs](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-mesh-vlans.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-mesh-vlans.jpg)

Even though the examples show static nodes, **none of the mesh nodes need to be static**. The mesh network and its components can be partially or totally mobile. For example, if some of your nodes are mobile units (e.g., vehicles, drones, robots, cellphones, laptops), they can leave and join the mesh, recreate the mesh elsewhere, join a completely different mesh, and so on.  The routing algorithm (`batman-adv`) will automatically (and  seamlessly) take care of changes to the network topology. (But of course, if there's a single gateway and it does not reach any node, the network is bound to stop working as intended without proper configuration to handle such scenarios.)

[![Topology - Moving nodes](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-moving-nodes.gif){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-moving-nodes.gif) 

## Planning
Just like any other type of network, deploying a mesh network--especially over large areas, with dozens of nodes--requires a fair deal of planning; Otherwise, you are bound to experience, for instance, bottlenecks, uneven access point signal quality, and unstable WAN connectivity across the mesh.  Also, features like **high availability** go well beyond the configuration and topology of a mesh network (e.g., power source, whre your WAN connections are coming from, and the hardware you are using all play important roles when it comes to high availability).  Mesh networks are very, very easy to scale but planning is key.  

*Eli the Computer Guy* has an old video about mesh networks that goes into things like high availability and bottlenecks.  If that matters to you, take a look. The relevant content **starts at `03:30`** and **ends at `17:30`**, approximately.

{% include video id=&quot;T7fJwAyALss&quot; provider=&quot;youtube&quot; %}
{:. text-center}

The examples in this tutorial are simple *by design*--they were created to illustrate different scenarios in a way that makes it easy to understand what is going on. The idea is to use the examples as templates for more complex implementations.

## OpenWrt installation and initial configuration
Now that you have the hardware, the first thing to do is to install OpenWrt.  Flashing a default OpenWrt image onto a ***compatible device* is a very easy and safe procedure** because it's been tested multiple times.  (For extra safety precautions, you might want to search the Web for your device + OpenWrt to see if there's any indexed forum post or comment regarding installation issues and bugs, for example.)  

If you're new to this, the folks at OpenWrt were kind enough to provide a plethora of instructions on [how to install and uninstall OpenWrt](https://openwrt.org/docs/guide-user/installation/start) and even put together an [**installation checklist**](https://openwrt.org/docs/guide-user/installation/generic.flashing#installation_checklist).  At the very least, do the following:

1. Look for your device's **model and version** in the [**Table of Hardware**](https://openwrt.org/toh/start) and open its **Device Page** (e.g., [TP-Link TL-WR1043ND](https://openwrt.org/toh/tp-link/tl-wr1043nd));
2. Double check that the **model and version** match your device's **model and version** in the **Supported Versions** table;
3. In the **Installation** table, you will find a column called *Firmware OpenWrt Install URL* and another one called *Firmware OpenWrt Upgrade URL*. If your device is **still running the original firmware**, then download the binary from the *Firmware OpenWrt **Install** URL* column; otherwise, download the binary from the *Firmware OpenWrt **Upgrade** URL* column.  Both files should have a `.bin` extension;
4. Regardless of the binary file downloaded, [**verify its checksum**](https://openwrt.org/docs/guide-quick-start/verify_firmware_checksum) afterwards;
5. Disconnect your laptop/PC from any access point or switch, and connect your laptop/PC directly to the device's ethernet port. 
6. Open your device's web UI, go to its Settings and/or find the **Firmware Upgrade** option. Then, select the downloaded OpenWrt binary, and let it do its thing. Once it's done, the device will reboot with OpenWrt installed. (You should be able to reach it at `192.168.1.1` if connected to a LAN port.)

If you can reach the OpenWrt web UI, then you've successfully installed OpenWrt and it's now time to configure it.  

### Initial configuration
As mentioned before, we **will not use the web UI** in this tutorial, even if the OpenWrt image you're using has LuCI installed by default.  Instead, we will access our device and configure it using only **SSH**.  So, open a terminal and `ssh` into your OpenWrt device, as follows

```
ssh root@192.168.1.1
```

in which `192.168.1.1` is your OpenWrt device's IP address (that's usually the case after a fresh install but if it's different, use the proper IP then). Because this is the first time using the system, you'll need to set a password for the `root` user.  You can do that by typing

```
passwd
```

and following the instructions.  At this point, it's good practice to label this device (e.g., `node01`) and take note of its **MAC address**.  To find out the latter, type

```
ip link
```

and keep a record of the device's name and its MAC address--if there are multiple different addresses, take note of all of them and their interface.

(*Optional*: [Configure key-based authentication](https://openwrt.org/docs/guide-user/security/dropbear.public-key.auth) and [disable password login](https://openwrt.org/docs/guide-user/base-system/dropbear). Reboot and check that `ssh` access methods are correctly configured.)  

From this point forward, we will start editing files using `vi`.  If you've not read the [section about how to use `vi`](#vi-text-editor) yet, this is a good time to do so.
{: .notice .notice--warning }

### Default config for the hardware
Regardless of the hardware, **before doing anything related to the mesh network**, always take your time and **study the default configuration** found in `/etc/config/`.  For reference, I usually go over the following:

* How many ethernet ports?
* Are they labeled either LAN or WAN or there's both?
* In `/etc/config/network`, how is the router handling multiple ethernet ports? If there's both LAN and WAN, how is the router separating LAN from WAN?
* If there is both LAN and WAN, how is the firewall handling them in `/etc/config/firewall`? (Probably two zones, LAN and WAN, with LAN-&gt;WAN accept all but WAN-&gt;LAN deny all?)
* In `/etc/config/dhcp`, how is the device handling IP addresses?  (Is there a DHCP server for LAN?)

And finally, look at the wireless settings (`/etc/config/wireless`):

* How many radio devices and their names? (e.g., `radio0`)
* Configuration-wise, what is the device using by default vs. what is it capable of? (`iw list`)
* Is the radio enabled or disabled? (Keep/add `option disabled 1` to disable it before configuration; to re-enable, simply comment this line out or set the value to `0`.)
* Are there pre-configured wireless access points being broadcast?  If yes, which `option network` is it using by default? (Likely `lan` or whatever the LAN interface is being called in `/etc/config/network`.)

For example, many wireless routers, including the TP-Link WR1043ND, have LAN and WAN ports which are handled by a `switch` configuration with VLANs enabled to separate LAN from WAN.  Take note of it;  understand what is going on in the config files;  play with them;  then, continue.  Also, take this opportunity to go over the **Device Page** to check if there's any warnings or special configuration notes (e.g., [warnings and gotchas with the 1043ND](https://openwrt.org/toh/tp-link/tl-wr1043nd#warningsgotchas)).

This understanding is instrumental to the way the device will be configured to play different roles in the mesh network and a good grasp of the device's default settings will greatly reward you later on.

### Updating and installing packages
(*Only experienced users*: If you used a default image, this is a good opportunity to remove unnecessary packages. See the OpenWrt FAQ for a reference of [safe to remove packages](https://openwrt.org/faq/which_packages_can_i_safely_remove_to_save_space), for example. If this is your first time playing with mesh, leave any unmentioned pkg alone until you get everything working as intended.)

In order to update and install packages, you need to give your device **temporary access to the Internet**.  More often than not, if you have an existing network with access to the Internet on-site, then just connect the device to a router/switch via cable.  If that doesn't work, go ahead and configure your device to act like a [**dumb access point**](https://openwrt.org/docs/guide-user/network/wifi/dumbap) first.  You can check that the device has access to the Internet by `ping`ing `google.com` or `8.8.8.8`, as follows

```
ping google.com
```

If it all looks good, it's time to **update the package list**, as follows

```
opkg update
```

*Optional*. Upgrade all installed packages. Type `opkg list-upgradable` to find which packages can be upgraded and then `opkg upgrade PKG`, in which `PKG` is the package name.  If `opkg list-upgradable` run into memory issues, try commenting out a few lines in `/etc/opkg/distfeeds.conf` and try again. Alternatively, it's possible to use the following command to automatically upgrade all packages at once, per the [opkg openwrt wiki examples](https://openwrt.org/docs/guide-user/additional-software/opkg#examples):
```
opkg list-upgradable | cut -f 1 -d ' ' | xargs opkg upgrade
```
**Be careful with mass upgrades though**, especially if you're running a device with limited memory.  You might end up even bricking your device.

Now, let's install the mesh-related packages and remove conflicting packages.  First, remove `wpad-basic` with

```
opkg remove wpad-basic
```

then install `batctl`, `batman-adv`, and `wpad-mesh-openssl` with

```
opkg install batctl kmod-batman-adv wpad-mesh-openssl
```

Make sure there are no error messages and if there are, troubleshoot them before proceeding. 

Remove the connection that gave your device temporary access to the Internet.  Then, **reboot** (type `reboot` in the terminal) and restart the SSH session with your laptop/PC still connected to the device via cable.

If you're using the **TP-Link WR1043ND v1.x** in your mesh project, take a look at my previous note about the [ath9k module](#ath9k-modules) in the [hardware section](#hardware).  In brief, if you have issues running the mesh with encryption, then you have to enable the `nohwcrypt` parameter of the `ath9k` module.
{: .notice .notice--warning }

## Mesh node basic config
It is time to configure the basics of our mesh network and nodes.  To do so, we will edit multiple files in `/etc/config/` but first, let's find out the capabilities of the detected radios in our wireless device, as follows

```
iw list
```

which will output something like this

```
Wiphy phy0
	max # scan SSIDs: 4
	max scan IEs length: 2257 bytes
	max # sched scan SSIDs: 0
	max # match sets: 0
	max # scan plans: 1
	max scan plan interval: -1
	max scan plan iterations: 0
	Retry short limit: 7
	Retry long limit: 4
	Coverage class: 0 (up to 0m)
	Device supports AP-side u-APSD.
	Device supports T-DLS.
	Available Antennas: TX 0x7 RX 0x7
	Configured Antennas: TX 0x7 RX 0x7
	Supported interface modes:
		 * IBSS
		 * managed
		 * AP
		 * AP/VLAN
		 * monitor
		 * mesh point
		 * P2P-client
		 * P2P-GO
		 * outside context of a BSS
	Band 1:
		Capabilities: 0x104e
			HT20/HT40
			SM Power Save disabled
			RX HT40 SGI
			No RX STBC
			Max AMSDU length: 3839 bytes
			DSSS/CCK HT40
		Maximum RX AMPDU length 65535 bytes (exponent: 0x003)
		Minimum RX AMPDU time spacing: 8 usec (0x06)
		HT TX/RX MCS rate indexes supported: 0-15
		Frequencies:
			* 2412 MHz [1] (20.0 dBm)
			* 2417 MHz [2] (20.0 dBm)
			* 2422 MHz [3] (20.0 dBm)
			* 2427 MHz [4] (20.0 dBm)
			* 2432 MHz [5] (20.0 dBm)
			* 2437 MHz [6] (20.0 dBm)
			* 2442 MHz [7] (20.0 dBm)
			* 2447 MHz [8] (20.0 dBm)
			* 2452 MHz [9] (20.0 dBm)
			* 2457 MHz [10] (20.0 dBm)
			* 2462 MHz [11] (20.0 dBm)
			* 2467 MHz [12] (20.0 dBm)
			* 2472 MHz [13] (20.0 dBm)
			* 2484 MHz [14] (disabled)
	valid interface combinations:
		 * #{ managed } &lt;= 2048, #{ AP, mesh point } &lt;= 8, #{ P2P-client, P2P-GO } &lt;= 1, #{ IBSS } &lt;= 1,
		   total &lt;= 2048, #channels &lt;= 1, STA/AP BI must match, radar detect widths: { 20 MHz (no HT), 20 MHz, 40 MHz }
	HT Capability overrides:
		 * MCS: ff ff ff ff ff ff ff ff ff ff
		 * maximum A-MSDU length
		 * supported channel width
		 * short GI for 40 MHz
		 * max A-MPDU length exponent
		 * min MPDU start spacing
	Supported extended features:
		* [ RRM ]: RRM
		* [ CQM_RSSI_LIST ]: multiple CQM_RSSI_THOLD records
		* [ CONTROL_PORT_OVER_NL80211 ]: control port over nl80211
		* [ TXQS ]: FQ-CoDel-enabled intermediate TXQs
```

Here, we are particularly interested in 

* the **supported modes of operation**, and more specifically, that the device is indeed able to operate in **mesh point** mode (it is), as shown under `Supported interface modes:`;
* the **total number of bands** (only one band, `Band 1`);
* then for each band
  * the possible [**`htmode`**](https://openwrt.org/docs/guide-user/network/wifi/basic#htmodethe_wi-fi_channel_width) (supports `htmode 'HT20'` and `htmode 'HT40'`), as shown in `HT20/HT40`, under `Capabilities:`;
  * the **acceptable channels** (from `channel '1'` to `channel '13'`), as shown under `Frequencies:`.  

With such information, we can now configure our radio devices in [`/etc/config/wireless`](https://openwrt.org/docs/guide-user/network/wifi/basic), as follows

```
vi /etc/config/wireless
```

and then edit each `config wifi-device` accordingly.  In the 1043ND, there's only one `wifi-device` and my config looks like the following

```
config wifi-device 'radio0'
        option type 'mac80211'
        option channel 3
        option hwmode '11g'
        option path 'platform/ahb/180c0000.wmac'
        option htmode 'HT20'
        option country 'BR'
```

If this radio device will be used for the mesh traffic, make sure all mesh nodes **use the same channel**.  However, if the radio will be used as an access point for non-mesh clients, **use a different channel than the mesh channel**.  In addition, for `HT20/HT40` devices, stick to `HT20` if you are deploying the mesh in a crowded area, such as an apartment building; otherwise, the interference might make `HT40` actually slower than `HT20`.  Finally, remember to edit the **country code** before enabling the radio.

Comment out any `config wifi-iface` automatically generated after a fresh install by adding a `#` at the beginning of each line, as follows

```
#config wifi-iface 'default_radio0'
#        option device 'radio0'
#        option network 'lan'
#        option mode 'ap'
#        option ssid 'OpenWrt'
#        option encryption 'none'
```

Then, at the end of the file, let's add a `wifi-iface` for the wireless mesh, called `wmesh`, as follows

```
config wifi-iface 'wmesh'
        option device 'radio0'	#must match the name of a wifi-device
        option ifname 'if-mesh'	#name for this iface
        option network 'mesh'	#mesh stanza in /etc/config/network
        option mode 'mesh'		#use 802.11s mode
        option mesh_id 'MeshCloud'	#like an ssid of the wireless mesh
        option encryption 'sae'	#https://openwrt.org/docs/guide-user/network/wifi/basic#wpa_modes
        option key 'MeshPassword123'	#mesh password if encryption is enabled
        option mesh_fwding 0	#let batman-adv handle routing
        option mesh_ttl 1		#time to live in the mesh
        option mcast_rate 24000	#routes with a lower throughput rate than the mcast_rate will not be visible to batman-adv
#       option disabled 1		#uncomment to disable
```

The comments are just for educational purpose. Feel free to remove them in your device's config file.
{: .notice .notice--info }

Because all mesh nodes must operate on the same channel, use the same authentication, etc., multiple config options are often dictated by the &quot;lowest common denominator&quot; across all mesh nodes--that is, the best possible config that will work with **all nodes**, not just the ones with the best hardware and software available.  For example, not all devices will necessarily be able to use SAE because it's very new and therefore, won't be able to connect to mesh networks that use it. Instead, you might want to set encryption to something like `psk2+aes`, which should be good enough for most devices out there. So, keep that in mind when configuring your mesh nodes.

**Save the file** and exit it.  

Now we need to configure [`/etc/config/network`](https://openwrt.org/docs/guide-user/base-system/basic-networking) to allow `wmesh` to use `batman-adv`.  To do so, edit the `network` file, as follows

```
vi /etc/config/network
```

and let's add an `interface` called `bat0` at the bottom of the file, as follows

```
config interface 'bat0'
        option proto 'batadv'
        option routing_algo 'BATMAN_IV'
        option aggregated_ogms 1
        option ap_isolation 0
        option bonding 0
        option bridge_loop_avoidance 1
        option distributed_arp_table 1
        option fragmentation 1
        option gw_mode 'off'
        option hop_penalty 30
        option isolation_mark '0x00000000/0x00000000'
        option log_level 0
        option multicast_mode 1
        option multicast_fanout 16
        option network_coding 0
        option orig_interval 1000
```

which has options with (mostly) default values to facilitate fine-tuning later on.  (For more details, refer to the [**Protocol Documentation**](https://www.open-mesh.org/projects/batman-adv/wiki#Protocol-Documentation) and more specifically, the [**Tweaking**](https://www.open-mesh.org/projects/batman-adv/wiki/Tweaking) section.)  Then, at the bottom of the same file, let's add an actual **network** interface to transport `batman-adv` packets, which in our case will be the network used by `wmesh` in the `/etc/config/wireless` config file, namely `mesh`, as follows

```
config interface 'mesh'
        option proto 'batadv_hardif'
        option master 'bat0'
        option mtu 2304
        option throughput_override 0
```

**Save the file** and exit. 

Next, let's **reboot** the device (type `reboot` in the terminal) and once it comes back online, `ssh` into it once again because we want to check that our `batman-adv` interfaces are up.  To do so, type

```
ip link | grep bat0
```
and if the config is right, you should now see `bat0` and `if-mesh` in the output. Similarly, we can use `batctl` to show us all active interfaces, as follows

```
batctl if
```

If all looks good, exit the `ssh` session, disconnect your laptop/PC from the wireless device (but keep it running nearby), and **go ahead and configure at least one other node**.  

Because we're starting SSH sessions with *different machines* using the *same IP addr* (`192.168.1.1`), it's quite possible that your SSH client will complaint about the authenticity of the host at `192.168.1.1`.  To get rid of this message, simply remove the relevant entry in your user's `known_hosts` file or delete it altogether.  On Linux distros, such file can be found at `~/.ssh/known_hosts`--that is, the `ssh` folder for your current user.
{: .notice .notice--warning }

Afterwards, `ssh` into one of the configured mesh nodes and type 

```
batctl n
```

which will show a table with the interfaces (`if-mesh`), MAC address of the neighboring mesh nodes, and when each of them was last seen.  Copy the MAC address (e.g., `f0:f0:00:00:00:01`) from each neighboring mesh node and ping them through the mesh (using `batctl p`) to see if they are all replying, as follows (press Ctrl+C to stop)

```
batctl p f0:f0:00:00:00:01
```

which should output something like the following if everything is working fine

```
PING f0:f0:00:00:00:01 (f0:f0:00:00:00:01) 20(48) bytes of data
20 bytes from f0:f0:00:00:00:01 icmp_seq=1 ttl=50 time=3.01 ms
20 bytes from f0:f0:00:00:00:01 icmp_seq=2 ttl=50 time=1.71 ms
20 bytes from f0:f0:00:00:00:01 icmp_seq=3 ttl=50 time=1.10 ms
--- f0:f0:00:00:00:01 ping statistics ---
3 packets transmitted, 3 received, 0% packet loss
rtt min/avg/max/mdev = 1.103/1.942/3.008/0.794 ms
```

Pat yourself on the back because you have successfully configured multiple mesh nodes! 

**Go ahead and configure all your mesh nodes the same way as before** and only then move on to bridges, gateways, and VLAN configs, as described next.

(*Optional*: This is a good time to [tweak the mesh configuration](https://www.open-mesh.org/projects/batman-adv/wiki/Tweaking) as well.)

## Troubleshooting mesh issues
These are a few tips in case you run into issues when configuring gateways and bridges. 

To test node to node connectivity, connect to a mesh node and use 

```
batctl p MAC
```

in which `MAC` is another node's MAC address.  If the node does not reply, there's an issue with `batman-adv` or its configuration.  Try rebooting both nodes before doing anything else.

A more powerful tool to see what is going on in the mesh network is the `tcpdump` utility for `batman-adv`.  To use it, connect to a mesh node and type

```
batctl td batX
```

in which `batX` is a `batman-adv` interface (usually `bat0` but if you have more than one, then `bat1`, etc.).  This is quite useful when configuring VLANs because it will show the VLAN ID of each client as well.  Depending on the scale of your mesh network, you might need to filter the output because things can get wild with `tcpdump` really fast.

For more details, see the [**batctl man page**](https://downloads.open-mesh.org/batman/manpages/batctl.8.html).

Finally, if you've been following my suggestion to name and take note of each device's MAC address, you can create a file called `bat-hosts` in `/etc/` that contains pairs of `MAC address` and `name`, as follows

```
f0:f0:00:00:00:00 node01
f0:f1:00:00:00:00 node02
f0:f2:00:00:00:00 node03
f0:f3:00:00:00:00 node04
```

which makes it much easier to identify the mesh nodes when issuing a command like `batctl n` and other debug tables.  As far as I'm aware, however, you have to create and update such file in each node because such information will just be available to nodes that have a `bat-hosts` file.

## Configuring common mesh networks
Here, we will see how to turn one or two of our configured mesh nodes into either a mesh **bridge** or a mesh **gateway**.  To avoid repetition, the configuration of bridges and gateways is described in more detail in the [first example](#gateway-bridge), and only a few small differences and observations are highlighted afterwards.  In addition, only IPv4 addresses and configurations were used but nothing prohibits the use of IPv6 in a mesh network.  

### Gateway-Bridge
This first example applies to the following topology:

[![Topology - Gateway-Bridge](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-gateway-bridge.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-gateway-bridge.jpg)

More specifically, the mesh has access to the WAN (**Network A**) via a *gateway device* and has a single, private network defined in the `192.168.10.0/24` IP range, which is used by both the **mesh network** devices and the **Network B**, non-mesh devices. The latter is enabled by a *bridge device* that works as an access point for non-mesh clients.

First, let's configure our **mesh gateway**.  

#### Mesh gateway configuration

Get one of the [pre-configured mesh nodes](#mesh-node-basic-config) that has at the very least two ethernet ports, a LAN port and a WAN port.  (This, of course, is not required for a gateway device because [there are multiple ways to connect to WAN](https://openwrt.org/docs/guide-user/network/wan/internet.connection) but having separate physical ports makes the explanation much simpler to follow.  If that is not your case, just adapt to whatever interfaces you have configured that play the role of default `lan` and `wan`.)  

If you've configured this node as a [dumb access point](https://openwrt.org/docs/guide-user/network/wifi/dumbap) to temporarily give it access to the Internet while updating and installing packages, undo the configuration before proceeding because we will use both the `firewall` and `dhcp` config files in the gateway configuration.  
{: .notice .notice--warning }

Connect your laptop/PC to the mesh node via cable using the LAN port--this way, the mesh node's IP address should still be `192.168.1.1`.  Then, `ssh` into the mesh node and let's take a look at the `/etc/config/network`, as follows

```
vi /etc/config/network
```

At the beginning of the file, there should a bunch of `config interface` for `loopback`, `lan`, and `wan`, for example, and at the end, there should be the mesh interfaces we previously created for the mesh node, namely `bat0` and `mesh`.  There are at least two options at this point: 

1. Create an entirely new `lan` interface for `bat0` (e.g., `lan_bat0`), at the expense of additional `dhcp` and `firewall` configuration; 
2. Or use the existing, default `lan` interface by simply bridging `lan` and `bat0`.

While the latter option is much easier than the former, we will choose the first here (i.e., create a new `lan` from the ground up) because it makes this tutorial compatible with multiple devices (switched or switchless) and it allows us to keep the default `lan` (`192.168.1.0/24`) as a management/debugging network.  (Later on, we will see how to bridge the default `lan` with any `bat0` VLAN, for example, so the default `lan` becomes accessible to the mesh as well.  For now, keep it simple.) 

At the bottom of the `/etc/config/network` file, let's add the following `lan_bat0` configuration

```
config interface 'lan_bat0'
#        option type 'bridge'	#uncomment if bridging in ifname as well
        option ifname 'bat0'
        option proto 'static'
        option ipaddr '192.168.10.1'	#static addr for this gateway on the 192.168.10.0/24 net
        option netmask '255.255.255.0'
#        list dns '1.1.1.1'	#uncomment to enable cloudflare dns server instead
        list dns '8.8.8.8'	#google dns server
```

**Save the file** and exit it. 

Next, let's edit the [`/etc/config/dhcp`](https://openwrt.org/docs/guide-user/base-system/dhcp) config to run a DHCP server on the new interface, as follows

```
vi /etc/config/dhcp
```

and at the end of the file, add the following

```
config dhcp 'lan_bat0'
        option interface 'lan_bat0'
        option start 50		#start leasing at addr 192.168.10.50
        option limit 100		#max leases, so for 100, leased addr goes from .50 to .149
        option leasetime '3h'
        option ra 'server'
```

**Save the file** and exit it. 

Finally, let's edit the [`/etc/config/firewall`](https://openwrt.org/docs/guide-user/firewall/firewall_configuration) config.  Many things that can be done at the firewall level and for this reason, it's often the most overwhelming part of the configuration.  Fortunately, in our case, all that we need to do here is simply **copy** the default `lan` config for the new `lan_bat0`.  That is, anything that has `lan` we will 

1. copy the related config;
2. paste it immediately below the equivalent default `lan` config;
3. and then change `lan` for `lan_bat0` in the new config. 

Start by editing the `firewall` config file with `vi`, as follows

```
vi /etc/config/firewall
```

then the first set of configs we will add (immediately below the equivalent `lan` config) is the **zone** settings, namely 

```
config zone
        option name     lan_bat0
        list network    'lan_bat0'
        option input    ACCEPT
        option output   ACCEPT
        option forward  ACCEPT
```

the second set of configs will be for the **forwarding** settings, namely

```
config forwarding
        option src   lan_bat0
        option dest  wan
```

and **that is it!**  

(*Optional*: At the end of the `firewall` config file, there's a bunch of examples that you could use as template for more avdanced usage of this device's firewall.  Feel free to play around with them **once you get everything up and running**.)

**Save the file** and exit it. 

(*Optional*: Because we're not going to use IPv6, I suggest disabling `odhcpd`, as follows

```
/etc/init.d/odhcpd stop &amp;&amp; /etc/init.d/odhcpd disable
```

and you could also comment out any related config in the files we just edited.)

**Reboot** the device and connect the **WAN** cable to the device's **WAN ethernet port**.

Once the device comes back online, `ssh` into it. Then, let's check the new configuration.  First, type

```
ip a | grep bat0
```

and as before, there should be `bat0` and `if-mesh` interfaces, but now, your gateway device should have the static IP `192.168.10.1` in the new `192.168.10.0/24` network under the `bat0` interface.  (Of note, if you enabled the `option type 'bridge'` in the `lan_bat0` stanza, then there should be an additional `br-lan_bat0`interface now because OpenWrt adds a `br-` prefix to bridges, and your device's static IP should be associated to it instead of the `bat0` interface.)

In addition, because we preserved the default `lan` configuration, the device will continue to have the static IP `192.168.1.1` and should always be reachable there with an ethernet cable directly connected to one of its LAN ethernet ports.

If you **don't see the static IP on the new network**, then review the files we have just configured because there's likely a misconfiguration.  Don't expect to get things working until you fix this issue.

#### Mesh bridge configuration
The configuration of a mesh bridge is much simpler than of a mesh gateway because contrary to the gateway config, our mesh bridge doesn't require the use of a DHCP server and firewall.  In fact, both services will be disabled in a mesh bridge and instead, the ony thing we will do is join interfaces to make them look like a single one to any connected device.

As before, get one of the other [pre-configured mesh nodes](#mesh-node-basic-config) and to start things off, we will configure it as a [dumb access point](https://openwrt.org/docs/guide-user/network/wifi/dumbap).  Follow the instructions in the OpenWrt documentation, except for the following when configuring the default `lan` interface

* add `bat0` to the list of `ifname`;
* set a static IP for the device on the `192.168.10.0/24` network, such as `192.168.10.10`, pointing to our gateway at `192.168.10.1`;
* the configuration of the default `lan` should then look something like this
  ```
  config interface lan
        option type 'bridge'
        option ifname 'eth0.1 eth1 bat0'	#ethX might be different for your device
        option proto 'static'
        option ipaddr '192.168.10.10'
        option netmask '255.255.255.0'
        option gateway '192.168.10.1'
        option dns '192.168.10.1'
``` 

After applying this configuration, it will let any **non-mesh client** to join the mesh **via ethernet cable**--that is, by connecting a cable to one of the LAN/WAN ports of the mesh bridge device.  As long as the gateway is reachable, everything should work like a standard network, you could use the device's own switch or connect the device to a switch and manage things there, and so on.

**Save the file** and exit it.

Similarly, you can create a **wireless access point** (WAP) for non-mesh clients, and the instructions in the [**dumb access point** documentation](https://openwrt.org/docs/guide-user/network/wifi/dumbap) will work just fine because it uses a network that is bridged with our mesh--namely, the default `lan`.  To avoid confusion, make sure to use **a different SSID** for the WAP(s) than the `mesh_id` used for the mesh.  In addition, if at all possible, use **a different radio or band** for the WAP(s) and set it to operate on **a different channel** than the mesh channel (`channel 3`, unless you changed yours).  If that is not possible, that is probably okay for most home users but keep in mind that node hoping will start affecting performance quite noticeably.

Finally, in the terminal, make sure to disable `dnsmasq`, `odhcpd`, and the `firewall`, as follows

```
/etc/init.d/dnsmasq stop &amp;&amp; /etc/init.d/dnsmasq disable 
/etc/init.d/odhcpd stop &amp;&amp; /etc/init.d/odhcpd disable
/etc/init.d/firewall stop &amp;&amp; /etc/init.d/firewall disable
```

**Reboot** your device and on your laptop/PC, **disable networking** altogether (this will force it to get a new IP from the bridge when it comes back)--alternatively, just disconnect the ethernet cable.

Once the bridge is back online (wait at least a minute or two to give it enough time to connect to the mesh first), **re-enable networking** on your laptop/PC (or reconnect the ethernet cable) and it should receive an IP addr from our mesh gateway in the `192.168.10.0/24` network (on a Linux distro, type `ip a` or `ip addr` or `ifconfig`), the bridge node should now be reachable at `192.168.10.10`, and you should be able to access the Internet from your laptop/PC through the mesh (try `ping google.com`, for example).  If something doesn't work, review the config files mentioned here and then go over the ones for the gateway, reboot all mesh nodes (gateway first, then nodes, then bridge) and test again.

### Bridge-Bridge
This second example applies to the following topology:

[![Topology - Bridge-Bridge](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-bridge-bridge.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-bridge-bridge.jpg)

Contrary to the first example, there's no mesh gateway device and as such, this topology could be used to extend an already existing private network (Networks A and B) over the wireless mesh (all defined in the `192.168.10.0/24` IP range).  However, to make matters simple, we will assume that **the existing network has a gateway/firewall** in either Network A or B that can be found at the IP addr `192.168.10.1`, and **there's a DHCP server being advertised on the network**.  (If your existing Networks A and B are not defined in the `192.168.10.0/24` IP range, just edit your previous config files accordingly and the mesh network will follow your existing network instead.)

Config-wise, the mesh bridges in this topology are configured exactly [as in the first example](#mesh-bridge-configuration), except for the following differences in the configuration of the `/etc/config/network` config file:

* **Each mesh bridge** should have a different static IP address in the `lan` interface, as indicated by `option ipaddr`.  For example, the first mesh bridge will have `option ipaddr '192.168.10.10'`, while the second mesh bridge will have `option ipaddr '192.168.10.11'`;

* The `option gateway '192.168.10.1'` in the default `lan` stanza must match an existing gateway on either Network A or B, and similarly, `option dns '192.168.10.1'` must point to a valid DNS resolver;

* As mentioned before, if your existing Networks A and B are not defined in the `192.168.10.0/24` IP range, then just edit the config file accordingly.

### Gateway-Gateway
The third and final example applies to the following topology:

[![Topology - Gateway-Gateway](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-gateway-gateway.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-gateway-gateway.jpg)

Specifically, there's only one private network (mesh, defined in the `192.168.10.0/24` IP range) and notably, **two** mesh gateways.  This provides &quot;high availability&quot; of the Internet connection to mesh nodes and surprisingly enough, the configuration of each mesh gateway is [just like in the first example](#mesh-gateway-configuration), with the following exceptions

* Like in the [bridge-bridge example](#bridge-bridge), we must assign different static IP addresses to **each** mesh gateway.  This is done by editing the `/etc/config/network` config file, and in the `lan` interface configuration, add a different IP addr next to the `option ipaddr` option.  For example, the first mesh gateway will have `option ipaddr '192.168.10.1'`, while the second mesh gateway will have `option ipaddr '192.168.10.2'`.

* Because we will now run **two** DHCP servers on **the same network**, we need to find a way of avoiding conflicts when assigning an IP address to new clients.  The easiest way of doing that is by assigning **different intervals** to each DHCP server running on the same network.  In OpenWrt, this is done by editing the `/etc/config/dhcp` config file, and in the `lan_bat0` DHCP configuration, we add a different starting point next to the `option start` option.  For example, while the DHCP server running on the first gateway will have `option start '50'`, the DHCP server running on the second gateway will have `option start '150'` instead.  This way, the first DHCP server leases addresses from `192.168.10.50` to `.149`, whereas the second leases addresses from `192.168.10.150` to `.249`.

* *Optional*: In the `bat0` interface config of the `/etc/config/network` config file, we can now enable the `option gw_mode 'server'` and specify the WAN connection speed with `option gw_bandwidth '10000/2000'` (i.e., 10000kbps download and 2000kbps upload).  Then, in each other **mesh node**, we set the `option gw_mode` to `'client'` instead of `'off'`.  This way, we can make each mesh node aware of the two gateways on the network (and their speeds) to better route mesh traffic.

## Mesh VLANs
You don't need to configure VLANs in order to use `batman-adv` but it is one of its best features.  In brief, this is a way of using **our already configured** wireless mesh network to route traffic **to/from multiple and all networks** in a secure, isolated way (as far as VLANs go).  No need for additional hardware--the combination of OpenWrt and `batman-adv` turns even cheap wireless hardware into powerful virtual switches.  It's just a matter of tagging the additional (and virtual) networks instead of using the untagged `bat0` (or similarly, in a port-based analogy, &quot;plugging&quot; standard interfaces into different ports of our `bat0` switch).  This is a fairly advanced topic but surprisingly easy to incorporate to our existing `batman-adv` configuration.

Consider, for example, the following network

[![Topology - Mesh VLANs](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-mesh-vlans.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/topo-mesh-vlans.jpg)

There's a single gateway device that provides WAN access to the mesh and Networks B, C, and D, which are all private networks defined in different IP ranges. In addition, all the Networks B, C, and D traffic should go via **any** mesh node in the mesh network while keeping them **isolated from each other**.  To make it easier to remember and distinguish each private network, let's call 

* Network **B** by `iot` network (`192.168.20.0/24`);
* Network **C** by `guest` network (`192.168.50.0/24`);
* and Network **D** by `default` network (`192.168.10.0/24`).

To implement such a mesh network with VLANs, we're going to follow very similar steps to [the first example of a gateway-bridge mesh network](#gateway-bridge), except for the following: 

* We will have two additional bridges in the network--that is, one for each mesh VLAN, for a total of three bridges. This is not a necessity but a matter of convenience to keep the example simple. The same bridge device can definitely bridge more than one mesh VLAN;
* In the gateway device, we will create VLAN IDs for the `iot` (**2**), `guest` (**5**), and `default` (**1**) networks, each with a separate set of DHCP server and firewall rules;
* In each bridge device, we will join the default `lan` with the **VLAN ID** of the mesh VLAN (`bat0.1`, `bat0.2`, `bat0.5`), instead of `bat0`.

Surprisingly enough, we don't need to do a thing about the **mesh nodes** that are not **gateways** or **bridges**--that is, the [mesh node basic config](#mesh-node-basic-config) is both necessary and sufficient for simple mesh nodes, even when using VLANs.  The only exception is if one of your mesh nodes is, for example, a laptop and you want it to use a particular mesh VLAN instead of the untagged `bat0`.  In our case, however, the pre-configured mesh nodes are ready to route traffic of any VLAN that belongs to `bat0`.

As before, let's start with the **gateway** configuration.

### Mesh gateway with VLAN configuration
First, configure the gateway **the same way** [as in the gateway-bridge example](#mesh-gateway-configuration).

Now, instead of `lan_bat0`, we're going to change it to `default` in the config files, then do the same for `iot` and `guest`.  So, if you're ready, `ssh` back into it and let's start by editing the `/etc/config/network` config file, as follows

```
vi /etc/config/network
```

and at the end, comment out the `lan_bat0` config, as follows

```
#config interface 'lan_bat0'
#        option type 'bridge'		#uncomment if adding other interfaces to ifname
#        option ifname 'bat0'
#        option proto 'static'
#        option ipaddr '192.168.10.1'	#static addr for this gateway on the 192.168.10.0/24 net
#        option netmask '255.255.255.0'
#        list dns '1.1.1.1'			#cloudflare dns server
#        list dns '8.8.8.8'			#google dns server
```

then below it, let's add a new interface for `default`, as follows

```
config interface 'lan_bat0_1'
#        option type 'bridge'	#uncomment if adding other interfaces to ifname
        option ifname 'bat0.1'
        option proto 'static'
        option ipaddr '192.168.10.1'
        option netmask '255.255.255.0'
        list dns '1.1.1.1'
#        list dns '8.8.8.8'	#make it use cloudflare
```

then another one for `iot`

```
config interface 'lan_bat0_2'
#        option type 'bridge'	#uncomment if adding other interfaces to ifname
        option ifname 'bat0.2'
        option proto 'static'
        option ipaddr '192.168.20.1'
        option netmask '255.255.255.0'
#        list dns '1.1.1.1'	#make it use google
        list dns '8.8.8.8'
```

and another one for `guest`

```
config interface 'lan_bat0_5'
#        option type 'bridge'	#uncomment if adding other interfaces to ifname
        option ifname 'bat0.5'
        option proto 'static'
        option ipaddr '192.168.50.1'
        option netmask '255.255.255.0'
#        list dns '1.1.1.1'	#make it use google
        list dns '8.8.8.8'
```

**Save the file** and exit it.

Now, let's edit the `/etc/config/dhcp` config file, as follows

```
vi /etc/config/dhcp
```

and once again, comment out all `lan_bat0` config, as follows

```
#config dhcp 'lan_bat0'
#        option interface 'lan_bat0'
#        option start 50		#start leasing at addr 192.168.10.50
#        option limit 100		#max leases, so for 100, leased addr goes from .50 to .149
#        option leasetime '3h'
#        option ra 'server'
```

then add a DHCP server config for the `default` interface below it

```
config dhcp 'lan_bat0_1'
        option interface 'lan_bat0_1'
        option start 50
        option limit 100
        option leasetime '12h'
        option ra 'server'
```

and like before, we will add another one for the `iot` interface

```
config dhcp 'lan_bat0_2'
        option interface 'lan_bat0_2'
        option start 50
        option limit 100
        option leasetime '6h'
        option ra 'server'
```

and another one for the `guest` interface

```
config dhcp 'lan_bat0_5'
        option interface 'lan_bat0_5'
        option start 50
        option limit 100
        option leasetime '1h'
        option ra 'server'
```

**Save the file** and exit it.

Finally, let's edit the `/etc/config/firewall` config file, as follows

```
vi /etc/config/firewall
```

and once again, comment out the `lan_bat0` configs, as follows

```
#config zone
#        option name     lan_bat0
#        list network    'lan_bat0'
#        option input    ACCEPT
#        option output   ACCEPT
#        option forward  ACCEPT
```
```
#config forwarding
#        option src   lan_bat0
#        option dest  wan
```

and below each one of them, add one for the `default` interface

```
config zone
        option name     lan_bat0_1
        list network    'lan_bat0_1'
        option input    ACCEPT
        option output   ACCEPT
        option forward  ACCEPT
```
```
config forwarding
        option src   lan_bat0_1
        option dest  wan
```

then another one for the `iot` interface

```
config zone
        option name     lan_bat0_2
        list network    'lan_bat0_2'
        option input    ACCEPT
        option output   ACCEPT
        option forward  ACCEPT
```
```
config forwarding
        option src   lan_bat0_2
        option dest  wan
```

and another one for the `guest` interface

```
config zone
        option name     lan_bat0_5
        list network    'lan_bat0_5'
        option input    ACCEPT
        option output   ACCEPT
        option forward  ACCEPT
```
```
config forwarding
        option src   lan_bat0_5
        option dest  wan
```

**Save the file** and exit.

**Reboot** the device.

Once the gateway device is back online--by the way, it should still be at `192.168.1.1` because the gateway's default `lan` is intact, so even if we fuck something up, we should be able to find the gateway via a direct cable connection--`ssh` into it once again and type

```
ip a
```

which now should show the new interfaces we created (e.g, `bat0.1@bat0`) and the static IP addr of your device in each one of them (`192.168.10.1`).  (As mentioned before, if the `option type 'bridge'` was enabled in the `/etc/config/network` config stanza, then there will be an additional interface with the `br-` prefix attached to it and the static IP addr of your device will be associated with it.)

If everything looks good, we're done with the gateway configuration!  We're now ready to tell our bridges which VLAN ID to join with their standard interfaces.

You don't need to use **interface names** such as `lan_bat0_1`; they can be whatever you find intuitive.  However, whatever you choose, **keep them short**--that is, less than 14 characters long--or you'll start experiencing config issues.
{: .notice .notice--danger }

### Mesh bridge with VLAN configuration
Here, we'll also configure the bridges **the same way** as in the gateway-bridge example. However, each bridge device will bridge **a different VLAN ID**--namely, either `bat0.1` or `bat0.2` or `bat0.5`--with its default `lan`, instead of bridging `bat0` with its default `lan`.

Let's start with the Network B (**IoT**) bridge. 

Configure one of the mesh nodes [as in the gateway-bridge example](#mesh-bridge-configuration), except that in the default `lan` interface stanza of the `/etc/config/network` file, let's do the following:

* In `option ifname`, change `bat0` for `bat0.2`;
* In `option ipaddr`, change `192.168.10.` for `192.168.20.`;
* In both `option gateway` and `option dns`, change `192.168.10.1` for `192.168.20.1`;
* Then, the default `lan` stanza should look something like this
  ```
config interface lan
        option type 'bridge'
        option ifname 'eth0.1 eth1 bat0.2'	#ethX might be different for your device
        option proto 'static'
        option ipaddr '192.168.20.10'
        option netmask '255.255.255.0'
        option gateway '192.168.20.1'
        option dns '192.168.20.1'
```

**Save the file** and exit it.

**Reboot** your device. 

Once it comes back on, your laptop/PC will receive an IP addr from our mesh gateway in the `192.168.20.0/24` network, the bridge node should be reachable at `192.168.20.10`, and you should be able to access the Internet via the **IoT** network (try `ping google.com`, for example). 

**If something doesnt work**, review the config files from your gateway and then from the bridge, then reboot the gateway and the bridge, and test again.

If this config is working, **repeat the same steps** in the config of the other two bridges, with the following exceptions

* In the Network C bridge (**Guest**), use `bat0.5` instead of `bat0.2`, and similarly, use the `192.168.50.` IP addr instead of `192.168.20.`;

* In the Network D bridge (**Default**), use `bat0.1` instead of `bat0.2`, and similarly, use the `192.168.10.` IP addr instead of `192.168.20.`;

*Optional*: When configuring a **Guest** WAP, for example, you can add `option isolate 1` to the relevant stanza in the `/etc/config/wireless` config file to deny client-to-client connectivity without the need of re-enabling the firewall in the bridge device.  If that's not enough, re-enable the firewall and configure it according to your needs--at the bottom of the `/etc/config/firewall` file, there are examples you can use as template.

## Getting started with batman-adv on any Linux device
OpenWrt makes using `batman-adv` a nearly trivial thing but you certainly don't need OpenWrt to implement a mesh network or even to use `batman-adv` in your mesh.  As mentioned before, `batman-adv` has long been added to the Linux Kernel and therefore, you should be able to configure it on pretty much *any* device running Linux.  

Even though the specifics of configuring network interfaces and managing connections might be different across Linux distributions, the initial steps always consist of the following:

1. Installing (in popular distros, this is *not needed*) and loading (*always* needed) the `batman-adv` Kernel module.
  `lsmod` will show a list of active modules, so we can `grep` it to check if the `batman-adv` module has already been loaded, as follows
  ```
lsmod | grep batman
  ```
  then if it isn't loaded, we add the `batman-adv` kmod to `/etc/modules` and load it with `modprobe`, as follows
  ```
# append batman-adv to /etc/modules
echo 'batman-adv' | sudo tee -a /etc/modules &gt; /dev/null
# load the batman-adv module
sudo modprobe batman-adv
# check that the batman-adv module is now loaded
lsmod | grep batman
  ```
  Afterwards, you can check the [**sysfs**](https://en.wikipedia.org/wiki/Sysfs) of each network device in `/sys/class/net/` and there should be a `batman_adv` folder.  When the `batman-adv` module gets configured to use a particular network device, the files `batman_adv/iface_status` and `batman_adv/mesh_iface` will change their contents to reflect that. In addition, once enabled, `bat0` will show up as a new network device in `/sys/class/net/` and its options (e.g., `gw_mode`) can be modified by `echo`ing new values to their corresponding file in `/sys/class/net/bat0/mesh/`  (`echo 'client' &gt; /sys/class/net/bat0/mesh/gw_mode`).
2. Installing the `batctl` package. On apt-based distros like Debian, you should be able to install it with the following
  ```
sudo apt install batctl
  ```
3. Using a combination of `iw` and `ip` to configure the network interfaces, as illustrated in the [B.A.T.M.A.N. quick start guide](https://www.open-mesh.org/projects/batman-adv/wiki/Quick-start-guide).  In our case, however, the wireless mode of operation (as in the specification of `type` in the `iw` interface creation command) is `mesh` (or `mp`), instead of `adhoc` (or `ibss`).
4. Using something like [wpa_supplicant](https://en.wikipedia.org/wiki/Wpa_supplicant) to manage connections.

If you know of a program that has a GUI and is able to handle such configurations on popular Linux distros, let me know about it. As far as I know, there's currently nothing like that and it would be so very useful.

[top](#){: .btn .btn--light-outline .btn--small}

# Bonus content: Physical computing
If your device has unused **general purpose I/O** pins, it's possible to do all sorts of things with them.  Check the [GPIO documentation](https://openwrt.org/docs/techref/hardware/port.gpio) for examples of how to install new LEDs and buttons, for instance.  ([Your device's OpenWrt page can be very useful as well](https://openwrt.org/toh/tp-link/tl-wr1043nd#gpios).)

Also, if you want to change the functionality of a few of the existing LEDs on your wireless device, check the [LED configuration documentation](https://openwrt.org/docs/guide-user/base-system/led_configuration).  Now that you have new mesh interfaces, you can use the LEDs to blink depending on the status of neighboring nodes, mesh gateways, or WAN connectivity through the mesh, to mention a few examples. (As mentioned before, [your device's OpenWrt page can be very useful here](https://openwrt.org/toh/tp-link/tl-wr1043nd#leds).)

[top](#){: .btn .btn--light-outline .btn--small}

# Final remarks

![Futurama Hubert Farnsworth](/assets/posts/2020-11-24-mesh-networking-openwrt-batman/futurama.jpg){:.PostImage}

Good news, everyone! You've reached the end of this tutorial, which means it's time to start planning your own mesh networking project.  I love to hear about different takes on the projects I post on my blog, so don't hesitate to [contact me](/contact/) if you just want to share or bounce a few ideas.  Different perspectives give an opportunity to learn, grow, and innovate.

## Other similar mesh solutions
If you find this guide overwhelming but you're still curious about mesh networking, take a look at the following alternatives (in alphabetical order):

* [Commotion Wireless](https://www.commotionwireless.net)
* [LibreMesh](https://libremesh.org)

They have pre-configured images that will work &quot;out of the box&quot; with compatible devices.  You might find instructive to start playing around with their software first and once comfortable, build your own configuration from a default (or customized from the source) OpenWrt image.

[top](#){: .btn .btn--light-outline .btn--small}</content><author><name>Carlos Gomes</name></author><category term="blog" /><category term="mesh" /><category term="adhoc" /><category term="ieee" /><category term="wifi" /><category term="wireless" /><category term="radio" /><category term="network" /><category term="router" /><category term="openwrt" /><category term="batman" /></entry><entry><title type="html">NanoPi M4 mini-NAS</title><link href="/blog/Nanopi-m4-mini-nas/" rel="alternate" type="text/html" title="NanoPi M4 mini-NAS" /><published>2020-07-06T13:42:00-03:00</published><updated>2020-07-06T13:42:00-03:00</updated><id>/blog/Nanopi-m4-mini-nas</id><content type="html" xml:base="/blog/Nanopi-m4-mini-nas/">This article is about my mini network-attached storage (NAS) project based on FriendlyARM's [NanoPi M4](http://wiki.friendlyarm.com/wiki/index.php/NanoPi_M4) and its [SATA hat](http://wiki.friendlyarm.com/wiki/index.php/NanoPi_M4_SATA_HAT).  If you're looking for a cheap, low-profile, low-power NAS solution for your home--or if you just like single-board computers (SBC)--then this article is for you.  

Here's a preview of how my NanoPi M4 mini-NAS looks like:

[![Final NAS 02](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-final-01.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-final-01.jpg)

[![Final NAS 01](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-final-02.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-final-02.jpg)

And for comparison, here's the unit next to a Raspberry Pi 3B:

[![Final NAS next to RPi](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-final-and-rpi.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-final-and-rpi.jpg)

This article should give you a fairly good idea about the following:

* What to buy; 
* What to install at the operating system (OS) and NAS management level;
* How to put everything together and get it up and running.  

After that, you're free to do whatever you want for your own use-case (disk partitions, storage systems, file sharing method, applications, etc.). 

# Changelog
**October 16th, 2020**, (#1 of 2): I've re-written the [pwm-fan script for the NanoPi-M4](https://github.com/cgomesu/nanopim4-satahat-fan) and updated [the section about it](#pwm-fan-controller) accordingly.
{: .notice .notice--info }

**October 16th, 2020**, (#2 of 2): Despite the CPU tuning improvements I mentioned in my previous update, I've continued to have a few stability issues with Kernel 5.x.  After a while, I've decided to reinstall **Armbian Buster** with **Kernel 4.4.213-rk3399 (legacy)** and it has been smooth sailing ever since.  I updated the [section about OS installation](#software) accordingly.
{: .notice .notice--warning }

**July 14th, 2020**: Added [information about CPU tuning to improve system stability](#cpu-tuning).
{: .notice .notice--info }

**July 8th, 2020**: Added a [cautionary note about SATA power cables](#nanopi-m4-sata-hat--passive-cooler--cables); Added a [table with the cost of all hardware components of this build](#cost-estimate); I also got a hold of a DC jack adapter that will let me measure the actual current draw from my final mini-NAS and will make it available here as soon as I'm done testing it.  If you've additional suggestions, please [reach out](/contact).
{: .notice .notice--info }

[top](#){: .btn .btn--small .btn--light-outline }

# Introduction
The NanoPi M4 is a SBC made by FriendlyARM (a.k.a. FriendlyElec), a Chinese company based in Guandong.  They have their own [online store](https://www.friendlyarm.com/) that you can use to buy a few of the boards and components they develop but chances are you can also buy from pretty much any of the large retail stores out there (e.g., AliExpress, Amazon, Newegg).  [I bought all components from AliExpress, for example, from the folks at [RealQvol](https://embedunion.aliexpress.com/store/113595).]  FriendlyARM also has a fairly good [wiki](http://wiki.friendlyarm.com/wiki/index.php/Main_Page) that documents the main aspects of their boards.

For a general review of the board, check these two videos:

{% include video id=&quot;knS854Taz-E&quot; provider=&quot;youtube&quot; %}

{% include video id=&quot;sxND3lLSwB4&quot; provider=&quot;youtube&quot; %}

You can also find a CPU performance comparison between the NanoPi M4 v2 and the Raspberry Pi 4 at [this blog post](https://www.androidpimp.com/embedded-single-board-computers/raspberry-pi-4-vs-nanopi-m4v2/), which suggests that the NanoPi M4 is superior and will be able to run tasks more efficiently than the RPi 4.

In the following sections, I talked about the hardware (board, hat, case, drive choices and power supply), then the software (OS + NAS management interface) and finally, assembly and board/hat testing.  The article ends with a very brief presentation of my current configuration for the mini-NAS.

[top](#){: .btn .btn--small .btn--light-outline }

# Hardware
For this project, I'm using the following hardware:
## NanoPi M4 v2
I'm using the **2nd version** (v2) of this board but everything should apply to v1.  I think the major differences between the two is that the **v2 has LPDDR4 RAM**, instead of LPDDR3, a power button, the eMMC is connected the opposite way and screwed to the board, and the v2 looks slightly cleaner than the v1.  Other than that, when buying one, you'll have the option to buy with 2GB or 4GB of RAM.  I'm using the one with **4GB of RAM** and I recommend it if you're going to use it as a NAS, even if you're not going to use a RAM intensive filesystem like ZFS.  (For reference, ext4 uses very little RAM and a 2GB version won't have any issues sharing files at all.  The problem in those cases is when you start adding applications to your NAS.)

[![Nanopi M4 v2 board](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4v2-board.jpg){: .PostImage .PostImage--large }](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4v2-board.jpg)

## NanoPi M4 heatsink
This little fella gets pretty hot but fortunately, this massive heatsink does a decent job at keeping it cool.  For even better performance, try adding a fan, use thermal paste instead of a pad, or use a copper heatsink with a large surface area.

[![Nanopi M4 heatsink](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-heatsink.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-heatsink.jpg)

## NanoPi M4 16-32gb eMMC (+ micro-SD adapter)
The adapter makes it easy to flash an OS image directly onto the eMMC, so make sure to buy one.  As far as I know, you don't need to use an eMMC with the NanoPi M4.  A micro-SD will do the trick but of course, it's slower than an eMMC.  However, an eMMC is slower than a solid state drive (SSD), so if you know how to run the OS from a SSD, let me know.  Either way, the OS and NAS program we're going to use is already configured to reduce the amount of writes to the eMMC/micro-SD/SSD (it comes configured to not use a swap partition, for example), which is good news if you're worried about wearing it out.

[![Nanopi M4 eMMC](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-emmc.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-emmc.jpg)

## NanoPi M4 SATA hat (+ passive cooler + cables)
This little hat has a [Marvell 88SE9215](https://www.marvell.com/content/dam/marvell/en/public-collateral/storage/marvell-storage-88se92xx-product-brief-2012-04.pdf) Four-Port 6 Gbps SATA I/O Controller.  It usually comes with two SATA interface cables and one SATA power cable able to power two drives.  If you're going to use more than two drives, like me, make sure to buy additional SATA interface cables and an extension/splitter for the SATA power cable (e.g., [StarTech splitter](https://www.amazon.com/StarTech-com-Power-Splitter-Adapter-PYO4SATA/dp/B0086OGN9E/ref=sr_1_7?dchild=1&amp;keywords=sata+power+extension+cable&amp;qid=1591723716&amp;sr=8-7)).

[![Nanopi M4 SATA hat](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-sata-hat.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-sata-hat.jpg)

When buying your SATA power cables, make sure the terminals are **crimped** (use blade connectors) instead of **molded**. In brief, molded terminals are not faulty by design but they are error prone, owning to the method that the cables are terminated (molding plastic), and such errors might lead to [catastrophic events](https://duckduckgo.com/?t=ffab&amp;q=sata+power+fire&amp;ia=web). The ones in my original pictures were all molded and **you should not use them**.  Thanks to **/u/Fuck_Birches** and **/u/WordBoxLLC** for pointing that out.  I have changed them for crimped ones now.  Here's an instructive video about the issue:
{: .notice .notice--danger }

{% include video id=&quot;TataDaUNEFc&quot; provider=&quot;youtube&quot; %}

If you plan on using the same 3d printed case I'm using (see [kirkdis' 3D printed case](#kirkdis-3d-printed-case)), make sure to buy SATA cables with **a straight/horizontal connector on both ends of the cable**.  That case is *very* tight, so you might want to consider buying at least two shorter than usual SATA cables for the HDDs closer to the base.

[![Nanopi M4 SATA hat](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-sata-cables.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-sata-cables.jpg)

## 12v (8A) power supply unit (PSU)
If you're using the SATA hat, you only need a single PSU to provide power to everything, and there are even two different options to do that: (a) via the DC 5.5x2.1mm jack on the SATA hat, using an external PSU (e.g., [Alitove](https://www.amazon.com/ALITOVE-100-240V-Converter-Transformer-5-5x2-1mm/dp/B07MXXXBV8/ref=sr_1_3?dchild=1&amp;keywords=psu+12v+10a+5.5x2.1mm&amp;qid=1591721696&amp;s=electronics&amp;sr=1-3)); or (b) via the 4-pin 12v connector, also on the SATA hat, using a low power (&lt; 200W) PC PSU.  If you're going to use four low revolutions per minute (RPM) 2.5&quot; HDDs (e.g., 5400 RPM), or four SSDs, a 12v PSU that is able to deliver up to 3A should be enough.  However, if you're driving high-RPM 2.5&quot; HDDs (e.g., 7200RPM) or 3.5&quot; HDDs, then do the math before powering the components.  If you want to be safe, just get a 12v PSU that is able to deliver up to 8A.

[![NanoPi M4 PSU connections](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-psu-connections.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-psu-connections.jpg)

Please note that if you're planning on using a PC PSU, you'll need to &quot;hack it&quot; in order to use the PSU without plugging it into a mobo. 

If you're not 100% sure about tinkering with anything related to electricity, do not attempt to modify any PSU you might have lying around and just buy a 12v (8A) external PSU.  You can die even if the PSU is not connected to an outlet, owing to the presence of massive capacitors inside the PSU.  I cannot emphasize this enough.  Also, don't go around cutting its cables to just make it look cute.  You might need them later. 
{:.notice--danger}

Alright, if you really want to use a PC PSU, follow the instructions in this video (but use a proper cable to connect the pins and make sure it's well secured):

{% include video id=&quot;j4erf6SuqdI&quot; provider=&quot;youtube&quot; %}
{:. text-center}

## 2.5&quot; hard disk drive (HDD)
You can run 3.5&quot; drives as well but if you plan to keep power consumption at a minimum, I suggest running 2.5&quot; drives instead or better yet, SSDs.  Here, I'm going to use **four 2.5&quot; WD Black HDD** because they are fast (7200rpm as opposed to the traditional 5400rpm for 2.5&quot; drives) and I don't have a need for a large local storage space.  (Just be careful that the 1TB 2.5&quot; WD Black [model WD10SPSX is actually SMR](https://www.westerndigital.com/products/internal-drives/wd-black-hdd).)  In general, my preference order is the following: SSD &gt; 2.5&quot; CMR HDD &gt; 3.5&quot; NAS HDD &gt; 3.5&quot; other CMR HDD &gt; 2.5&quot; whatever HDD &gt; 3.5&quot; whatever HDD.  Of course, you don't need to use all four SATA ports if there's no demand for it.

[![2.5&quot; WD Black HDD 500GB](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/hdd-wb-black-25-500gb.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/hdd-wb-black-25-500gb.jpg)

[![2.5&quot; WD Black HDD 750GB](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/hdd-wb-black-25-750gb.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/hdd-wb-black-25-750gb.jpg)

## [kirkdis' 3D printed case](https://www.thingiverse.com/thing:3736661)
There are other 3D printed cases out there but I like kirkdis' take on a minimal case for the NanoPi M4 and 2.5&quot; drives.  Notice that there are 3- and 4-bay versions of the HDD case and mounts.  More specifically, for this project, I printed the following pieces: 

* 01 x `topcase_all_versions.stl`
* 01 x `fanmount_all_versions.stl`
* 04 x `4bay_discmount.stl`
* 01 x `4bay_hddbase.stl`

If you don't have a 3D printer, don't worry about it!  Just Google `3d printing service` and you'll find plenty of options to choose from.  You shouldn't have to pay more than $100 for this case, for reference.  Also, remember to [**buy screws**](https://www.amazon.com/hard-drive-screws/s?k=hard+drive+screws) for your HDDs, if you don't have a bunch a lying around. You'll need 08 for the bottom and top HDDs (16) + 04 for each in between (08), for a total of **24 screws** for four drives.

[![3D case stl](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-kirkdis-case.png){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-kirkdis-case.png)

Another option is to buy a [4-bay enclosure for your drives](https://www.amazon.co.uk/OImaster-Backplane-Function-Hot-swap-Transmission/dp/B074V52L9D) and use some sort of [stackable case](https://www.amazon.com/GeeekPi-Raspberry-Cluster-Cooling-Heatsink/dp/B07MW3GM1T/ref=sr_1_1?dchild=1&amp;keywords=stackable+case+rpi&amp;qid=1591726436&amp;sr=8-1) for your NanoPi M4.  If you go with this solution, remember to buy extra spacers to make room for the SATA hat and cables (and you might need longer cables).  Alternatively, you can always use a standard computer case (or rack mounted) that has support for 4 drives.  Get rid of the mobo and you're probably all set (see my note on modifying a PC PSU).

## Fan 50x50x15mm 12v (.08A)
(This fan size is for kirkdis' 3D printed case. You'd want something different if you're using another case.) You can probably find a .2A fan with the same dimensions, which will move more air but will be louder.  (If you're going to use the PWM connector, take a look at [PWM Fan controller](#pwm-fan-controller) to learn how to use it.)

[![50x50x15mm Fan](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/fan.png){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/fan.png)

Additionally, you might want to buy a filter for the fan. However, notice that *there's no space for the filter inside the 3d printed case* but you can glue/attach it to the outside (that's what I've done with the one I bought).

[![50x50x15mm Fan-filter](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/fan-filter.png){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/fan-filter.png)

## Cost estimate
For reference, here's how much each hardware component cost me in Brazilian Real (BRL$) and US Dollar (USD$), except for the HDDs.  Values were the total for all units, instead of per unit.  When appropriate, values were converted using the exchange rate from **July 8th, 2020**. Shipping costs were not included.  Notice that all values are likely **overestimating the actual cost** because many products include Brazilian taxes and were bought multiple months ago.

| component | quantity | BRL$ | USD$ |
|:---:|:---:|:---:|:---:|
| NanoPi M4 v2 4GB RAM | 01 | 477.25 | 89.04 |
| Heatsink | 01 | 37.41 | 6.98 |
| 32gb eMMC + mSD adapter | 01 | 144.61 | 26.98 |
| SATA hat | 01 | 149.97 | 27.98 |
| SATA III cable | 10 | 35.9 | 6.7 |
| RTC battery | 01 | 23.52 | 4.39 |
| SATA power Y splitter | 02 | 37.3 | 5.96 |
| 3d printed case | 01 | 155 | 28.92 |
| PSU 12v 10A | 01 | 53.9 | 10.06 |
| 50mm Fan 12v .08A | 01 | 18.8 | 3.51 |
| 50mm Fan filter | 01 | 19.5 | 3.64 |
| TOTAL | - | 1153.16 | 214.16 |

[top](#){: .btn .btn--light-outline .btn--small}

# Software
For the OS, I'm using the **server edition** of the **Armbian Buster** with **Kernell 4.4 (legacy)**. *(Of note, this section has been updated since the original article. In the previous version of the article, I suggested installing the latest Kernel 5.x instead of the legacy 4.4.x. The reason is that I've had multiple stability issues with Kernel 5.x and after switching to legacy, it's been solid as a rock.  That said, I've also read that many users have been running the latest Kernel without any issues, which makes me suspicious that there was somthing corrupted with my previous installation. So, my suggestion is the following: if you can afford testing for a few days, do try the latest Kernel 5.x first, and if you run into issues, reinstall the OS with legacy Kernel; otherwise, if you want it ready and solid right away, go straight to legacy Kernel.)*  You can download the image from the [official Armbian website](https://www.armbian.com/nanopi-m4/#kernels-archive-all).  Don't skip the integrity check.  On Linux, just open a terminal and run ```sha1sum /path/to/file.img.xz``` and check the output against the SHA file from the Armbian website.  This ensures your downloaded file has the same hash as the true file.  If you've ever used Debian or derivatives before (e.g., Ubuntu, Raspbian), Armbian will feel like home. 

[![SSH welcome and lscpu](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-sshwelcome-lscpu.jpg){:.PostImage .PostImage--large }](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-sshwelcome-lscpu.jpg)

If you don't like terminals, don't worry.  You pretty much don't need to ever see it again because we'll be managing everything from [Openmediavault 5 (OMV5)](https://www.openmediavault.org).  I've been using OMV since the 3rd edition as my go-to NAS solution and it has never let me down.  It's not super fancy, like freeNAS and unraid, but it will get the job done for most home-users.  Plus, it's free and [open-source](https://github.com/openmediavault/openmediavault) and this matters to me.  It also comes with a bunch of packages that facilitate file sharing, monitoring resources, manage users, plug-ins, etc., and it has a very clean graphical user interface accessible via web-browser (webUI):

[![OMV4 dashboard](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/omv4-dashboard.png){:.PostImage .PostImage--large }](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/omv4-dashboard.png)

In addition, the folks at OMV put together a guide on their Github repo that tells exactly [how to install OMV on Armbian](https://github.com/OpenMediaVault-Plugin-Developers/docs/blob/master/Adden-A-Installing_OMV5_on_Armbian.pdf).  Download their PDF and follow it step-by-step, with the following exceptions:

* Instead of flashing the OS image onto a micro-SD, plug your eMMC into the micro-SD adapter and then flash the OS image onto the eMMC.
* Before turning the NanoPi M4 on with the eMMC installed for the first time, remove any drives connected to the SATA hat.  This is more of a cautionary move than anything else.  We want to minimize the risk of corrupting the eMMC at these initial configuration steps and there's no need for additional drives at this point.  We'll add them after we're done installing OMV5.  The same applies to any other device connected to the NanoPi M4, like USB devices.  Keep it simple right now.

As you'll learn, the OMV installation script will take some time to finish.  We're talking about more than 10min.  Be patient!  Afterwards, open a web browser and log into OMV's WebUI and do your thing or read the [Getting Started Guide](https://github.com/OpenMediaVault-Plugin-Developers/docs/blob/master/Getting_Started-OMV5.pdf) that the OMV team wrote.

## CPU tuning
The **Rockchip RK3399** is a fairly new and nichey system on a chip and therefore, its implementation is not widely stable. On Armbian with Kernel 5.4, for example, I've noticed a few CPU-related Kernel panics that cause the board to freeze/reboot. [Upon further investigation](https://forum.armbian.com/topic/11710-nanopi-m4-v2-m4-image-not-working/page/7/?tab=comments#comment-93238), it seems this issue can be fixed by changing the default CPU governor from *ondemand* to ***conservative***, and setting the *minimum CPU frequency to **1.4GhZ*** and the *maximum to **1.8GhZ***. 

Be extra careful when tuning your CPU because things can go wrong if you set the board to operate in a condition that it was not meant to.  Move slowly and keep an eye on related statistics afterwards to make sure you're not going to fry the board. 
{:. .notice .notice--warning }

There are two ways to change the CPU frequency and governor. The first and recommended one is via the `armbian-config` configuration utility:
```
# Run the configuration utility
armbian-config
# Navitage to CPU options: System / CPU
# Set min frequency to 1416000 Hz
# Set max frequency to 1800000 Hz
# Set the governor to conservative
# Confirm 
# Exit the configuration utility
# Reboot
```

The second method is by making direct changes to the `cpufrequtils` file, as follows:
```
# Edit the cpufrequtils file
echo -e 'ENABLE=&quot;true&quot;\nGOVERNOR=conservative\nMAX_SPEED=1800000\nMIN_SPEED=1416000' &gt; /etc/default/cpufrequtils
# Reboot
```

My board has been running rock solid after making such changes, so I recommend it.  Of course, you can try to use other configurations.  My understanding from what I read about the Kernel panics is that it's likely a power issue caused by the rapid switching of CPU frequencies that the *ondemand* governor makes.  The *conservative* governor also scales the CPU frequency dynamically but much more gradually than the *ondemand* governor.
By this logic, setting the governor to either *performance* or *powersaving* will likely improve stability as well because those governors do not change the CPU frequency at all.


## PWM Fan controller
The **2-PIN PH2.0 connector** on the SATA hat is a power width modulated (PWM) connector for a 12v fan.  

[![PWM fan connector](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-fan-pwm.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-fan-pwm.jpg)

However, this connector is not enabled by default and furthermore, the Armbian OS does not come with a service that allows you to control the fan speed according to the CPU temperature.  Fortunately, other users have reported this issue before and a few of them have even written scripts to fix this issue.  I've made several changes to previous scripts (e.g., [mar0ni's script](https://forum.armbian.com/topic/11086-pwm-fan-on-nanopi-m4/?tab=comments#comment-95180)) and wrote a highly configurable fan controller that uses a bounded model to set the fan speed dynamically.  To make it easier for me (and everyone else), I've created a Github repo (**[cgomesu/nanopim4-satahat-fan](https://github.com/cgomesu/nanopim4-satahat-fan)**) for the fan controller.  For more detailed and updated info about the controller, please refer to the repo (and if you've any issues or suggestions, open an issue there).

Briefly, to install and run the script, read the [README.md](https://github.com/cgomesu/nanopim4-satahat-fan/blob/master/README.md) or follow these instructions:

```
# Install git, clone the repo, and test the script

apt update
apt install git
cd /opt

# From now on, if you're not running as root, append 'sudo' if you run into permission issues
git clone https://github.com/cgomesu/nanopim4-satahat-fan.git
cd nanopim4-satahat-fan

# Allow the script to be executed
chmod +x pwm-fan.sh

# Test the script
./pwm-fan.sh

# Check for any error messages 
# When done, press Ctrl+C after to send a SIGINT and stop the script
```

If everything looks good, then run the fan controller in the background (as a systemd service), as follows:

```
# Copy the pwm-fan.service file to your systemd folder
cp /opt/nanopim4-satahat-fan/pwm-fan.service /lib/systemd/system/

# Enable the service and start it
systemctl enable pwm-fan.service
systemctl start pwm-fan.service

# Check the service status to make sure it's running without issues
systemctl status pwm-fan.service
```

**Alternatively**, if you don't want to play around with PWM stuff and are okay with having your fan at 100%, 24/7, then you can just connect it to the board as follows:

[![PWM fan alt connector](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-fan-alternative-alwayson.jpg){:.PostImage .PostImage--small }](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-fan-alternative-alwayson.jpg)

Of note, you can also do the latter using the fan controller by running the script in *full speed mode*, as follows:

```
./pwm-fan.sh -f
```

[top](#){: .btn .btn--light-outline .btn--small}

# Assembly
If you're like me, you'll not receive all parts at the same time and you'll only print the case after making sure that the board and hat are both working.

[![Nanopi M4 parts on table](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-parts.jpg){:.PostImage .PostImage--large }](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-parts.jpg)

The first thing you'll want to do is **to flash the OS onto the eMMC**.  That's because the eMMC will not be as accessible as a micro-SD card and HDDs once the SATA hat is installed--it is screwed to the board itself, above the audio jack (in v2, and above the HDMI in v1).

After that, install the eMMC and the SATA hat.  Your SBC should look something like this right now:

[![Nanopi M4 with hat 01](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-assembled-01.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-assembled-01.jpg)

[![Nanopi M4 with hat 02](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-assembled-02.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-assembled-02.jpg)

Now, it's time to test the board and the SATA hat.  **Connect the board to an Ethernet cable and plug it into your 12v PSU.**  Observe the red and green LEDs as it turns on and starts running the OS for the first time. 

[![Nanopi M4 connected to PSU](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-psu-test01.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-psu-test01.jpg)

Go ahead and **find out which IP address your DHCP server gave to your NanoPi M4** (you might also be able to find it via the hostname nanopim4) and ping it to check it's up and running.  If it's replying, then **SSH into it** with `root` (default pass is `1234`).  When logging in for the first time, Armbian will ask to change password and to create a new sudo user.  Go ahead and do that.  (I'll assume that from this point on, you'll still be using `root` instead of the sudo user.  If you're using the latter though, then add a ```sudo``` prefix to each of the commands below.)

Afterwards, run the [**armbian configuration utility**](https://docs.armbian.com/User-Guide_Armbian-Config/) to make sure your NAS has the correct time, date, UTC offset, apt mirrors, etc., by running the command
```
armbian-config
```
(Depending on what you chose to change here, Armbian will need to reboot.  That's fine.  Just SSH into it again afterwards.)  Now, let's make sure all packages that came with the OS are up-to-date by running
```
apt update &amp;&amp; apt upgrade -y
```
Go back to your router/firewall and assign a static IP address to your NanoPi M4 and then reboot the NanoPi
```
reboot now
```
After reboot, wait a few seconds and try to SSH into the static IP address you gave to the NanoPi and if everything looks good, it's time to run the **OMV installation script** (see [**software**](#software)).  Again, this will take some time.  **Be patient!**  When it's done, open a web-browser and type the static IP address of your NanoPi M4.  At this point, it's a good idea to do at least the following in **System** (remember to **Apply changed settings** every time it asks you to):

1. Change your default admin password in **General Settings**.  This will only affect access to OMV's webUI.  It has nothing to do with your Linux user credentials;
2. Check **Date/Time** settings to make sure they are right;
3. Enable **System Monitoring**;
4. Enable and configure **Notification**;
5. In **Power Management**, enable Monitoring and select the Shutdown action for the power button;
6. **Reboot** via the webUI (arrow at the top right corner / reboot).

After rebooting, check your **Storage** and **Diagnostics** tabs.  In Storage / Disks, there should be a single device for the OS eMMC.  Later on, we will come back to see if the drives plugged into the SATA hat are showing up here. 

In Diagnostics / Sys Info, check all tabs to make sure they are displaying things correctly.  Your OMV should be collecting Performance Stats at this point, so there should be graphs available. 

(If you're new to OMV, take your time here and explore it a little bit.  This is a good time to read the Getting Started guide and get yourself familiarized with the webUI.)

If everything is good, **shutdown the NanoPi via the webUI**.  With everything off (none of the LEDs should be red), plug one or more HDDs to the SATA hat, as follows (I'm using an old 500GB Toshiba 2.5&quot; HDD in the pictures below just for testing):

[![Nanopi M4 hat HDD test](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-test01.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-test01.jpg)

Now, **turn on** the board.  You should notice a new LED on the other side of the SATA hat lighting up right away.  (The hat has LEDs for each SATA port.  If it's not lighting up for a connected drive, you already know there's a problem, like insufficient power or a bad connection.)  Go to the **OMV webUI** and in **Storage / Disks**, see if the NanoPi was able to detect your HDD connected to the SATA hat correctly.  If not, press the 'Scan' button and check again.  You can repeat this process for each SATA interface if you want.

[![Storage/Disks OMV webUI](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-satahat-test-toshiba25hdd.jpg){:.PostImage .PostImage--large }](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-satahat-test-toshiba25hdd.jpg)

At this point, if it looks like the board and SATA hat are working as they should, then **it's time to put everything inside the case**.  

## My printed cases
As I've mentioned before, I'm using kirkdis' 3D printed case. I printed two cases for this project. This is the first one:

[![CGomesu case 01](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-case01.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-case01.jpg)

[![CGomesu case 02](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-case02.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-case02.jpg)

And here's the second (backup) case:

[![CGomesu backup case](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-backup-case.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-backup-case.jpg)

[In kirkdis' last post](https://scheisser.net/?p=7781), he mentioned 
&gt; &quot;... to be careful when you put the upper case over the external ports as this is the most fragile part. Designwise I didnt found a workaround for this area as result it can happen if you push too much that the connections between the ports break off but with a liztle bit patience you can set iz in place as one piece.&quot; 

I think I read his comment a bit too late:

[![CGomesu backup case](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-frankensteins-case-01.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-frankensteins-case-01.jpg)

but I managed to fix it a little bit by the end:

[![CGomesu backup case](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-frankensteins-case-02.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-frankensteins-case-02.jpg)

### My opinion about the case

The HDD case and disk mounts feel very sturdy in comparison to the board case (a.k.a. upper case). I feel the **board case** could be improved in the following way:

1. Add **thicker walls**, especially where the USB ports and the DC jack are;
2. Add a way of **screwing** the board to the case;
3. Make the base of the fan mount thinner, so we can use the screws that come along with the board, instead of having to find longer screws just for that.  

[![CGomesu backup case](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-screws.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-screws.jpg)

Regarding the **whole case**:

1. It could be **a bit larger** to make room for the cables and improve air flow.  Right now, it's an extremelly tight fit if you're using four HDDs and some cables get bent in ways that are probably not good for them in the long run;
2. Because all printed pieces are so tightly connected to each other, **there's very little room for error** when printing them. I feel that both the HDD case and board case should be a little looser and rely more on **screws** to secure the printed pieces to the hardware.  Honestly, it was kind of a pain to attach and remove the board to the board case, and similarly, the HDD stack to the HDD case. It felt *too* tight with both cases I printed.

Honestly, I don't know shit about 3d printing.  This is just my opinion on how the case could be improved.  If something I said doesn't make sense, let me know.

### Procedure
If you don't want to figure out how to put all pieces together on your own, take a look at kirkdis' video and notice how he disassembled his unit:

{% include video id=&quot;zmxovsvsy_I&quot; provider=&quot;youtube&quot; %}

My advice is to do the following:

* Start by attaching the HDDs to the four disk mount pieces, so that you have a nice stack by the end of this step;

[![CGomesu backup case](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-stack-01.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-stack-01.jpg)

[![CGomesu backup case](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-stack-02.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-stack-02.jpg)

[![CGomesu backup case](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-stack-03.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-stack-03.jpg)

* Connect all the SATA data and SATA power cables to the SATA hat;

[![CGomesu backup case](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-sata-ports.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-sata-ports.jpg)

* Attach the fan to the mount and the mount to the SATA hat and plug it to the board;

* Put the board with the fan mount inside its case, making sure all the SATA cables are accessible from the other side of the case, where the HDDs will be;

* Attach the HDD stack to the base of the board case and connect the SATA cables;

[![CGomesu backup case](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-stack-04.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-stack-04.jpg)

[![CGomesu backup case](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-stack-05.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-hdd-stack-05.jpg)

* Now, cover the HDD stack with its case and screw the bottom of the case to the last HDD;

[![CGomesu backup case](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-assembled-04.jpg){:.PostImage}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-assembled-04.jpg)

* Connect your PSU to the DC power jack on the SATA hat;

* Turn it on.

Voil!  Check your OMV webUI to make sure it detected all connected disks and then start mounting them and adding your file sharing configurations, installing applications, adding users, etc. 

[![Nanopi M4 hat 4 HDD test](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-satahat-test-fourwdblacks.jpg){:.PostImage .PostImage--large}](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-satahat-test-fourwdblacks.jpg)

[top](#){: .btn .btn--light-outline .btn--small}

# Final Remarks
I'm very happy with this mini-NAS.  It's arguably not as powerful as my previous HP Proliant Gen8 that I turned into a NAS but it is **more energy efficient**, **smaller**, **quieter** and **cheaper**.  

Regarding applications, I strongly suggest you to take a look at [Docker](https://www.docker.com/) and [Portainer](https://www.portainer.io/).  You can install both Docker and Portainer from within the OMV webUI (System / OMV-Extras / Docker - Docker Install; Portainer Install).  They make installing and managing applications so much easier.  Just be mindful that you're running docker within an **ARM architecture**, so any image must have a compatible **arm release** to be able to run with the NanoPi M4.

I don't use any sort of RAID solution for this NAS.  Instead, I use unionFS/mergerFS to pool multiple drives/folders into individual folders and then have various applications running periodic local backups and overnight remote backups.  (The SATA hat *does not support hardware RAID* but if you're into redundancy, then it's possible to create a software RAID from within the OMV webUI.)

Here's an overview of how I'm currently organizing my mini-NAS:

[![mini-NAS drives and folders](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-organization.png){:.PostImage .PostImage--large }](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-organization.png)

[According to kirkdis](https://forum.openmediavault.org/index.php?thread/29089-nanonas-nanopi-m4-3-bay-or-4-bay-most-compact-and-low-consumption-raid/), a NanoPi M4 mini-NAS with three 2.5&quot; HDDs consumes between **7W** (idle) and **20W** (heavy load). I cannot measure the actual power consumption of my build but I think it's safe to assume that it consumes a bit more power than kirkdis', especially under heavy load. I estimate that mine consumes between 9W (idle) and 25W (heavy load), owing to the fact that my HDDs have a higher RPM and I'm using an additional 2.5&quot; HDD.  For comparison, a [Synology Diskstation DS918+ with four 3.5&quot; HDDs](https://www.techpowerup.com/review/synology-ds918plus/13.html) consumes between 27W (idle) and 44W (heavy load).

Well, this concludes my NanoPi M4 mini-NAS project. I hope you enjoyed this article and that it will inspire you to create something for your own use-case.  As usual, let me know if you have any questions or suggestions.

[top](#){: .btn .btn--light-outline .btn--small}

# Bonus Content
## Real time clock
The NanoPi M4 comes with a built-in real time clock (RTC) module and to use it, all that you need is a compatible **RTC battery** with a *Molex 53398-0271 connector*:

[![RTC battery](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/rtc-battery.jpg){:.PostImage }](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/rtc-battery.jpg)

As the name suggests, its main purpose is to keep track of time, regardless of the board's power state.  However, it also supports waking up the NanoPi from various power states.  On Linux, you can access and configure all such options with a package called `rtcwake`, which comes pre-installed on Armbian (and pretty much any other Linux distro, by the way, because it's part of the `util-linux` core package).  (If the package is not accessible from within your user's `$PATH`, try `whereis rtcwake` and type the entire `/path/to/rtcwake`.)  You can find info about its usage with the standard `--help` argument. For more detailed info, read `man rtcwake`. An RTC battery is *really* cheap ([less than $10](https://www.amazon.com/Rtc-Battery/s?k=Rtc+Battery)) and worthy of your attention for such a key component of a home network.  You definitely don't want your mini-NAS time travelling to 1970...

[![RTC battery](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-rtc-battery.jpg){:.PostImage }](/assets/posts/2020-07-06-Nanopi-m4-mini-nas/nanopim4-cgomesu-rtc-battery.jpg)

[top](#){: .btn .btn--light-outline .btn--small}</content><author><name>Carlos Gomes</name></author><category term="blog" /><category term="sbc" /><category term="arm" /><category term="homelab" /><category term="homeserver" /><category term="storage" /></entry><entry><title type="html">The ASRock J3355b-itx pfSense box</title><link href="/blog/Pfsense-white-box/" rel="alternate" type="text/html" title="The ASRock J3355b-itx pfSense box" /><published>2020-06-25T10:31:25-03:00</published><updated>2020-06-25T10:31:25-03:00</updated><id>/blog/Pfsense-white-box</id><content type="html" xml:base="/blog/Pfsense-white-box/"># Introduction
[pfSense CE](https://www.pfsense.org/) is a free, [open-source](https://github.com/pfsense/pfsense), and very popular **firewall/router** that runs on [FreeBSD](https://www.freebsd.org/) and is developed by [Netgate](https://www.netgate.com/).  Even though Netgate sells [official pfSense appliances](https://www.netgate.com/products/appliances/), it's possible to build your own, custom-made pfSense box for (way) less money (at the expense of way less support from Netgate). 

In this article, I talked about **my ASRock mini-ITX pfSense box project**.  In the first part, I listed all the necessary hardware to build the box, and in the second part, I briefly talked about the software.

[top](#){: .btn .btn--small .btn--light-outline}

# Hardware
This project has five main hardware components, namely the **motherboard** (mobo), the **network interface card** (NIC), **storage**, **case**, and **power supply unit** (PSU).

## Motherboard
Chances are that if you search for ```pfSense white-box```, you'll find someone mentioning the [**ASRock J3355b-itx**](https://www.asrock.com/mb/Intel/J3355B-ITX/).  This is definitely **not a top of the line** mobo but it comes with a **passively cooled [Intel dual-core processor](https://ark.intel.com/content/www/us/en/ark/products/95597/intel-celeron-processor-j3355-2m-cache-up-to-2-5-ghz.html)** (AES-NI enabled), two **SO-DIMM DDR3L** memory slots, a **PCIe 2.0x16** expansion slot, and 2x SATA III ports.  On top of that, this is a ***mini*-ITX mobo**, so we can put it inside a low-profile case.  At the very least, if you're looking for a more recent mobo, my suggestion is to use the ASRock J3355b-itx as reference.

[![ASRock J3355b-itx](/assets/posts/2020-06-25-Pfsense-white-box/asrock-mobo.jpg){: .PostImage}](/assets/posts/2020-06-25-Pfsense-white-box/asrock-mobo.jpg)

## Network interface card
Even though the ASRock mini-itx comes with a built-in NIC, it's a single port Realtek NIC that pfSense will likely not recognize out of the box.  Ideally, you'd buy and install an Intel NIC using the PCI-e expansion slot on the ASRock mobo.  The card choice depends on your needs but at the very least, consider a **Gigabit Intel NIC with two ports**, one for WAN and another for LAN.  (It's possible to use a single port with a VLAN-capable switch but this is a far more complex setup.)  Also, make sure the Intel NIC comes with a **low-profile support** or it won't fit many min-ITX cases.

[![Intel NIC with 2 ports](/assets/posts/2020-06-25-Pfsense-white-box/intel-nic.jpg){: .PostImage}](/assets/posts/2020-06-25-Pfsense-white-box/intel-nic.jpg)

## Storage
pfSense uses very little storage space, so you don't need TBs of storage here.  The things that matter are read/write speed and reliability.  A simple **120GB solid-state drive (SSD)** will be more than enough, for example. 

[![SSD](/assets/posts/2020-06-25-Pfsense-white-box/120gb-ssd.jpg){: .PostImage}](/assets/posts/2020-06-25-Pfsense-white-box/120gb-ssd.jpg)

## Case
You can use *any* mini-ITX case *as long as* it has support for at least **one expansion slot**.  Also, note that some mini-itx cases have an expansion slot parallel to the mobo (it sits above the mobo's i/o plate), instead of perpendicular (next to the mobo's i/o plate).  That will usually be okay but you'll need to buy compatible PCI-e extension cable then.

[![Case](/assets/posts/2020-06-25-Pfsense-white-box/case-antec-front.jpg){: .PostImage}](/assets/posts/2020-06-25-Pfsense-white-box/case-antec-front.jpg)

[![Case](/assets/posts/2020-06-25-Pfsense-white-box/case-antec-back.jpg){: .PostImage}](/assets/posts/2020-06-25-Pfsense-white-box/case-antec-back.jpg)

[![Case](/assets/posts/2020-06-25-Pfsense-white-box/case-kmex-front.jpg){: .PostImage}](/assets/posts/2020-06-25-Pfsense-white-box/case-kmex-front.jpg)

[![Case](/assets/posts/2020-06-25-Pfsense-white-box/case-kmex-back.jpg){: .PostImage}](/assets/posts/2020-06-25-Pfsense-white-box/case-kmex-back.jpg)

## Power supply unit
If you bought an expensive case with a built-in PSU, go ahead and use it.  However, if you bought a cheap case with a PSU or one that even doesn't have a built-in PSU, then buy and use a [**pico PSU**](https://www.amazon.com/s?k=pico+PSU). My experience is that **cheap PSUs come with bad fans**, so avoid them if your firewall will be next to anyone in the house because it will eventually start making a lot of noise.  A pico PSU is the way to go, and because this box uses very little power, buy a low power PSU (anything between 60W-180W should be okay, for reference).

[![PicoPSU](/assets/posts/2020-06-25-Pfsense-white-box/pico-psu.jpg){: .PostImage}](/assets/posts/2020-06-25-Pfsense-white-box/pico-psu.jpg)

[top](#){: .btn .btn--light-outline .btn--small}

# Software
Software-wise, there's not much to say other than

1. Download the ISO from the [official website](https://www.pfsense.org/download/);
2. Check the SHA signature of the downloaded file against the one from the official website;
3. Flash the image onto a USB stick;
4. Connect a monitor and keyboard to your pfSense box;
5. Insert the USB stick into your pfSense box, turn it on, and follow the instructions.

Now, if you want a more in-depth look into installation and initial configuration, check [**the official docummentation**](https://docs.netgate.com/pfsense/en/latest/install/installing-pfsense.html).  Alternatively, there's a very easy to follow video tutorial that [Lawrence Systems](https://www.youtube.com/channel/UCHkYOD-3fZbuGhwsADBd9ZQ) put together. (It's a bit old but still valid.)

{% include video id=&quot;9kSZ1oM-4ZM&quot; provider=&quot;youtube&quot; %}

[top](#){: .btn .btn--light-outline .btn--small}

# Conclusion
This concludes the basics of a cheap, low-profile, and low-power (yet powerful) pfSense white-box.  I've never had any issues with this hardware and recommend it to anyone interested in diving into firewalls or just looking for something a bit more advanced than what commercial routers can offer.  If you want to try something different than pfSense, take a look at [OPNsense](https://opnsense.org/)--a pfSense fork--for another free and open-source firewall software.

[top](#){: .btn .btn--light-outline .btn--small}</content><author><name>Carlos Gomes</name></author><category term="blog" /><category term="homelab" /><category term="homeserver" /><category term="firewall" /><category term="network" /></entry><entry><title type="html">Youtube live-streams as IPTV channels for TVHeadend</title><link href="/blog/Youtube-as-IPTV-with-TVH/" rel="alternate" type="text/html" title="Youtube live-streams as IPTV channels for TVHeadend" /><published>2020-05-07T00:00:00-03:00</published><updated>2020-05-07T00:00:00-03:00</updated><id>/blog/Youtube-as-IPTV-with-TVH</id><content type="html" xml:base="/blog/Youtube-as-IPTV-with-TVH/"># Changelog
**January 21st, 2021**: **READ THIS**. This tutorial **has been deprecated** because I wrote a **new tutorial** about the integration between Tvheadend and Streamlink, called **[TVHlink: Livestreams as IPTV channels with TVHeadend and Streamlink](/blog/Tvhlink/)**.  The integration has been greatly simplified and is more reliable than before.  In addition, the new tutorial is much more comprehensive than this one.  The new tutorial is self-contained, so you don't need to read this one first--just skip it altogether.  I will only keep this up for archiving purposes.
{: .notice .notice--danger }

**September 15th, 2020**: There's a [new release of the Youtube4TVH](https://github.com/cgomesu/youtube4tvh/releases) program that does not require the use of API keys. The section about how to create an API key has been updated accordingly.
{: .notice .notice--info }

**June 23rd, 2020**: Moved content from Blogger to my website and converted to markdown.  Fixed typos I found.
{: .notice .notice--info }

**May 19th, 2020**: Added info about TVH m3u re-fetch period and youtube4tvh cronjob for streams that change very often.
{: .notice .notice--info }

**May 14th, 2020**: Added more info about streamlink install and outdated versions; fixed a few typos. 
{: .notice .notice--info }

[top](#){: .btn .btn--light-outline .btn--small}

# Introduction
In this guide, we will learn how to feed Youtube live-streams into a TVHeadend (TVH) server as IPTV channels.  This is a fairly advanced guide but I'll try my best to make it as digestible as possible to any individual with minimal knowledge about selfhosting.  You will need a **Linux distro** (e.g., Debian, Ubuntu) to follow this guide.  All the software described here is **free and open-source**.

I'm not an expert in any of the topics mentioned here.  If you have suggestions on how to improve something, please leave a comment below stating what could be changed and why it should be changed.

Youtube4tvh is a utility program I wrote just for this guide.  I welcome anyone who wants to improve it or fork into something more abstract.  If that sounds like something you want to do, please head to [my Github repo](https://github.com/cgomesu/youtube4tvh) and hit me up once you've done some coding. 

[top](#){: .btn .btn--light-outline .btn--small}

# Motivation
There are multiple reasons to watch Youtube live-streams as if they were IPTV channels.  Here are a reasons few that come to mind right now:

* It's free and all programs are open-source;
* There is at least one Youtube 24/7 live-stream that you enjoy. Some of my personal favorites, per category: 
  * **News**: ABC News AU, Sky News, DW in English, France 24 in English
  * **Space**: NASA TV, Space Videos, Space &amp; The Universe HD
  * **Webcam - Nature**: Cornell Lab of Ornithology Cams, Monterey Bay Aquarium, Explore Oceans, Explore Nature, Volcanoverse
  * **Webcam - Other**: Virtual Railfan, earthTV, I Love You Venice,
  * **Radio**:  BGM channel, Cafe del Mar, Stay See
* You want to make selected Youtube live-streams available as IPTV channels through a TVH server (TVH -&gt; Streamlink pipe -&gt; Youtube);
* You want to keep your streaming services as centralized as possible.  That is, instead of multiple apps, you can manage all of them using a single application (TVH);
* You want to take advantage of one of the fastest and most reliable media delivery networks out there (Youtube's CDN);
* You dislike Youtube ads (Streamlink will get rid of them without the need to install any filtering system);
* You like how it looks for the client:

{% include video id=&quot;9FSPf5wISUY&quot; provider=&quot;youtube&quot; %}

[top](#){: .btn .btn--light-outline .btn--small}

# Objectives
By the end of the guide, you'll have learned how to do the following:

* Create a customized Youtube live-stream m3u playlist with the help of youtube4tvh;
* Install a TVH server on a Linux machine;
* Install Streamlink to pipe live-stream data into a TVH server;
* Add a Youtube live-stream m3u playlist to a TVH server as an IPTV auto network;
* Configure a TVH server to auto-map muxes to channels using bouquets;
* Create a cronjob to automatically update the Youtube live-stream m3u playlist every day at 6am.

[top](#){: .btn .btn--light-outline .btn--small}

# Client-server layout
There are three main components to this setup, namely **TVH**, **Streamlink**, and **youtube4tvh**, which are all open-source and free:

* [**TVHeadend**](https://github.com/tvheadend/tvheadend): Tvheadend is a TV streaming server for Linux supporting DVB-S, DVB-S2, DVB-C, DVB-T, ATSC, IPTV, SAT&gt;IP and other formats through the unix pipe as input sources.

[![TVH Github](/assets/posts/2020-05-07-Youtube-as-IPTV-with-TVH/tvh-github.png){:.PostImage}](/assets/posts/2020-05-07-Youtube-as-IPTV-with-TVH/tvh-github.png)

[![TVH WebUI](/assets/posts/2020-05-07-Youtube-as-IPTV-with-TVH/tvh-webui.png){:.PostImage}](/assets/posts/2020-05-07-Youtube-as-IPTV-with-TVH/tvh-webui.png)

* [**Streamlink**](https://github.com/streamlink/streamlink): Streamlink is a CLI utility which pipes video streams from various services into a video player.

[![Streamlink Github](/assets/posts/2020-05-07-Youtube-as-IPTV-with-TVH/streamlink-github.png){:.PostImage}](/assets/posts/2020-05-07-Youtube-as-IPTV-with-TVH/streamlink-github.png)

* [**youtube4tvh**](https://github.com/cgomesu/youtube4tvh): Youtube4tvh is a Python CLI program that uses Youtube API to create (or update) m3u playlists of live-streams that are piped into a TVH server via Streamlink. 

[![youtube4tvh Github](/assets/posts/2020-05-07-Youtube-as-IPTV-with-TVH/youtube4tvh-github.png){:.PostImage}](/assets/posts/2020-05-07-Youtube-as-IPTV-with-TVH/youtube4tvh-github.png)

For this guide, we will assume that such components are related to each other and any clients (any IPTV players, such as VLC, Plex or a Kodi PVR) according to the following layout:

[![Client-server layout](/assets/posts/2020-05-07-Youtube-as-IPTV-with-TVH/tvh-layout.jpg){:.PostImage}](/assets/posts/2020-05-07-Youtube-as-IPTV-with-TVH/tvh-layout.jpg)

However, once you're done with the initial configuration, you can try changing it to accomodate your needs.  For example, you can [multicast a live-stream to a TVH server using VLC](https://tvheadend.org/projects/tvheadend/wiki/VLC_Multicasting).  This will let you use a single connection to Youtube be distributed to multiple clients, instead of creating multiple connections to Youtube--definitely take a look at it if you're serving a large number of clients with your TVH server.  Also, you might want to pipe the Streamlink data to FFMPEG before sending to TVH, which will let you set custom AV codecs.  

[top](#){: .btn .btn--light-outline .btn--small}

# Youtube4tvh
This is a utility program that will let us create and manage m3u playlist of Youtube live-streams.  It can extract information directly from Youtube's frontend (default) or from Youtube's API (by using a valid API key).  Be aware that the API keys have daily quotas that this program will reach fairly quickly. For more info, checkout [the github page](https://github.com/cgomesu/youtube4tvh).

## Create a Youtube API v3
*Since the release of [**v0.1.1**](https://github.com/cgomesu/youtube4tvh/releases), youtube4tvh does not require the use of API keys to run. Therefore, **the use of API keys is now optional**. If you choose to skip this step, simply omit the* `--apikey` *argument when running this utility.*

You can find instructions on [the official page](https://developers.google.com/youtube/v3/getting-started).  If you don't want to head there, here is a streamlined version:

1. Sing up for or Log into your Google account;

2. Go to your [API dashboard](https://console.developers.google.com/apis/);

3. Create a project (top left &gt; new project);

4. Give the project a name and create it (this should take a few seconds...);

5. Select the project you just created and in the dashboard, go to '+ Enable APIs and Services';

6. Search for Youtube Data API v3 and enable it;

7. It should redirect you to its dashboard but if doesn't, select Manage;

8. Select Create Credentials (if you don't see a button, just go to Credentials in the side menu);

9. It's going to ask you which API you're going to use (select Youtube Data API v3), where you'll be calling it from (Other UI) and what data (Public data). Then select 'What credentials do I need?' and it will generate an unrestricted API for the project you created;

10. In the side menu, go to Credentials and Edit the API Key you generated;

11. Under 'API restrictions', select Restrict key &gt; Youtube Data API v3 &gt; Save.

That's it! Your key is that long string with random letters and numbers in the column labeled **Key**. Whenever you see a field to ```YOURKEY```, use that one.  Also, you can repeat this process to generate additional keys.  It's a good idea to do so. 

## Install youtube4tvh
Open a terminal window and run the following:

```
sudo apt update
sudo apt install git python-pip
cd /opt
sudo git clone https://github.com/cgomesu/youtube4tvh.git
cd youtube4tvh
```

Install required packages via pip:
```
pip install .
```

Test the program (change ```YOURKEY``` for your API key)
```
cd youtube4tvh
python main.py --apikey=YOURKEY --channelname=&quot;DW News&quot;
```

Now, there should be an output.m3u file on the same folder you are (you can ```ls``` to list files).

If you run into permission issues, make sure to use a user with sudo perission.  Also, if your user is not allowed to write to /opt, then run the follwing (changing ```YOURUSER``` for your sudo username):

```
sudo chown -R YOURUSER:sudo /opt/youtube4tvh
```

If everything looks good, go ahead and add permission to execute the streamlink.sh helper script that will pipe data into TVH (if you want to change settings from streamlink, change them in the streamlink.sh file):

```
sudo chmod +x /opt/youtube4tvh/streamlink.sh
```

## Basic usage
This program has two modes of execution, **add** and **update**. The ```--mode=add``` is the default mode and it will create an m3u file if you don't specify one.  However, if you do provide an ```--m3uinput=/path/to/file.m3u```, it will instead append channels to output.m3u. (If ```--m3uinput``` and ```--m3uoutput``` are the same, then it appends to itself.) 

The ```--mode=update``` will parse an ```--m3uinput=/path/to/file.m3u``` and update all URLs to make sure they are the ones currently available (instead of a broken URL).  This is useful because even though some Youtube channels stream 24/7, they will at times stop and restart the stream, which will cause Youtube to generate a new URL to their live-stream.  The ```--mode=update``` will make sure your output.m3u is always using the correct URLs.  (Again, if you want to update the same input file, then point both ```--m3uinput``` and ```--m3uoutput``` to the same m3u file.)

First, we will generate a youtube.m3u file with the channel &quot;DW News&quot;.  Afterwards, we will append a couple of additional channels to the youtube.m3u file.  Then, we will create a cronjob to keep our youtube.m3u up-to-date.

* Create youtube.m3u file and add the channel &quot;DW News&quot; (change ```YOURKEY``` to your actual API key):

```
cd /opt/youtube4tvh/youtube4tvh
python main.py --apikey=YOURKEY --m3uoutput=youtube.m3u --channelname=&quot;DW News&quot;
```

* Append the channel &quot;France 24 English&quot; to the youtube.m3u file:

```
python main.py --apikey=YOURKEY --m3uinput=youtube.m3u --m3uoutput=youtube.m3u --channelname=&quot;France 24 English&quot;
```

* Append the channel &quot;Explore Nature&quot; to the youtube.m3u file:

```
python main.py --apikey=YOURKEY --m3uinput=youtube.m3u --m3uoutput=youtube.m3u --channelname=&quot;Explore Nature&quot;
```

* Create a cronjob to update the youtube.m3u file everyday at 6am. First, make a backup or your youtube.m3u file:

```
cp /opt/youtube4tvh/youtube4tvh/youtube.m3u /opt/youtube4tvh/youtube4tvh/youtube.m3u.backup
```

* Create a cronjob:

```
crontab -e
```

* Add the following at the bottom

```
0 6 * * * /usr/bin/python /opt/youtube4tvh/youtube4tvh/main.py --apikey=YOURKEY --m3uinput=/opt/youtube4tvh/youtube4tvh/youtube.m3u --m3uoutput=/opt/youtube4tvh/youtube4tvh/youtube.m3u --mode=update
```

* Save and exit (ctrl+x)

That's all we need to do with this program.  If you ever feel like adding a new channel to the playlist, you can just repeat the &quot;Append&quot; examples with the new channel instead. 

If you want to remove a channel, you'll need to manually edit the youtube.m3u file (remove the channel's #EXTINF row and the one immediately below it, which contains the pipe command).  You can also manually edit the m3u file to add a group-title to the channels (see sample/input.m3u, for example), change their order, etc.  Just use your favorite text editor to do that and when you're done, save preserving the .m3u extension.

## Recommendations
Theoretically, the m3u playlists can contain as many streams as you want.  However, as a general rule of thumb, I find it useful to create one m3u playlist for each type of streaming channel--for example, youtube-webcams.m3u, youtube-news.m3u, youtube-radio.m3u, and etc--and then have a unique API key for each of them.  This way, I can run the youtube4tvh cronjob more often, thus reducing the chance of having broken URLs in the m3u file.

[top](#){: .btn .btn--light-outline .btn--small}

# Streamlink
Streamlink is an awesome utility program and if you've never used it before, make sure to check their [documentation](https://streamlink.github.io/).  Here, we will only use it to pipe data from Youtube to a TVH server but Streamlink is able to pipe video streams from many other platforms (Twitch, Dailymotion, etc.). 

To install Streamlink, please follow the instructions on [the official website](https://streamlink.github.io/install.html).  Make sure you're running the latest version afterwards.  You can find the installed version by running ```streamlink --version```, which should be the same one as the latest version on their [Releases page](https://github.com/streamlink/streamlink/releases).

(It looks like multiple repos are distributing a much older version than the 1.4.1, which is the latest when this article was first posted.  If that's the case for your distro, take a look at the PyPi and source installation on their Install page.  Uninstall the older version and install via pip and if that doesn't work, try cloning their git repo and install via setup-tools, very much like the youtube4tvh utility.)

In ```/opt/youtube4tvh```, you'll notice a file called **streamlink.sh**.  That is a helper script that TVH will use to get the video stream from a Youtube URL.  If you open it with a text editor, you'll see the following:

```
#!/bin/bash
####################################################
################ Streamlink script #################
####################################################
# The default version writes the data from the best
# stream ($1, the first argument) to stdout using a
# thread pool of size 2 to download HLS segments.
# Everything else follows default values.
#
# Inspired by niwi_niwi's post at
# https://tvheadend.org/boards/5/topics/35658
#
# More info: https://streamlink.github.io/cli.html
#
####################################################
#### Add/modify script according to your needs #####
streamlink \
--stdout \
--hls-segment-threads 4 \
--hls-live-edge 10 \
&quot;$1&quot; best
```

The actual command to execute streamlink and its options are all at the bottom.  If you know what you're doing and want to play with different configurations, go ahead and change the arguments in the streamlink command.  Say, if instead of playing always the 'best' stream you want to play the 480p version, then just change it to that (but always leave ```--stdout``` or you won't be able to pipe data to TVH).  Once again, [check the docs](https://streamlink.github.io/cli.html) for a comprehensive list of options. 

To test the script, you can simply execute the following (change ```YOUTUBEURL``` for the URL of a Youtube live-stream):

```
bash streamlink.sh YOUTUBEURL
```

You should see a whole bunch random characters as streamlink outputs the video stream to the terminal.  Hit ctrl+c to terminate the process.  If you have a player, you can run the command above with a pipe to the player.  Using [**VLC**](https://github.com/videolan/vlc), for example:

```
bash streamlink.sh YOUTUBEURL | vlc -
```

[top](#){: .btn .btn--light-outline .btn--small}

# TVH server
TVH was a game-changer for me.  It offers a centralized system to manage multiple IPTV networks and TV tuners.  I can fully customize how all channels will show up to all my clients and that's so much better than using multiple (and sometimes shady) applications developed by each IPTV provider.  If a channel is down, I can tell TVH to automatically remove it or remap to another provider.  If the EPG is not working, I can tell TVH to fetch from another source.  If a client does not support a particular type of codec, I can create a profile that uses the codec that works with it.  And all those changes are automatically applied to all clients, without the need to change one by one, because they are all getting data from my TVH server instead of external sources.  (It's the TVH server that should always do that latter.) 

## Installation
To install a TVH server, please follow the instructions on [the official website](https://tvheadend.org/projects/tvheadend/wiki/Download).  I strongly suggest you to install from the repo to make it easy to update with a simple ```apt update``` command.  Also, make sure you're running the latest version of it afterwards.

## Basic configuration
After installing TVH, head to the webUI on [http://localhost:9981](http://localhost:9981).  (If you're not running a desktop environment on the same machine, access it from another machine on the same network and change localhost for the IP of the machine running the TVH server.  Also, it goes without saying that the machine hosting the TVH server should have a fixed IP address at the local network because all the clients will be pointing to it.) 

If you provided admin credentials for TVH during the installation, it will ask you to identify yourself now. 

TVH will start the wizard the first time you access the webUI but you can just skip it (hit Cancel).

Notice that there are several tabs in the webUI but many options will not show up if the &quot;View level&quot; is set to Basic, so let's change the default to **Expert**: 

```
# Go to Configuration &gt; General &gt; Base &gt; Server &gt; Set &quot;User interface level&quot; to Expert and hit Save
```

Now, let's configure the Stream profiles to restart on error:

```
# Go to Configuration &gt; Stream &gt; Stream profiles &gt; htsp &gt; Check &quot;restart on error&quot; hit Save
```

(You can repeat that step to all profiles that you're going to use.  I usually just use htsp for clients and pass for auto-recording.)

While we're at it, let's go ahead and customize the Recording settings as well.  This is all really up to your own preferences but this is what I use that is different from the default configuration:

```
# Go to Configuration &gt; Recording &gt; DVR Profiles &gt; Default profile
# DVR file retention: 3 days
# Pre-recording padding: 5 mins
# Post-recording padding: 5 mins
# Recording system path: /path/to/my/NAS/media/iptv/recording
# Maintain free storage space in MiB: 5000
# File permissions: 0777
# Filename character set: UTF-8
# Skip commercials: Unchecked
# Format string: $c/$t - $c - %F - %R$n.$x
# Directory permissions: 0777
# Make subdirectories per channel: Checked
# Include date in filename: Checked
# Include time in filename: Checked
# Remove all unsafe characters from filename: Checked
# Hit Save
```

We're done with the basic configuration!  Before moving to the next section, notice that at the bottom of the webUI there's a bar called **Tvheadend log** and on the opposite side, there is a button.  Click on it to open the log.  This is very useful to check if there's any error while you're making changes to the server.  Keep it open as you change the settings and if you see an error, there's probably something misconfigured that you should fix before moving on. 

## Create an IPTV auto network
We're now going to create an IPTV network using the youtube.m3u file we created with youtube4tvh.  Open the TVH webUI and do the following:

```
# Go to Configuration &gt; DVB Inputs &gt; Networks &gt; Add
# Type: IPTV automatic network
```

This will redirect to IPTV settings.  Change the following:

```
# Network name: youtube
# URL: file:///opt/youtube4tvh/youtube4tvh/youtube.m3u
# Create bouquet: Checked
# Channel numbers start from: 1
# Accept zero value for TSID: Checked
# Provider network name: youtube
# Ignore provider's channel numbers: Checked
# Character set: UTF-8
# Scan after creation: Unchecked
# Content character set: UTF-8
# Service ID: 1
# Hit Create
```

Before we move on, now is a good time to check if streamlink and the helper script are working.  We're going to force play a few muxes (channels from your youtube.m3u playlist) to make sure that it's all good before mapping them to actual TV channels.  (You gonna need a player for this step; if you don't have one, skip it or install VLC).

```
# Go to Configuration &gt; DVB Inputs &gt; Muxes &gt; Choose a random one and Hit the Play button
```

The selected stream should show up in a few seconds.  If it doesn't, there's likely an issue with streamlink or the player or both, in which case you should stop and try to solve it before moving on.

## Mapping serves to channels
There are two ways of mapping services to channels.  The standard way is to go to the Services tab and choose Map Selected &gt; Map all services.  This should work very well if your muxes won't ever change.  However, if they do (as in our case), they won't be automatically remapped to their channel, and you gonna have to do this mapping process manually once again, multiple times.  We don't wanna do that.  Fortunately, there's a second way of mapping services to channels that does so automatically, even if your muxes change, and that's via **Bouquets**. 

Remember that when we created the youtube IPTV network, we selected &quot;Create a bouquet&quot;.  Because of that, there's now a new entry in Configuration &gt; Channel / EPG &gt; Bouquets &gt; &quot;youtube&quot;.  So, let's go ahead and edit it a little bit:

```
# Go to Configuration &gt; Channel / EPG &gt; Bouquets &gt; Edit the &quot;youtube&quot; bouquet
# Enabled: Checked
# Auto-map to channels: Checked
# Channel mapping options: Select all
# Create tags: Create provider name tags, Create network name tags
# Hit Save
```

Wait a few seconds and go to the &quot;Channels&quot; tab and you should see all your channels auto-mapped to their services.  If you make any changes to the youtube.m3u playlist, the bouquet should automatically detect those changes from now on.

## EPG data
Some of the 24/7 news channels on Youtube (e.g., France 24, DW) actually follow the same eletronic program guide (EPG) as their Cable/Satellite broadcast.  So, if you want, you can add EPG data to their Youtube live-stream.  There's a fantastic program called [**WebGrab+Plus**](http://webgrabplus.com/) that can do that for you **for free**, but there's a learning curve to it and how to feed the data to TVH (netcat or curl).  I'm planning on writing a guide about it in the near future, as I work on a parser for the site.pack folder as well.  But if you don't feel like diving into that, you can always pay an EPG provider and manually add it to your clients (bad) or try to figure it out how to feed the EPG data to the TVH server (good).

## Creating and editing users
Clients can access TVH using the same credentials as you've been using to configure the TVH server (admin access). As a general rule of thumb, however, that's not a good practice.  Also, if you have multiple clients, it's nice to know what each one is trying to access on your TVH server.  So, let's go ahead and create a &quot;client&quot; user:

```
# Go to Configuration &gt; Users &gt; Access Entries &gt; Add
# Streaming: Select all
# Video recorder: Basic, HTSP, View All
# Hit Create
```

Now let's add a password for it:

```
# Go to Configuration &gt; Users &gt; Passwords &gt; Add
# Enabled: Checked
# Username: client
# Password: password
# Hit Create
```

That's it!  You can repeat this process as many times as you need and play around with permissions, depending on your use-case.

## Re-fetch period and youtube4tvh cronjobs
If you've a youtube m3u playlist with channels that are likely to change multiple times during the same day, then it's a good idea to create a separate playlist for those channels.  Then, when you create a youtube4tvh cronjob for the new m3u playlist, make it run more frequently (e.g., every 5 mins would be ```*/5 * * * *```) and in the TVH server, add a new IPTV auto network for the new m3u playlist and in its settings, edit the &quot;re-fetch period&quot; to match the cronjob update interval (5); hit save and then restart the TVH server to apply the new settings. If you've done it right, the TVH server will now check the m3u playlist at an interval equal to the re-fetch period and update any new/changed mux on it, which will be automatically mapped to a channel in its bouquet.

[top](#){: .btn .btn--light-outline .btn--small}

# TVH client
There are multiple ways to watch the channels on your TVH server, including directly from the webUI itself (EPG tab &gt; Watch TV).  The one I use is [**Kodi**](https://kodi.tv/download) + **TVH client addon** because my Kodi clients also access my Plex server.

You can install Kodi on virtually any single-board computer, such as [Raspberry Pi](https://www.raspberrypi.org/) and [Odroid](https://www.hardkernel.com/), and Linux distro.  There are hundreds of guides showing how to install Kodi, so I won't do that.  Instead, I'll talk about the **TVH client addon** for it.

## Install a TVH client addon for Kodi
Open Kodi and try to install via the official repo:

```
# Go to Add-ons &gt; Install from repo &gt; PVR clients
# Look for Tvheadend HTSP Client and install it
```

Now, depending on the distribution, you won't see the &quot;PVR clients&quot; option.  In this case, you have to manually install the TVH client.  On Debian, for example, you can install it like so:

```
# Open a terminal
sudo apt update
sudo apt install kodi-pvr-hts
```

(Another option is to download a .zip of the addon but please do your research first.  Don't download and install addons from random repos.)  If you didn't see any error, it means the PVR client is now available on Kodi, so open it (restart it, if it was already open) and then do the following (changing the values to the appropriate ones for your TVH server and client credentials):

```
# Go to Add-ons &gt; My add-ons &gt; PVR clients &gt; Tvheadend HTSP Client &gt; Configure
# &gt; Connection Settings
# IP address: The IP address of the machine hosting your TVH server
# HTTP port: 9981
# HTSP port: 9982
# Username: client
# Password: password
# &gt; Streaming settings
# Profile to use: htsp
# (If your connection is pretty good, you might want to try enabling predictive tuning
# but I've had mixed results with it.)
# Hit OK
# Restart Kodi
```

If you want to play around, you can create a video profile just for this client and then set the Profile to use it.  This could be a profile that transcodes to a particular AV codec that best fits the client hardware, for example.  Be mindful that whenever you make a change to the addon, you'll need to restart Kodi to see the changes take effect.

Test the Kodi client:

```
# Go to TV &gt; Channels &gt; Play random one
```

If everything is working as it should, you should now be able to watch the stream from your Kodi client.  Play around with it and try recording something, too.  Now it's time to fine-tune your TVH server to best serve your clients.

You can make further client-side changes in **Kodi's PVR &amp; Live TV settings menu**, such as mapping channels to specific numbers, behavior of changing channels, etc.

[top](#){: .btn .btn--light-outline .btn--small}

# Conclusion
Congratulations for reaching the end of this guide.  As I said before, one of my future projects is to work on a parser for the Webgrab+Plus EPG data and then write a guide on how to implement it using the current setup.

If you found this useful or have suggestions on how to improve this guide, please leave a comment and I'll try to reply asap.

[top](#){: .btn .btn--light-outline .btn--small}</content><author><name>Carlos Gomes</name></author><category term="blog" /><category term="github" /><category term="iptv" /><category term="kodi" /><category term="streamlink" /><category term="tvheadend" /><category term="youtube" /></entry><entry><title type="html">Using the Odroid C2 IR receiver with LibreElec OS</title><link href="/blog/IR-with-odroidc2/" rel="alternate" type="text/html" title="Using the Odroid C2 IR receiver with LibreElec OS" /><published>2020-02-18T00:00:00-03:00</published><updated>2020-02-18T00:00:00-03:00</updated><id>/blog/IR-with-odroidc2</id><content type="html" xml:base="/blog/IR-with-odroidc2/">In case you didn't know, the [Odroid C2](https://www.hardkernel.com/shop/odroid-c2/) comes with an onboard infrared (IR) receiver.  Until a few days ago, I thought that such a receiver was only compatible with their own IR remote controller but it turns out you can use it with *any IR controller*.  We can do that with a package called [**lirc**](http://www.lirc.org/html/), which stands for **linux infrared remote control**.

[![Odroid C2 board](/assets/posts/2020-02-18-IR-with-odroidc2/board.png){:.PostImage}](/assets/posts/2020-02-18-IR-with-odroidc2/board.png)

This brief tutorial is for the **LibreElec OS** but one can use lirc with **any Linux distro** and the configuration won't be completely different than the one shown here.  (For the sake of completeness, I've tested with **LibreElec Official OS 9.0.2** running **Kodi 18.2**) Here's a step by step procedure to get the IR working with lirc:

1. SSH into your Odroid C2
```
ssh root@IP
```
2. Get a list of all available keys that you can map to your IR remote
```
irrecord --list-namespace
```
3. Kill running lircd, if there's any
```
ps aux | grep lircd
kill PID
```
4. Turn off all other IR compatible devices before moving forward
5. Go to ```/storage```, record IR custom keys and follow the instructions that will show yup on your screen:
```
cd /storage/
irrecord
```
6. If succesful, irrecord will genetare a .conf file on /storage/ with the name you provided at the beginnig. Copy the .conf file to ```/storage/.conf/lircd.conf```, as follows:
```
cp *.conf /storage/.conf/lircd.conf
```
7. Reboot your system
```
reboot now
```
8. Test your IR remote! If some key is missing, you can go back to ```irrecord``` and edit or record new keys.

That's it.  This is a short tutorial I wrote mostly to remind myself about this feature but hopefully, this tutorial is going to help someone else out there, too.

[top](#){: .btn .btn--small .btn--light-outline}</content><author><name>Carlos Gomes</name></author><category term="blog" /><category term="odroid" /><category term="sbc" /></entry><entry><title type="html">The math of a bruised souleater</title><link href="/blog/Math-of-bruised-souleater/" rel="alternate" type="text/html" title="The math of a bruised souleater" /><published>2019-07-19T00:00:00-03:00</published><updated>2019-07-19T00:00:00-03:00</updated><id>/blog/Math-of-bruised-souleater</id><content type="html" xml:base="/blog/Math-of-bruised-souleater/">This is a repost of my [original reddit post](https://www.reddit.com/r/magicTCG/comments/7phqk1/the_math_of_a_bruised_souleater/). I've made a few changes to the original version to improve readability.
{: .notice .notice--info}

This is a post about an interesting interaction that came up yesterday, when I was making changes to an EDH deck. I thought someone else might find this analysis interesting, so I decided to share it here. If you spot an error, feel free to point it out. The interaction is about two cards, namely **Immolating Souleater** and **Bruse Tarl, Boorish Herder**.

[![Immolating souleater](/assets/posts/2019-07-19-Math-bruised-souleater/immolating-souleater.jpg){: .PostImage}](/assets/posts/2019-07-19-Math-bruised-souleater/immolating-souleater.jpg)

[![Bruse tarl](/assets/posts/2019-07-19-Math-bruised-souleater/bruse-tarl.jpg){: .PostImage}](/assets/posts/2019-07-19-Math-bruised-souleater/bruse-tarl.jpg)

Suppose you have Immolating Souleater on the battlefield and Bruse Tarl, Boorish Herder's triggered ability give it double-strike and lifelink. Souleater is a 1/1 creature that costs 2 colorless and let's you pay one phyrexian red mana to give it +1/+0 until eot.  Let's assume you cannot pay red mana and if you want to activate Souleater's ability, you need to pay life. The souleater is not under summoning sickness, so it can attack an opponent. For now, let's also assume you have 40 life and your opponents also have 40 life. You see an opportunity to kill an opponent, declare attack, the souleater is not blocked, you pay 38 life to make it a 20/1 creature with double-strike and lifelink, and after all damage is done, your opponent dies and you gain 40 life back (for a +2 net life, as you end up with 42 in the end).

This is cool and all but what happens when you cannot pay 38 life before the first hit? What if your opponent has more life than you? Life-wise, does it matter how much life you pay before the first hit? How much life can you pay at any given point to either maximize damage or minimize net life loss? Let's think about it.

Souleater's activated ability is a simple linear function of the amount of life you pay. Let x be the amount of life paid, so that souleater's power is given by

[![Eq 01](/assets/posts/2019-07-19-Math-bruised-souleater/eq1.png){: .PostImage}](/assets/posts/2019-07-19-Math-bruised-souleater/eq1.png)

(To make it simple, we ignore the fact that phyrexian mana is always 2 life and let x be any non-negative integer.) As in the previous example, if you pay 38 life, f(38) = 20. The tricky part is how this simple linear function interacts with Bruse's ability, that is, the ability to give a creature double-strike and lifelink (&quot;bruised&quot;).

The intuition with double-strike is to multiply f(x) by 2, which would be correct if we only paid life before the first hit (x1) and nothing else before the second hit (x2 = 0) but that does not need to be the case. Say we pay 20 life before the first hit (x1 = 20) and an additional 10 life afterwards (x2 = 10). How much damage will we deal to the opponent? We know that f(20) = 11 and f(10) = 6 but the first hit should carry over to the second becasue the +1/+0 lasts until eot. At this point, let's make an equation for the first hit,

[![Eq 02](/assets/posts/2019-07-19-Math-bruised-souleater/eq2.png){: .PostImage}](/assets/posts/2019-07-19-Math-bruised-souleater/eq2.png)

and another for the second hit,

[![Eq 03](/assets/posts/2019-07-19-Math-bruised-souleater/eq3.png){: .PostImage .PostImage--large}](/assets/posts/2019-07-19-Math-bruised-souleater/eq3.png)

Now, we can sum both functions to get the total amount of damage dealt (d) by a Souleater with double-strike:

[![Eq 04](/assets/posts/2019-07-19-Math-bruised-souleater/eq4.png){: .PostImage  .PostImage--large}](/assets/posts/2019-07-19-Math-bruised-souleater/eq4.png)

(It's easy to see how one could generalize this to triple-strike, quadruple-strike, ..., but lets not delve into it now.) Therefore, if x1=20 and x2=10, d(20,10) = f1(20)+f2(20,10), which is 27 damage for 30 life paid.

So, now we have an equation (d) that we can play with. For example, if an opponent has 60 life, how much life do you need to pay? Because x1 is multiplied by two, if the goal is to deal as much damage as possible, you should always pay as much life as possible before the first hit. The easiest way here is to pay 58 life right away (x1 = 58 and x2 = 0) but what if you only have 40 life. Our dmg equation shows that if you have 40 life, you can pay 38 before the first hit (x1=38) but in order to kill your opp, youd have to pay 40 before the second hit (x2=40), which we can already tell that wont be possible with the other parameters we set for this scenario. The question is then how high can x2 be in order to deal the highest amount of damage without killing ourselves? Now we need to figure out how to add lifelink into the equation.

Lifelink will affect your life total (k) and because a souleater with double-strike hits twice, lets define your starting life total (k1), our life total after the first hit (k2), and our life total after the second hit (k3). As before, lets say that we pay 20 life before the first hit (x1 = 20) and an additional 10 life afterwards (x2 = 10). Because our life total matters here, lets also assume that our starting life total is k1 = 40. So, if x1 = 20, our remaining life before the first hit is the difference k1  x1 = 20 and immediately after the first hit, the lifelink effect makes it go up by f1(20) = 11 points, which means that we can define

[![Eq 05](/assets/posts/2019-07-19-Math-bruised-souleater/eq5.png){: .PostImage}](/assets/posts/2019-07-19-Math-bruised-souleater/eq5.png)

and similarly,

[![Eq 06](/assets/posts/2019-07-19-Math-bruised-souleater/eq6.png){: .PostImage}](/assets/posts/2019-07-19-Math-bruised-souleater/eq6.png)

Now we have a simple way of defining net-life gain/loss (nl) as the difference between k3 and k1, namely

[![Eq 07](/assets/posts/2019-07-19-Math-bruised-souleater/eq7.png){: .PostImage}](/assets/posts/2019-07-19-Math-bruised-souleater/eq7.png)

which funny enough doesnt include x1 into the equation. The equation for nl tells us three main things: (a) that we will never net more than 2 life, (b) well net life loss proportional to the amount of life we pay before the second hit (x2), and (c) net-wise, it doesnt really matter how much life you pay before the first hit (x1). (x1 doesnt matter because in our scenario, it always nets 0 life. Think about it. You are paying 2 life to increase 1 dmg but with double-strike, souleater hits twice and in the end, you get your 2 life back with lifelink. The only thing that carries over is the base power, which is why theres a constant 2 in the equation for k3.)
 
Good. Now, what can we do with that? Well, we can figure out how to maximize dmg in terms of our life total, so that you deal as much damage as possible without dying for any given amount of starting life total (the math equivalent of just pay as much life as you can before each hit). For k1 &gt; 0, let i1 and i2 be the amount of life you want to have before the first hit and second hit, respectively, then

[![Eq 08](/assets/posts/2019-07-19-Math-bruised-souleater/eq8.png){: .PostImage .PostImage--large}](/assets/posts/2019-07-19-Math-bruised-souleater/eq8.png)

(Theres an additional complication here because of how we use phyrexian mana but we dont need to worry too much about it as long as we can figure out the appropriate i1 and i2 for each value of k1. For example, if you have 40 life, max(d) = 2.5 + 1.25(40) - .75(2) - .5(2) = 50. Because k1 is multiplied by a value greater than one, this equation tells us that the amount of damage done above your starting life increases with our starting life. For example, if you have 40 life, you can deal 10 damage above your starting life to an opponent (e.g., kill an opponent with 50 life points) but if you have 20 life, you can only deal 5 damage above your starting life (e.g., kill an opponent with 25 life points). Its easier to see this relationship when we plot max(d) as a function of the starting life (k1) using the minimum appropriate values of i1 and i2:

[![Regression](/assets/posts/2019-07-19-Math-bruised-souleater/regression.jpg){: .PostImage}](/assets/posts/2019-07-19-Math-bruised-souleater/regression.jpg)

If we fit a linear equation to it, we get a solution that does not require knowing the exact values of i1 and i2, namely max(d)  .65 + 1.25k1.  However, because each point is equally likely, as /u/darth_aardvark pointed out, the appropriate intercept should be the mean of all possible combinations of min(i1) and min(i2), which can only take on values {1, 2}.  There is a total of 2^2 combinations of  min(i1) and min(i2), namely

[![Eq 09](/assets/posts/2019-07-19-Math-bruised-souleater/eq9.png){: .PostImage .PostImage--large}](/assets/posts/2019-07-19-Math-bruised-souleater/eq9.png)

Those equations give us a mean intercept = .625 and a revised and final formula for the maximum amount of damage that a &quot;bruised&quot; souleater can do, specifically 

[![Eq 10](/assets/posts/2019-07-19-Math-bruised-souleater/eq10.png){: .PostImage}](/assets/posts/2019-07-19-Math-bruised-souleater/eq10.png)

which is equivalent to the more memorable formula

[![Eq 11](/assets/posts/2019-07-19-Math-bruised-souleater/eq11.png){: .PostImage}](/assets/posts/2019-07-19-Math-bruised-souleater/eq11.png)

in which k1 is simply your life total before the attack.  The 5/4 coefficient is quite instructive because it connects this approach to /u/darth_aardvark's.  Specifically, the first maximized damage of a bruised souleater will hit for approximately half our life total (k1/2), while the second hit will hit for half our life total plus half of the life gained from the second hit (k1/2 + k1/4), which gives us a total of 5/4(k1).

Well, this has been fun. Im sure there are other things we could play with here but Ive had enough for now. I think there are two main conclusions about a bruised Souleater. The first and least obvious one imo is that the more life you have, the more damage you can deal above your own life total. This is useful because it gives an intuition about whether you can kill an opponent or not at any given point (low life = cannot deal much above my own life; high life = can deal a bit more than my own life), and whether you should attempt to compute exacties. In most cases, however, you wont be able to deal a whole lot more than your own life. The other conclusion is that the amount of life you pay before the first hit and second hit is net neutral and net negative, respectively, but I feel most of us would be able to figure this one out without much effort (lifelink gets only half the amount of life paid immediately before the second hit, while it gets it all back for the amount of life paid immediately before the first hit).

Again, if you spot an error, please point it out. If you found a better way to look at this interaction or thought about a different scenario, feel free to explain it. 

[top](#){: .btn .btn--small .btn--light-outline}</content><author><name>Carlos Gomes</name></author><category term="blog" /><category term="mtg" /><category term="math" /></entry><entry><title type="html">The probability of Warp World</title><link href="/blog/Probability-warp-world/" rel="alternate" type="text/html" title="The probability of Warp World" /><published>2019-07-15T00:00:00-03:00</published><updated>2019-07-15T00:00:00-03:00</updated><id>/blog/Probability-warp-world</id><content type="html" xml:base="/blog/Probability-warp-world/">This is a repost from my [original reddit post](https://www.reddit.com/r/magicTCG/comments/8956af/the_probability_of_warp_world_math/). I've made a few changes to it to improve readability as well.
{: .notice .notice--info}

# Introduction
If youre unfamiliar with **Warp World**, you are in for a treat. Its a 5RRR sorcery from Ravnica that reads as follows:

&gt; Each player shuffles all permanents he or she owns into his or her library, then reveals that many cards from the top of his or her library. Each player puts all artifact, creature, and land cards revealed this way onto the battlefield, then does the same for enchantment cards, then puts all cards revealed this way that weren't put onto the battlefield on the bottom of his or her library.

[![Warp world](/assets/posts/2019-07-15-Probability-warp-world/warp-world.jpg){: .PostImage}](/assets/posts/2019-07-15-Probability-warp-world/warp-world.jpg)

There are many different ways to build around such a card. For example, we can play mostly permanents in our deck (i.e., very few instants and sorceries), add creatures with enter the battlefield (ETB) ability (e.g., Eternal Witness), add creatures with landfall ability (Lotus Cobra), and so on. Im not going to tell you how to play Warp World or advertise any particular deck that takes advantage of it. Instead, Ill try to formalize what happens when we cast Warp World, and how the outcome of casting it changes as a function of the type of cards we choose to play and when we cast it.

This is not meant to be an exhaustive analysis of the card and all of its possible interactions. If you spot an error or thought about a much simpler way of analyzing Warp World, please feel free to share it. Above all, this is meant to be a mathematical and statistical exercise. 

[top](#){: .btn .btn--small .btn--light-outline}

# The Basics
In a game of magic, we play with a deck, , composed of *n* cards, such that  = {*&lt;sub&gt;1&lt;/sub&gt;*, , *&lt;sub&gt;n&lt;/sub&gt;*} is our deck. The current types of cards in MtG can be of two sorts, namely permanents (land, creature, artifact, enchantment, and planeswalker) and non-permanents (sorcery and instant). Let  be the set of all *z* permanents that we have in our deck (e.g., Elvish Mystic, forests, mountains, Primeval Titan), such that  = {*&lt;sub&gt;1&lt;/sub&gt;*, , *&lt;sub&gt;z&lt;/sub&gt;*} are all the permanents in our deck. Because therere only permanents and non-permanents in our deck, the set of non-permanents can be defined as the negation of , , such that    = .

When a game of magic starts, our deck becomes our library. Lets define our library by the set  of *k* cards, such that  = {*&lt;sub&gt;1&lt;/sub&gt;*, , *&lt;sub&gt;k&lt;/sub&gt;*} is our library, and the rules tell us that   , that is, all cards in our library are cards from our deck. In addition, when the game starts, it also creates other three zones that are of particular relevance to us, namely the battlefield, our hand, and the graveyard. Lets define  as the set of *y* permanents we have on the battlefield, such that  = {*&lt;sub&gt;1&lt;/sub&gt;*, , *&lt;sub&gt;y&lt;/sub&gt;*} are the permanents we have on our side of the battlefield. To make matters as simple as possible for now, lets also assume that   , that is, all permanents we have on the battlefield are permanents from our deck, until otherwise specified, and permanents are all but planeswalkers. Then we define  as the set of *a* permanents in our hand, such that  = {*&lt;sub&gt;1&lt;/sub&gt;*, , *&lt;sub&gt;a&lt;/sub&gt;*} are the permanents in our hand, and B is the set of *b* permanents in our graveyard, B = {*&lt;sub&gt;1&lt;/sub&gt;*, , *&lt;sub&gt;b&lt;/sub&gt;*}. As before, lets also assume that A   and B  .

Now we have a fairly good characterization of our deck and board state, so lets see what Warp World does. First, it makes us: 

1. count all permanents we have on the battlefield;
2. shuffle all of them into our library;
3. then reveal as many cards from the top of our library as permanents we counted;
4. and finally, put all revealed artifacts, creatures, lands, and (afterwards) enchantments onto the battlefield. Everything else that was not put onto the battlefield goes to the bottom of the library. (Our opponents do the same thing at the same time, and triggered abilities follow *apnap* order, as usual.)

Lets relate what Warp World does to our previous definitions. During the **first** step, the number of permanents we have on the battlefield will be the cardinality of , that is, \|\| = *y*. During the **second** step, we put \|  \| cards back into our library, and because were assuming that   , there are exactly *y* cards from  that will be put back into our library. So, by the end of the second step, our library will have exactly \|  \| = *k* + *y* cards, of which \|\| - \|  B\| = *z* - (*a* + *b*) are permanents. Regarding shuffling, we assume its not biased in any particular manner--that is, cards from our library are ordered at random every time its required to shuffle.

Here comes the interesting part, namely the **third** and **fourth** steps. During the **third** step, were instructed to reveal *y* cards from the top of our library and then, during the **fourth** step, we put all artifacts, creatures, lands, and enchantments revealed this way onto the battlefield. Lets define  as the set of *x* revealed artifacts, creatures, lands, and enchantments, such that  = {*&lt;sub&gt;1&lt;/sub&gt;*, , *&lt;sub&gt;x&lt;/sub&gt;*} are all the revealed permanents that will be put onto the battlefield. Now, because we dont know how all the cards in our library were ordered (unbiased shuffling), we cant tell which cards will be revealed in a deterministic way (e.g., the first will be a land, the second will be a creature, etc.). Fortunately, were quite capable of telling which cards will be revealed in a stochastic way (probabilistically).  For example, theres a .90 chance to reveal a land, or theres a .10 chance to reveal a creature.

The act of revealing cards from the top of our library is analogous to **sampling objects from a finite population without replacing them**, much like picking apples from an apple tree. Of note, we are usually revealing more than one card (*y* &gt; 1), and for now, the outcomes of interest will fall into two main categories, namely its either a permanent that we will put onto the battlefield or not. If each sampling were independent of one another (e.g., after revealing a card, we reshuffle it back into our library before revealing another card), we could classify this action as a Bernoulli trial and compute the probability of revealing permanents according to the binomial distribution. However, in our case, each sampling is not independent of one another, as the probability of a `success` (to reveal a permanent) changes as the number of revealed cards also changes. Therefore, we should model such an action of revealing cards from the top of our library with a **hypergeometric distribution**, which some magic players should be already familiar with, as it is often used to compute the optimal number of lands in a deck, for example, or the chance of drawing a certain card by turn.

When there are two mutually exclusive outcomes (e.g., permanent and non-permanent card), the **probability mass function** (pmf) of the number of permanents that Warp World will reveal will take the form

[![Eq. 1](/assets/posts/2019-07-15-Probability-warp-world/eq1.jpg &quot;Equation 1&quot;){: .PostImage .PostImage--large}](/assets/posts/2019-07-15-Probability-warp-world/eq1.jpg)

in which (*p*  *q*) is a **binomial coefficient**--that is, the number of ways *q* elements can be chosen from *p* elements, regardless of order, computed as *p*! / \[*q*!(*p* - *q*)!\]. Across ***four** coin tosses* (*p* = 4), for example, there are ***six** different ways of arranging* ***two** Tails* (*q* = 2)--namely, TTHH, THTH, THHT, HTTH, HTHT, and HHTT--which can be represented by the binomial coefficient (4  2) = 6. 

To make it easier for us, I wrote a table with definitions of the main parameters:

| parameter | definition |
|:---:|:---:|
| *a* | number of permanents in hand |
| *b* | number of permanents in the graveyard |
| *k* | number of cards in the library |
| *x* | number of permanents revealed with Warp World |
| *y* | number of cards revealed and number of permanents on the battlefield before resolving Warp World |
| *z* | number of permanents in the deck |

When we compute Eq.1 for all possible number of permanents revealed with Warp World, we get a probability distribution with mean

[![Eq. 2](/assets/posts/2019-07-15-Probability-warp-world/eq2.jpg &quot;Equation 2&quot;){: .PostImage .PostImage--large}](/assets/posts/2019-07-15-Probability-warp-world/eq2.jpg)

and variance

[![Eq. 3](/assets/posts/2019-07-15-Probability-warp-world/eq3.jpg &quot;Equation 3&quot;){: .PostImage .PostImage--large}](/assets/posts/2019-07-15-Probability-warp-world/eq3.jpg)

To illustrate its application, lets imagine the following scenario. Were playing with a 60-card deck that has 56 permanents (lets think of them as all mountains; *z* = 56) and four copies of Warp World. The game starts. Were on the play and we mull to two cards, a mountain and a copy of Warp World. During the next seven turns, we only draw mountains, so when we get to turn eight, we have eight mountains on the battlefield (*y* = 8), a single card in hand, which is Warp World, and 51 remaining cards in our library (*k* = 51). If we cast Warp World, what are our chances of putting, say, eight permanents back on the battlefield? What about seven, six, five, ? If we calculate such probabilities with Eq. 1 and plot the results for various numbers of permanents we had before casting Warp World (*y*), we get the following probability distributions:

[![Figure 1](/assets/posts/2019-07-15-Probability-warp-world/figure1.jpg &quot;Figure 1&quot;){: .PostImage .PostImage--large}](/assets/posts/2019-07-15-Probability-warp-world/figure1.jpg)

In the horizontal axis, we have the number of permanents that we get after resolving Warp World (*x*), while in the vertical axis, we have the probability of each of them. In addition, the multiple distributions represent different numbers of permanents we had before casting Warp World (*y*). (Missing probabilities are all zero.) In our example, if we have 8 permanents on the battlefield when we cast Warp World, we will get a mean of 8 permanents after resolving Warp Worldthat is, we usually get our eight lands backbut if we have 20 permanents on the battlefield when we cast Warp World, on average, we get 19 permanents back. Notice that even though the variability (sd stands for standard deviation) is low in absolute terms (the value of *x* is likely equal or close to the mean), the higher is the value of *y*, the higher is the variance. For example, if we have 8 permanents on the battlefield, we will usually get 7 or 8 permanents after resolving Warp World, and rarely anything other than that. However, if we have 20 permanents on the battlefield, we will usually get something between 18 and 20 permanents after resolving Warp World, and rarely anything other than that.

Before we move on, I should point out that each probability in Figure 1 refers to the probability of getting exactly that number of permanents, as Eq. 1 is a pmf. However, if your interest is in answering questions about fewer-than/up-to/at-least a certain number of permanents, all you need to do is sum adjacent values of *x* in the appropriate direction to get the cumulative probability. For example, if we have 20 permanents on the board before casting Warp World, what would be the probability of getting at least, say, 18 permanents? According to the Y=20 distribution in Figure 1, that probability would be .96.

Despite being a somewhat unrealistic scenario, Figure 1 gives us something that we can use to compare against different situations. For instance, how adding more non-permanents to our deck would affect the previous distributions? Lets set everything else equal to the previous example, except that now, our deck has 44 mountains (*z* = 44), four copies of Warp World, and 12 other non-permanents. The results are the following:

[![Figure 2](/assets/posts/2019-07-15-Probability-warp-world/figure2.jpg &quot;Figure 2&quot;){: .PostImage .PostImage--large}](/assets/posts/2019-07-15-Probability-warp-world/figure2.jpg)

Inspection of Figure 2 indicates two main differences in comparison to Figure 1. First, adding more non-permanents to a Warp World deck decreases the mean of the probability distribution of the number of permanents you will get after resolving Warp World, regardless of how many permanents you had before casting Warp World. Second, variability increased all over the board, so the chance of getting screwed up by Warp World increased quite a lot. In other words, this is why its not a good idea to play non-permanents in a Warp World deck, as you decrease its expected value and increase its variability. You get double screwed.

[top](#){: .btn .btn--small .btn--light-outline}

# The Multivariate Warp World Model

One limitation of the previous approach is that we cant tell what sort of permanent Warp World puts onto the battlefield. In some cases, the binary distinction is just what we need. In others, however, a more detailed distinction is needed, as different types of permanent will have different effects on the board state after Warp World resolves. One distinction that would make sense is the one given by Warp World itself, namely that permanents can be artifacts, creatures, lands, and enchantments. Weve already defined  as the set of all permanents in our deck, so it follows that artifacts, &lt;sub&gt;1&lt;/sub&gt;, creatures, &lt;sub&gt;2&lt;/sub&gt;, lands, &lt;sub&gt;3&lt;/sub&gt;, and enchantments, &lt;sub&gt;4&lt;/sub&gt;, ought to be subsets of , such that

[![Eq. 4](/assets/posts/2019-07-15-Probability-warp-world/eq4.jpg &quot;Equation 4&quot;){: .PostImage }](/assets/posts/2019-07-15-Probability-warp-world/eq4.jpg)

because for the sake of simplicity, we will continue to assume that were not playing planeswalkers. (Remember that Warp World does not put planeswalkers onto the battlefield, even though they are permanents that can be part of our deck.) Similarly, lets say that mutually exclusive subsets of , A, and B fall into the same categories as &lt;sub&gt;*i*&lt;/sub&gt;, such that

[![Eq. 5](/assets/posts/2019-07-15-Probability-warp-world/eq5.jpg &quot;Equation 5&quot;){: .PostImage .PostImage--large }](/assets/posts/2019-07-15-Probability-warp-world/eq5.jpg)

Now we can extend Eq. 1 to accommodate the additional outcomes of Warp Wold as follows

[![Eq. 6](/assets/posts/2019-07-15-Probability-warp-world/eq6.jpg &quot;Equation 6&quot;){: .PostImage .PostImage--large }](/assets/posts/2019-07-15-Probability-warp-world/eq6.jpg)

which is the pmf of the multivariate Warp World model. Such a distribution has mean

[![Eq. 7](/assets/posts/2019-07-15-Probability-warp-world/eq7.jpg &quot;Equation 7&quot;){: .PostImage .PostImage--large }](/assets/posts/2019-07-15-Probability-warp-world/eq7.jpg)

and variance

[![Eq. 8](/assets/posts/2019-07-15-Probability-warp-world/eq8.jpg &quot;Equation 8&quot;){: .PostImage .PostImage--large }](/assets/posts/2019-07-15-Probability-warp-world/eq8.jpg)

As before, lets think about a scenario to illustrate how Eq. 4-6 informs us about the probability of Warp World revealing different sorts of permanents as a function of the properties of our deck. Similar to our previous example, imagine we were playing with a 60-card deck composed of 24 lands (*z&lt;sub&gt;3&lt;/sub&gt;* = 24), 16 creatures (*z&lt;sub&gt;2&lt;/sub&gt;* = 24), and 20 non-permanents. The game starts. Were on the play and unfortunately, we have to mull to four cards, specifically two forests and two copies of Elvish Mystic. On turn 1, we play a forest and an elvish mystic. On turn 2, we draw a copy of Warp World, then play another forest and cast another elvish mystic. During the next four turns, we draw four mountains, so when we get to turn 6, we cast Warp World with two forests, four mountains, and two elvish mystics on the battlefield (*y* = 8), no cards in hand or graveyard, and 51 cards left in our library (*k* = 51). Whats the probability of revealing, say, two creatures and four lands with Warp World? On average, how many creatures and lands would Warp World put back on the battlefield after it resolves? We can answer such questions with Eq. 6-8. When we compute the probabilities in Eq. 6 for all possible values of *x&lt;sub&gt;2&lt;/sub&gt;* and *x&lt;sub&gt;3&lt;/sub&gt;* and plot such values, we generate the following three-dimensional representation of the probability distribution of *x&lt;sub&gt;2&lt;/sub&gt;* and *x&lt;sub&gt;3&lt;/sub&gt;*

[![Figure 3](/assets/posts/2019-07-15-Probability-warp-world/figure3.jpg &quot;Figure 3&quot;){: .PostImage .PostImage--large}](/assets/posts/2019-07-15-Probability-warp-world/figure3.jpg)

Figure 3 shows that when *y* = 8, the probability of revealing exactly two creatures and four lands from the top of our library is .10. In fact, this is one of the two most likely cases, the second one being two creatures and three lands, as both of them account for roughly 20% of the possible outcomes of a Warp World under this condition. In addition, Eq. 7 and 8 show that on average, Warp World will reveal 2 creatures (*sd* = 1 creature) and 3 lands (*sd* = 1 land) in this particular example.

Weve seen before that playing non-permanents in a Warp World deck is a bad idea. So, lets run the same simulation as before, except that instead of playing 16 creatures and 24 lands, our deck has 22 creatures and 26 lands. When thats done, we find the following distribution

[![Figure 4](/assets/posts/2019-07-15-Probability-warp-world/figure4.jpg &quot;Figure 4&quot;){: .PostImage .PostImage--large}](/assets/posts/2019-07-15-Probability-warp-world/figure4.jpg)

Inspection of Figure 4 indicates a shift of the mean of the probability distribution. Indeed, on average, Warp World would reveal 3 creatures (*sd* = 1 creatures) and 4 lands (*sd* = 1 lands) with the latter deck.

How would Figures 3 and 4 change if we increased the number of permanents on the battlefield before casting Warp World to, say, 20 permanents (*y* = 20)? The probability distribution of *x&lt;sub&gt;i&lt;/sub&gt;* in Figure 3 would look like this

[![Figure 5](/assets/posts/2019-07-15-Probability-warp-world/figure5.jpg &quot;Figure 5&quot;){: .PostImage .PostImage--large}](/assets/posts/2019-07-15-Probability-warp-world/figure5.jpg)

and would have mean 5 creatures (*sd* = 2) and 8 lands (*sd* = 2), while the distribution in Figure 4 would look like this

[![Figure 6](/assets/posts/2019-07-15-Probability-warp-world/figure6.jpg &quot;Figure 6&quot;){: .PostImage .PostImage--large}](/assets/posts/2019-07-15-Probability-warp-world/figure6.jpg)

and have mean 8 creatures (*sd* = 2) and 9 lands (*sd* = 2).

Of course, we could calculate probability distributions for decks that have non-zero artifacts and enchantments as well but it would be difficult to visualize them, as we would be using higher dimensions than before. Similarly, the same approach could be used for different, mutually exclusive distinctions (e.g., green creatures vs. red creatures vs. other permanents; ramp permanents vs. graveyard recursion permanents).

There are many things that can be done moving forward. For instance, we could use Eq. 6-8 to investigate how cards that generate mana or produce more than one permanent can net mana or permanents, then describe the necessary and sufficient conditions to create loops with Warp World. 

[top](#){: .btn .btn--small .btn--light-outline}

# Tokens
So far, weve worked under the assumption that when we cast Warp World, the only sort of permanent we have on the battlefield (and thus the number of cards we will reveal with Warp World) are the ones contained in our deckthat is,   . In some cases, this will be true; in others, however, it wont, as we might have tokens on the battlefield, which will increase the number of cards revealed with Warp World but it doesnt mean well shuffle that many cards into our library. Fortunately, taking tokens into account does not require us to make huge changes to the previous equations. Specifically, if    is not true, then by the end of the **second** step of Warp World, our new library will have size \|\| + \|  \|, instead of \|  \|, in which    are all permanents on the battlefield that are permanents from our deck (i.e., all non-token permanents). Everything else remains the same.

[top](#){: .btn .btn--small .btn--light-outline}

# Other Similar Spells
There are a few other spells that in one way or another, do something that is quite similar to what Warp World does. One example that comes to mind is **The Great Aurora**. I have no doubt we can use the Warp World model to compute probabilities for those spells as well. We just need to tweak the model a little bit to make it consistent with the wording used in similar spells (e.g., great aurora also makes we shuffle our hand).

[![The great aurora](/assets/posts/2019-07-15-Probability-warp-world/great-aurora.jpg){: .PostImage}](/assets/posts/2019-07-15-Probability-warp-world/great-aurora.jpg)

[top](#){: .btn .btn--small .btn--light-outline}

# Other Approaches
We could find probability distributions empirically. Goldfish a Warp World deck, say, a thousand times, take note of the relevant stats prior to and after casting Warp World, and estimate the distributions empirically. 

[top](#){: .btn .btn--small .btn--light-outline}

# Final Remarks
We end with a cautionary note. We know that adding more permanents to a Warp World deck usually yields a better outcomethat is, *the more permanents we have in the deck*, *the more permanents well likely reveal with Warp World*. However, it would be inappropriate to simply compare mean differences to draw conclusions about different Warp World decks. That is because changing properties of Warp World decks will likely change the variance of their distributions. One possible solution is to use a **standardized measure of the compound mean difference**--that is, the standardized measure of distance between the means of two *Pr*(*x&lt;sub&gt;i&lt;/sub&gt;*) distributions. 

[top](#){: .btn .btn--small .btn--light-outline}</content><author><name>Carlos Gomes</name></author><category term="blog" /><category term="mtg" /><category term="math" /><category term="probability" /><category term="model" /></entry></feed>